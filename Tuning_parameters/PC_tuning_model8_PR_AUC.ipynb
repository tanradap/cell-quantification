{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic classification: RF & adjust tuning step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thresholding in the context of:\n",
    "\n",
    "1) Compute the difference between p(class) - t(class) **\n",
    "\n",
    "1) Sorted in descending order\n",
    "\n",
    "2) Compare max to threshold, if less then we move on to compare the next most likely class against the threshold\n",
    "\n",
    "3) Continue until probability is equal or greater than threshold, assign that class\n",
    "\n",
    "4) If no classes get assigned, then that cell is labelled as 'ambiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import random \n",
    "\n",
    "from sklearn import preprocessing \n",
    "from statistics import mean\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from pprint import pprint \n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "#import ml_insights as mli "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Require: \n",
    "1. input_files.txt - to contian filenames I want to use. ** currently .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in:  12 files\n",
      "703484_cell_annotations_SD.csv  number of features:  342\n",
      "721701_cell_annotations_SD.csv  number of features:  342\n",
      "721735_cell_annotations_SD.csv  number of features:  342\n",
      "721771_cell_annotations.csv  number of features:  62\n",
      "721856_cell_annotations_SD.csv  number of features:  342\n",
      "722215_cell_annotations_SD.csv  number of features:  342\n",
      "755472_cell_annotations_SD.csv  number of features:  61\n",
      "755480_cell_annotations.csv  number of features:  61\n",
      "755481_cell_annotations.csv  number of features:  61\n",
      "755485_cell_annotations_SD.csv  number of features:  61\n",
      "755486_cell_annotations_SD.csv  number of features:  61\n",
      "755525_cell_annotations_SD.csv  number of features:  61\n",
      "Extracted: 12 files\n",
      "Note: inconsistencies come from tau necrosis - will be removed later\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Name</th>\n",
       "      <th>Class</th>\n",
       "      <th>Parent</th>\n",
       "      <th>ROI</th>\n",
       "      <th>Centroid_X</th>\n",
       "      <th>Centroid_Y</th>\n",
       "      <th>Detection probability</th>\n",
       "      <th>Nucleus: Area ¬µm^2</th>\n",
       "      <th>Nucleus: Length ¬µm</th>\n",
       "      <th>...</th>\n",
       "      <th>Smoothed: 50 µm: DAB: Membrane: Min</th>\n",
       "      <th>Smoothed: 50 µm: DAB: Membrane: Max</th>\n",
       "      <th>Smoothed: 50 µm: DAB: Membrane: Std.Dev.</th>\n",
       "      <th>Smoothed: 50 µm: DAB: Cell: Mean</th>\n",
       "      <th>Smoothed: 50 µm: DAB: Cell: Median</th>\n",
       "      <th>Smoothed: 50 µm: DAB: Cell: Min</th>\n",
       "      <th>Smoothed: 50 µm: DAB: Cell: Max</th>\n",
       "      <th>Smoothed: 50 µm: DAB: Cell: Std.Dev.</th>\n",
       "      <th>Smoothed: 50 µm: tau: Necrosis area µm^2</th>\n",
       "      <th>Smoothed: 50 µm: Nearby detection counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>721701.svs</td>\n",
       "      <td>Grey_matter</td>\n",
       "      <td>Epithelial_new</td>\n",
       "      <td>PathAnnotationObject</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>13262.7</td>\n",
       "      <td>12570.4</td>\n",
       "      <td>0.8110</td>\n",
       "      <td>19.2875</td>\n",
       "      <td>17.1735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0264</td>\n",
       "      <td>0.2883</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>-0.0725</td>\n",
       "      <td>0.4021</td>\n",
       "      <td>0.0615</td>\n",
       "      <td>10.1183</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>721701.svs</td>\n",
       "      <td>Grey_matter</td>\n",
       "      <td>Epithelial_new</td>\n",
       "      <td>PathAnnotationObject</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>13281.1</td>\n",
       "      <td>12573.9</td>\n",
       "      <td>0.7445</td>\n",
       "      <td>15.8931</td>\n",
       "      <td>16.4348</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0239</td>\n",
       "      <td>0.2995</td>\n",
       "      <td>0.0571</td>\n",
       "      <td>0.0617</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>-0.0673</td>\n",
       "      <td>0.4383</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>11.9707</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>721701.svs</td>\n",
       "      <td>Grey_matter</td>\n",
       "      <td>Epithelial_new</td>\n",
       "      <td>PathAnnotationObject</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>13258.4</td>\n",
       "      <td>12577.8</td>\n",
       "      <td>0.8102</td>\n",
       "      <td>42.2255</td>\n",
       "      <td>25.9681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0265</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.0553</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>-0.0722</td>\n",
       "      <td>0.3911</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>9.5437</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>721701.svs</td>\n",
       "      <td>Grey_matter</td>\n",
       "      <td>Oligo_new</td>\n",
       "      <td>PathAnnotationObject</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>13328.6</td>\n",
       "      <td>12592.3</td>\n",
       "      <td>0.8895</td>\n",
       "      <td>22.8011</td>\n",
       "      <td>17.0965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0308</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>-0.0937</td>\n",
       "      <td>0.3983</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>13.3102</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>721701.svs</td>\n",
       "      <td>Grey_matter</td>\n",
       "      <td>Oligo_new</td>\n",
       "      <td>PathAnnotationObject</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>13296.7</td>\n",
       "      <td>12622.4</td>\n",
       "      <td>0.8204</td>\n",
       "      <td>17.3133</td>\n",
       "      <td>15.4801</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0233</td>\n",
       "      <td>0.2791</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>-0.0866</td>\n",
       "      <td>0.4009</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>10.8676</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 342 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image         Name           Class                Parent      ROI  \\\n",
       "0  721701.svs  Grey_matter  Epithelial_new  PathAnnotationObject  Polygon   \n",
       "1  721701.svs  Grey_matter  Epithelial_new  PathAnnotationObject  Polygon   \n",
       "2  721701.svs  Grey_matter  Epithelial_new  PathAnnotationObject  Polygon   \n",
       "3  721701.svs  Grey_matter       Oligo_new  PathAnnotationObject  Polygon   \n",
       "4  721701.svs  Grey_matter       Oligo_new  PathAnnotationObject  Polygon   \n",
       "\n",
       "   Centroid_X  Centroid_Y  Detection probability  Nucleus: Area ¬µm^2  \\\n",
       "0     13262.7     12570.4                 0.8110              19.2875   \n",
       "1     13281.1     12573.9                 0.7445              15.8931   \n",
       "2     13258.4     12577.8                 0.8102              42.2255   \n",
       "3     13328.6     12592.3                 0.8895              22.8011   \n",
       "4     13296.7     12622.4                 0.8204              17.3133   \n",
       "\n",
       "   Nucleus: Length ¬µm  ...  Smoothed: 50 µm: DAB: Membrane: Min  \\\n",
       "0              17.1735  ...                              -0.0264   \n",
       "1              16.4348  ...                              -0.0239   \n",
       "2              25.9681  ...                              -0.0265   \n",
       "3              17.0965  ...                              -0.0308   \n",
       "4              15.4801  ...                              -0.0233   \n",
       "\n",
       "   Smoothed: 50 µm: DAB: Membrane: Max  \\\n",
       "0                               0.2883   \n",
       "1                               0.2995   \n",
       "2                               0.2878   \n",
       "3                               0.2705   \n",
       "4                               0.2791   \n",
       "\n",
       "   Smoothed: 50 µm: DAB: Membrane: Std.Dev.  Smoothed: 50 µm: DAB: Cell: Mean  \\\n",
       "0                                    0.0551                            0.0567   \n",
       "1                                    0.0571                            0.0617   \n",
       "2                                    0.0552                            0.0553   \n",
       "3                                    0.0568                            0.0602   \n",
       "4                                    0.0484                            0.0588   \n",
       "\n",
       "   Smoothed: 50 µm: DAB: Cell: Median  Smoothed: 50 µm: DAB: Cell: Min  \\\n",
       "0                              0.0372                          -0.0725   \n",
       "1                              0.0392                          -0.0673   \n",
       "2                              0.0372                          -0.0722   \n",
       "3                              0.0405                          -0.0937   \n",
       "4                              0.0432                          -0.0866   \n",
       "\n",
       "   Smoothed: 50 µm: DAB: Cell: Max  Smoothed: 50 µm: DAB: Cell: Std.Dev.  \\\n",
       "0                           0.4021                                0.0615   \n",
       "1                           0.4383                                0.0686   \n",
       "2                           0.3911                                0.0590   \n",
       "3                           0.3983                                0.0655   \n",
       "4                           0.4009                                0.0596   \n",
       "\n",
       "   Smoothed: 50 µm: tau: Necrosis area µm^2  \\\n",
       "0                                   10.1183   \n",
       "1                                   11.9707   \n",
       "2                                    9.5437   \n",
       "3                                   13.3102   \n",
       "4                                   10.8676   \n",
       "\n",
       "   Smoothed: 50 µm: Nearby detection counts  \n",
       "0                                         7  \n",
       "1                                         8  \n",
       "2                                         7  \n",
       "3                                        11  \n",
       "4                                         9  \n",
       "\n",
       "[5 rows x 342 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 1) Importing annotated cells \n",
    "#Variables: mylist, inputs \n",
    "\n",
    "## obtaining list of files \n",
    "with open(\"D:/Tanrada_classification/imbalance_cortical_training/annotated/annotated_inputs_SD.txt\") as f: \n",
    "    mylist= f.read().splitlines()\n",
    "    \n",
    "print(\"Read in: \",len(mylist),\"files\")\n",
    "\n",
    "## 2) reading in all those files \n",
    "inputs = [] \n",
    "for i in mylist: \n",
    "    dat = pd.read_csv('D:/Tanrada_classification/imbalance_cortical_training/annotated/'+i,sep=\",\")\n",
    "    ## Changing column names - since these names tend to be inconsistent causing problems \n",
    "    dat.columns.values[5] = 'Centroid_X'\n",
    "    dat.columns.values[6] = 'Centroid_Y'\n",
    "    dat.columns.values[8] = 'Nucleus: Area ¬µm^2'\n",
    "    dat.columns.values[9] = 'Nucleus: Length ¬µm'\n",
    "    dat.columns.values[12] = 'Nucleus: Max diameter ¬µm'\n",
    "    dat.columns.values[13] = 'Nucleus: Min diameter ¬µm'\n",
    "    dat.columns.values[14] = 'Cell: Area ¬µm^2'\n",
    "    dat.columns.values[15] = 'Cell: Length ¬µm'\n",
    "    dat.columns.values[18] = 'Cell: Max diameter ¬µm'\n",
    "    dat.columns.values[19] = 'Cell: Min diameter ¬µm'\n",
    "    #dat_cleaned = dat.iloc[:,0:61] ## SELECTING ONLY RELELVANT COLUMNS \n",
    "    print(i,\" number of features: \", dat.shape[1])\n",
    "    inputs.append(dat)\n",
    "\n",
    "print(\"Extracted:\", len(inputs),\"files\")\n",
    "print(\"Note: inconsistencies come from tau necrosis - will be removed later\")\n",
    "#Example\n",
    "inputs[1].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in: 12  NUMBER OF neighbouring cells files\n",
      "Extracted: 12 files\n"
     ]
    }
   ],
   "source": [
    "# 2.5) Importing in neghbouring cells info (numbers)\n",
    "\n",
    "with open(\"D:/Tanrada_classification/number_NNB/to_use/imbalance_NB_inputs_SD.txt\") as f: \n",
    "    nb_mylist= f.read().splitlines()\n",
    "    \n",
    "print(\"Read in:\",len(nb_mylist),\" NUMBER OF neighbouring cells files\")\n",
    "\n",
    "# reading in all those files \n",
    "nb_inputs = [] \n",
    "for i in nb_mylist: \n",
    "    dat = pd.read_csv(\"D:/Tanrada_classification/number_NNB/to_use/\"+i,sep=\",\") \n",
    "    nb_inputs.append(dat)\n",
    "    \n",
    "print(\"Extracted:\", len(nb_inputs),\"files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features  13\n",
      "Number of features  13\n",
      "Number of features  13\n",
      "Number of features  13\n",
      "Number of features  13\n",
      "Number of features  13\n",
      "Number of features  13\n",
      "Number of features  13\n",
      "Number of features  13\n",
      "Number of features  13\n",
      "Number of features  13\n",
      "Number of features  13\n"
     ]
    }
   ],
   "source": [
    "# Inspecting number of columns in NNB files: \n",
    "for i in nb_inputs:\n",
    "    print(\"Number of features \",i.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_dat shape: (485605, 13)\n",
      "dat shape: (573, 342)\n",
      "Expected shape: 573 353  Resulting shape: (573, 353)\n",
      "--------------------------\n",
      "nb_dat shape: (272349, 13)\n",
      "dat shape: (193, 342)\n",
      "Expected shape: 193 353  Resulting shape: (193, 353)\n",
      "--------------------------\n",
      "nb_dat shape: (410302, 13)\n",
      "dat shape: (253, 342)\n",
      "Expected shape: 253 353  Resulting shape: (253, 353)\n",
      "--------------------------\n",
      "nb_dat shape: (413521, 13)\n",
      "dat shape: (197, 62)\n",
      "Expected shape: 197 73  Resulting shape: (197, 73)\n",
      "--------------------------\n",
      "nb_dat shape: (442130, 13)\n",
      "dat shape: (216, 342)\n",
      "Expected shape: 216 353  Resulting shape: (216, 353)\n",
      "--------------------------\n",
      "nb_dat shape: (475306, 13)\n",
      "dat shape: (246, 342)\n",
      "Expected shape: 246 353  Resulting shape: (246, 353)\n",
      "--------------------------\n",
      "nb_dat shape: (357603, 13)\n",
      "dat shape: (625, 61)\n",
      "Expected shape: 625 72  Resulting shape: (625, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (516132, 13)\n",
      "dat shape: (593, 61)\n",
      "Expected shape: 593 72  Resulting shape: (593, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (296324, 13)\n",
      "dat shape: (515, 61)\n",
      "Expected shape: 515 72  Resulting shape: (515, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (331459, 13)\n",
      "dat shape: (590, 61)\n",
      "Expected shape: 590 72  Resulting shape: (590, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (530977, 13)\n",
      "dat shape: (508, 61)\n",
      "Expected shape: 508 72  Resulting shape: (508, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (364677, 13)\n",
      "dat shape: (247, 61)\n",
      "Expected shape: 247 72  Resulting shape: (247, 72)\n",
      "--------------------------\n",
      "Succesfully combined nb cell counts to main data\n"
     ]
    }
   ],
   "source": [
    "## Extracting only annotated cells from nb files \n",
    "inputs_=[]\n",
    "n=len(inputs)\n",
    "for i in range(0,n):\n",
    "    #all cells on slide\n",
    "    nb_dat = nb_inputs[i]\n",
    "    nb_dat = nb_dat.rename(columns={'X':'Centroid_X','Y':'Centroid_Y'})\n",
    "    print(\"nb_dat shape:\", nb_dat.shape)\n",
    "    #annotated cells with no nb info\n",
    "    dat = inputs[i]\n",
    "    print(\"dat shape:\", dat.shape)\n",
    "    #annotated cells with nb info: intersect between 2 dataframes \n",
    "    combined = dat.merge(nb_dat,on=['Centroid_X','Centroid_Y'],how='inner',validate='1:1') \n",
    "    inputs_.append(combined)\n",
    "    print(\"Expected shape:\", dat.shape[0],dat.shape[1]+nb_dat.shape[1]-2,\" Resulting shape:\",combined.shape)\n",
    "    print(\"--------------------------\")\n",
    "    \n",
    "print(\"Succesfully combined nb cell counts to main data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in: 12 hema files\n",
      "Extracted: 12 hema files\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Centroid_X</th>\n",
       "      <th>Centroid_Y</th>\n",
       "      <th>Hematoxylin: Nucleus: Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8351.9</td>\n",
       "      <td>478.67</td>\n",
       "      <td>0.1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8250.8</td>\n",
       "      <td>479.90</td>\n",
       "      <td>0.1938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8300.6</td>\n",
       "      <td>479.33</td>\n",
       "      <td>0.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8294.8</td>\n",
       "      <td>487.18</td>\n",
       "      <td>0.2580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8230.7</td>\n",
       "      <td>497.89</td>\n",
       "      <td>0.2701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Centroid_X  Centroid_Y  Hematoxylin: Nucleus: Mean\n",
       "0      8351.9      478.67                      0.1949\n",
       "1      8250.8      479.90                      0.1938\n",
       "2      8300.6      479.33                      0.2000\n",
       "3      8294.8      487.18                      0.2580\n",
       "4      8230.7      497.89                      0.2701"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 2) Importing hema nucleus mean of all detected cells & location coordinates \n",
    "# Variables: hema_mylist, hema_inputs \n",
    "\n",
    "## obtaining list of files \n",
    "with open(\"D:/Tanrada_classification/imbalance_cortical_training/hema/annotated_hema_SD.txt\") as f: \n",
    "    hema_mylist= f.read().splitlines()\n",
    "    \n",
    "print(\"Read in:\",len(hema_mylist),\"hema files\")    \n",
    "\n",
    "\n",
    "## 4) reading in all those files \n",
    "hema_inputs = [] \n",
    "for i in hema_mylist: \n",
    "    dat = pd.read_csv('D:/Tanrada_classification/imbalance_cortical_training/hema/'+i,sep=\",\")\n",
    "    dat.columns.values[0] = 'Centroid_X' # To fix naming inconsistency problem \n",
    "    dat.columns.values[1] = 'Centroid_Y'\n",
    "    hema_inputs.append(dat)\n",
    "\n",
    "print(\"Extracted:\",len(hema_inputs),\"hema files\")  \n",
    "\n",
    "#Example \n",
    "hema_inputs[2].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mylist & nb_list matched?: True\n",
      "mylist & hema_list matched?: True\n"
     ]
    }
   ],
   "source": [
    "# Checking if filenames & order of them from mylist, nb_mylist & hema_mylist match\n",
    "x_nb = [i[1:7] for i in nb_mylist]\n",
    "x = [i[0:6] for i in mylist]\n",
    "x_h = [i[0:6] for i in hema_mylist]\n",
    "print(\"mylist & nb_list matched?:\", x==x_nb)\n",
    "print(\"mylist & hema_list matched?:\",x==x_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalising hematoxlyin per brain side & discard top 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  No. of cells with normalised Hema >1: 4848 from 485605 detected cells\n",
      "1  No. of cells with normalised Hema >1: 2720 from 272349 detected cells\n",
      "2  No. of cells with normalised Hema >1: 4104 from 410302 detected cells\n",
      "3  No. of cells with normalised Hema >1: 4132 from 413521 detected cells\n",
      "4  No. of cells with normalised Hema >1: 4415 from 442130 detected cells\n",
      "5  No. of cells with normalised Hema >1: 4736 from 475306 detected cells\n",
      "6  No. of cells with normalised Hema >1: 3577 from 357603 detected cells\n",
      "7  No. of cells with normalised Hema >1: 5144 from 516132 detected cells\n",
      "8  No. of cells with normalised Hema >1: 2964 from 296324 detected cells\n",
      "9  No. of cells with normalised Hema >1: 3314 from 331459 detected cells\n",
      "10  No. of cells with normalised Hema >1: 5301 from 530977 detected cells\n",
      "11  No. of cells with normalised Hema >1: 3642 from 364677 detected cells\n"
     ]
    }
   ],
   "source": [
    "### 1) Get instances needed to be remove for each slide\n",
    "#Variables: hema_to_remove, hema_inputs \n",
    "hema_to_remove = [] \n",
    "for h in hema_inputs: \n",
    "    h2 = h.copy() \n",
    "    hema = h2['Hematoxylin: Nucleus: Mean']\n",
    "    threshold = hema.quantile(0.99)\n",
    "    hema_norm = hema/threshold \n",
    "    h2['Hematoxylin: Nucleus: Mean'] = hema_norm \n",
    "    h2 = h2[h2['Hematoxylin: Nucleus: Mean']>1] # to select instances need removing (keep <=1)\n",
    "    hema_to_remove.append(h2)\n",
    "\n",
    "for i in range(0,len(hema_to_remove)): \n",
    "    print(i, \" No. of cells with normalised Hema >1:\",len(hema_to_remove[i]), \"from\", len(hema_inputs[i]),\"detected cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703484_cell_annotations_SD.csv : 7 cells removed\n",
      "721701_cell_annotations_SD.csv : 3 cells removed\n",
      "721735_cell_annotations_SD.csv : 5 cells removed\n",
      "721771_cell_annotations.csv : 6 cells removed\n",
      "721856_cell_annotations_SD.csv : 1 cells removed\n",
      "722215_cell_annotations_SD.csv : 2 cells removed\n",
      "755472_cell_annotations_SD.csv : 2 cells removed\n",
      "755480_cell_annotations.csv : 5 cells removed\n",
      "755481_cell_annotations.csv : 4 cells removed\n",
      "755485_cell_annotations_SD.csv : 0 cells removed\n",
      "755486_cell_annotations_SD.csv : 3 cells removed\n",
      "755525_cell_annotations_SD.csv : 1 cells removed\n"
     ]
    }
   ],
   "source": [
    "## 2) Discarding annotated cells if they fit the criteria above \n",
    "#Variables: cleaned_inputs, removed  \n",
    "\n",
    "cleaned_inputs = []\n",
    "removed = [] \n",
    "for n in range(0,(len(inputs_))): #looping through annotated % hema (detected) slides \n",
    "    \n",
    "    i = inputs_[n] #annotated cells \n",
    "    h = hema_to_remove[n] #cells we need to remove, may or may not contain annotated cells \n",
    "    \n",
    "    #Find cells that exist in both 'i' & 'h' = cells we want to remove \n",
    "    to_remove = i.merge(h,on=['Centroid_X','Centroid_Y'],how='inner',validate='1:1')\n",
    "    \n",
    "    #Find cells that only exist in 'i' but not in 'h' = cells we want to retain \n",
    "    to_retain = i.merge(h,on=['Centroid_X','Centroid_Y'],how='left',indicator=True,validate='1:1')\n",
    "    \n",
    "    #Extract cells we want to retain \n",
    "    retained = i[to_retain['_merge']=='left_only']\n",
    "    \n",
    "    cleaned_inputs.append(retained)\n",
    "    removed.append(to_remove)\n",
    "    print(mylist[n],\":\",i.shape[0]-retained.shape[0],\"cells removed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(566, 353)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Image',\n",
       " 'Name',\n",
       " 'Class',\n",
       " 'Parent',\n",
       " 'ROI',\n",
       " 'Centroid_X',\n",
       " 'Centroid_Y',\n",
       " 'Detection probability',\n",
       " 'Nucleus: Area ¬µm^2',\n",
       " 'Nucleus: Length ¬µm',\n",
       " 'Nucleus: Circularity',\n",
       " 'Nucleus: Solidity',\n",
       " 'Nucleus: Max diameter ¬µm',\n",
       " 'Nucleus: Min diameter ¬µm',\n",
       " 'Cell: Area ¬µm^2',\n",
       " 'Cell: Length ¬µm',\n",
       " 'Cell: Circularity',\n",
       " 'Cell: Solidity',\n",
       " 'Cell: Max diameter ¬µm',\n",
       " 'Cell: Min diameter ¬µm',\n",
       " 'Nucleus/Cell area ratio',\n",
       " 'Hematoxylin: Nucleus: Mean',\n",
       " 'Hematoxylin: Nucleus: Median',\n",
       " 'Hematoxylin: Nucleus: Min',\n",
       " 'Hematoxylin: Nucleus: Max',\n",
       " 'Hematoxylin: Nucleus: Std.Dev.',\n",
       " 'Hematoxylin: Cytoplasm: Mean',\n",
       " 'Hematoxylin: Cytoplasm: Median',\n",
       " 'Hematoxylin: Cytoplasm: Min',\n",
       " 'Hematoxylin: Cytoplasm: Max',\n",
       " 'Hematoxylin: Cytoplasm: Std.Dev.',\n",
       " 'Hematoxylin: Membrane: Mean',\n",
       " 'Hematoxylin: Membrane: Median',\n",
       " 'Hematoxylin: Membrane: Min',\n",
       " 'Hematoxylin: Membrane: Max',\n",
       " 'Hematoxylin: Membrane: Std.Dev.',\n",
       " 'Hematoxylin: Cell: Mean',\n",
       " 'Hematoxylin: Cell: Median',\n",
       " 'Hematoxylin: Cell: Min',\n",
       " 'Hematoxylin: Cell: Max',\n",
       " 'Hematoxylin: Cell: Std.Dev.',\n",
       " 'DAB: Nucleus: Mean',\n",
       " 'DAB: Nucleus: Median',\n",
       " 'DAB: Nucleus: Min',\n",
       " 'DAB: Nucleus: Max',\n",
       " 'DAB: Nucleus: Std.Dev.',\n",
       " 'DAB: Cytoplasm: Mean',\n",
       " 'DAB: Cytoplasm: Median',\n",
       " 'DAB: Cytoplasm: Min',\n",
       " 'DAB: Cytoplasm: Max',\n",
       " 'DAB: Cytoplasm: Std.Dev.',\n",
       " 'DAB: Membrane: Mean',\n",
       " 'DAB: Membrane: Median',\n",
       " 'DAB: Membrane: Min',\n",
       " 'DAB: Membrane: Max',\n",
       " 'DAB: Membrane: Std.Dev.',\n",
       " 'DAB: Cell: Mean',\n",
       " 'DAB: Cell: Median',\n",
       " 'DAB: Cell: Min',\n",
       " 'DAB: Cell: Max',\n",
       " 'DAB: Cell: Std.Dev.',\n",
       " 'tau: Necrosis area µm^2',\n",
       " 'Smoothed: 10 µm: Detection probability',\n",
       " 'Smoothed: 10 µm: Nucleus: Area µm^2',\n",
       " 'Smoothed: 10 µm: Nucleus: Length µm',\n",
       " 'Smoothed: 10 µm: Nucleus: Circularity',\n",
       " 'Smoothed: 10 µm: Nucleus: Solidity',\n",
       " 'Smoothed: 10 µm: Nucleus: Max diameter µm',\n",
       " 'Smoothed: 10 µm: Nucleus: Min diameter µm',\n",
       " 'Smoothed: 10 µm: Cell: Area µm^2',\n",
       " 'Smoothed: 10 µm: Cell: Length µm',\n",
       " 'Smoothed: 10 µm: Cell: Circularity',\n",
       " 'Smoothed: 10 µm: Cell: Solidity',\n",
       " 'Smoothed: 10 µm: Cell: Max diameter µm',\n",
       " 'Smoothed: 10 µm: Cell: Min diameter µm',\n",
       " 'Smoothed: 10 µm: Nucleus/Cell area ratio',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Nucleus: Mean',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Nucleus: Median',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Nucleus: Min',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Nucleus: Max',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Nucleus: Std.Dev.',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Cytoplasm: Mean',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Cytoplasm: Median',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Cytoplasm: Min',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Cytoplasm: Max',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Cytoplasm: Std.Dev.',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Membrane: Mean',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Membrane: Median',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Membrane: Min',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Membrane: Max',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Membrane: Std.Dev.',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Cell: Mean',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Cell: Median',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Cell: Min',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Cell: Max',\n",
       " 'Smoothed: 10 µm: Hematoxylin: Cell: Std.Dev.',\n",
       " 'Smoothed: 10 µm: DAB: Nucleus: Mean',\n",
       " 'Smoothed: 10 µm: DAB: Nucleus: Median',\n",
       " 'Smoothed: 10 µm: DAB: Nucleus: Min',\n",
       " 'Smoothed: 10 µm: DAB: Nucleus: Max',\n",
       " 'Smoothed: 10 µm: DAB: Nucleus: Std.Dev.',\n",
       " 'Smoothed: 10 µm: DAB: Cytoplasm: Mean',\n",
       " 'Smoothed: 10 µm: DAB: Cytoplasm: Median',\n",
       " 'Smoothed: 10 µm: DAB: Cytoplasm: Min',\n",
       " 'Smoothed: 10 µm: DAB: Cytoplasm: Max',\n",
       " 'Smoothed: 10 µm: DAB: Cytoplasm: Std.Dev.',\n",
       " 'Smoothed: 10 µm: DAB: Membrane: Mean',\n",
       " 'Smoothed: 10 µm: DAB: Membrane: Median',\n",
       " 'Smoothed: 10 µm: DAB: Membrane: Min',\n",
       " 'Smoothed: 10 µm: DAB: Membrane: Max',\n",
       " 'Smoothed: 10 µm: DAB: Membrane: Std.Dev.',\n",
       " 'Smoothed: 10 µm: DAB: Cell: Mean',\n",
       " 'Smoothed: 10 µm: DAB: Cell: Median',\n",
       " 'Smoothed: 10 µm: DAB: Cell: Min',\n",
       " 'Smoothed: 10 µm: DAB: Cell: Max',\n",
       " 'Smoothed: 10 µm: DAB: Cell: Std.Dev.',\n",
       " 'Smoothed: 10 µm: tau: Necrosis area µm^2',\n",
       " 'Smoothed: 10 µm: Nearby detection counts',\n",
       " 'Smoothed: 20 µm: Detection probability',\n",
       " 'Smoothed: 20 µm: Nucleus: Area µm^2',\n",
       " 'Smoothed: 20 µm: Nucleus: Length µm',\n",
       " 'Smoothed: 20 µm: Nucleus: Circularity',\n",
       " 'Smoothed: 20 µm: Nucleus: Solidity',\n",
       " 'Smoothed: 20 µm: Nucleus: Max diameter µm',\n",
       " 'Smoothed: 20 µm: Nucleus: Min diameter µm',\n",
       " 'Smoothed: 20 µm: Cell: Area µm^2',\n",
       " 'Smoothed: 20 µm: Cell: Length µm',\n",
       " 'Smoothed: 20 µm: Cell: Circularity',\n",
       " 'Smoothed: 20 µm: Cell: Solidity',\n",
       " 'Smoothed: 20 µm: Cell: Max diameter µm',\n",
       " 'Smoothed: 20 µm: Cell: Min diameter µm',\n",
       " 'Smoothed: 20 µm: Nucleus/Cell area ratio',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Nucleus: Mean',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Nucleus: Median',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Nucleus: Min',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Nucleus: Max',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Nucleus: Std.Dev.',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Cytoplasm: Mean',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Cytoplasm: Median',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Cytoplasm: Min',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Cytoplasm: Max',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Cytoplasm: Std.Dev.',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Membrane: Mean',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Membrane: Median',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Membrane: Min',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Membrane: Max',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Membrane: Std.Dev.',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Cell: Mean',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Cell: Median',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Cell: Min',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Cell: Max',\n",
       " 'Smoothed: 20 µm: Hematoxylin: Cell: Std.Dev.',\n",
       " 'Smoothed: 20 µm: DAB: Nucleus: Mean',\n",
       " 'Smoothed: 20 µm: DAB: Nucleus: Median',\n",
       " 'Smoothed: 20 µm: DAB: Nucleus: Min',\n",
       " 'Smoothed: 20 µm: DAB: Nucleus: Max',\n",
       " 'Smoothed: 20 µm: DAB: Nucleus: Std.Dev.',\n",
       " 'Smoothed: 20 µm: DAB: Cytoplasm: Mean',\n",
       " 'Smoothed: 20 µm: DAB: Cytoplasm: Median',\n",
       " 'Smoothed: 20 µm: DAB: Cytoplasm: Min',\n",
       " 'Smoothed: 20 µm: DAB: Cytoplasm: Max',\n",
       " 'Smoothed: 20 µm: DAB: Cytoplasm: Std.Dev.',\n",
       " 'Smoothed: 20 µm: DAB: Membrane: Mean',\n",
       " 'Smoothed: 20 µm: DAB: Membrane: Median',\n",
       " 'Smoothed: 20 µm: DAB: Membrane: Min',\n",
       " 'Smoothed: 20 µm: DAB: Membrane: Max',\n",
       " 'Smoothed: 20 µm: DAB: Membrane: Std.Dev.',\n",
       " 'Smoothed: 20 µm: DAB: Cell: Mean',\n",
       " 'Smoothed: 20 µm: DAB: Cell: Median',\n",
       " 'Smoothed: 20 µm: DAB: Cell: Min',\n",
       " 'Smoothed: 20 µm: DAB: Cell: Max',\n",
       " 'Smoothed: 20 µm: DAB: Cell: Std.Dev.',\n",
       " 'Smoothed: 20 µm: tau: Necrosis area µm^2',\n",
       " 'Smoothed: 20 µm: Nearby detection counts',\n",
       " 'Smoothed: 30 µm: Detection probability',\n",
       " 'Smoothed: 30 µm: Nucleus: Area µm^2',\n",
       " 'Smoothed: 30 µm: Nucleus: Length µm',\n",
       " 'Smoothed: 30 µm: Nucleus: Circularity',\n",
       " 'Smoothed: 30 µm: Nucleus: Solidity',\n",
       " 'Smoothed: 30 µm: Nucleus: Max diameter µm',\n",
       " 'Smoothed: 30 µm: Nucleus: Min diameter µm',\n",
       " 'Smoothed: 30 µm: Cell: Area µm^2',\n",
       " 'Smoothed: 30 µm: Cell: Length µm',\n",
       " 'Smoothed: 30 µm: Cell: Circularity',\n",
       " 'Smoothed: 30 µm: Cell: Solidity',\n",
       " 'Smoothed: 30 µm: Cell: Max diameter µm',\n",
       " 'Smoothed: 30 µm: Cell: Min diameter µm',\n",
       " 'Smoothed: 30 µm: Nucleus/Cell area ratio',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Nucleus: Mean',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Nucleus: Median',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Nucleus: Min',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Nucleus: Max',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Nucleus: Std.Dev.',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Cytoplasm: Mean',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Cytoplasm: Median',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Cytoplasm: Min',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Cytoplasm: Max',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Cytoplasm: Std.Dev.',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Membrane: Mean',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Membrane: Median',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Membrane: Min',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Membrane: Max',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Membrane: Std.Dev.',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Cell: Mean',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Cell: Median',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Cell: Min',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Cell: Max',\n",
       " 'Smoothed: 30 µm: Hematoxylin: Cell: Std.Dev.',\n",
       " 'Smoothed: 30 µm: DAB: Nucleus: Mean',\n",
       " 'Smoothed: 30 µm: DAB: Nucleus: Median',\n",
       " 'Smoothed: 30 µm: DAB: Nucleus: Min',\n",
       " 'Smoothed: 30 µm: DAB: Nucleus: Max',\n",
       " 'Smoothed: 30 µm: DAB: Nucleus: Std.Dev.',\n",
       " 'Smoothed: 30 µm: DAB: Cytoplasm: Mean',\n",
       " 'Smoothed: 30 µm: DAB: Cytoplasm: Median',\n",
       " 'Smoothed: 30 µm: DAB: Cytoplasm: Min',\n",
       " 'Smoothed: 30 µm: DAB: Cytoplasm: Max',\n",
       " 'Smoothed: 30 µm: DAB: Cytoplasm: Std.Dev.',\n",
       " 'Smoothed: 30 µm: DAB: Membrane: Mean',\n",
       " 'Smoothed: 30 µm: DAB: Membrane: Median',\n",
       " 'Smoothed: 30 µm: DAB: Membrane: Min',\n",
       " 'Smoothed: 30 µm: DAB: Membrane: Max',\n",
       " 'Smoothed: 30 µm: DAB: Membrane: Std.Dev.',\n",
       " 'Smoothed: 30 µm: DAB: Cell: Mean',\n",
       " 'Smoothed: 30 µm: DAB: Cell: Median',\n",
       " 'Smoothed: 30 µm: DAB: Cell: Min',\n",
       " 'Smoothed: 30 µm: DAB: Cell: Max',\n",
       " 'Smoothed: 30 µm: DAB: Cell: Std.Dev.',\n",
       " 'Smoothed: 30 µm: tau: Necrosis area µm^2',\n",
       " 'Smoothed: 30 µm: Nearby detection counts',\n",
       " 'Smoothed: 40 µm: Detection probability',\n",
       " 'Smoothed: 40 µm: Nucleus: Area µm^2',\n",
       " 'Smoothed: 40 µm: Nucleus: Length µm',\n",
       " 'Smoothed: 40 µm: Nucleus: Circularity',\n",
       " 'Smoothed: 40 µm: Nucleus: Solidity',\n",
       " 'Smoothed: 40 µm: Nucleus: Max diameter µm',\n",
       " 'Smoothed: 40 µm: Nucleus: Min diameter µm',\n",
       " 'Smoothed: 40 µm: Cell: Area µm^2',\n",
       " 'Smoothed: 40 µm: Cell: Length µm',\n",
       " 'Smoothed: 40 µm: Cell: Circularity',\n",
       " 'Smoothed: 40 µm: Cell: Solidity',\n",
       " 'Smoothed: 40 µm: Cell: Max diameter µm',\n",
       " 'Smoothed: 40 µm: Cell: Min diameter µm',\n",
       " 'Smoothed: 40 µm: Nucleus/Cell area ratio',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Nucleus: Mean',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Nucleus: Median',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Nucleus: Min',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Nucleus: Max',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Nucleus: Std.Dev.',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Cytoplasm: Mean',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Cytoplasm: Median',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Cytoplasm: Min',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Cytoplasm: Max',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Cytoplasm: Std.Dev.',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Membrane: Mean',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Membrane: Median',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Membrane: Min',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Membrane: Max',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Membrane: Std.Dev.',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Cell: Mean',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Cell: Median',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Cell: Min',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Cell: Max',\n",
       " 'Smoothed: 40 µm: Hematoxylin: Cell: Std.Dev.',\n",
       " 'Smoothed: 40 µm: DAB: Nucleus: Mean',\n",
       " 'Smoothed: 40 µm: DAB: Nucleus: Median',\n",
       " 'Smoothed: 40 µm: DAB: Nucleus: Min',\n",
       " 'Smoothed: 40 µm: DAB: Nucleus: Max',\n",
       " 'Smoothed: 40 µm: DAB: Nucleus: Std.Dev.',\n",
       " 'Smoothed: 40 µm: DAB: Cytoplasm: Mean',\n",
       " 'Smoothed: 40 µm: DAB: Cytoplasm: Median',\n",
       " 'Smoothed: 40 µm: DAB: Cytoplasm: Min',\n",
       " 'Smoothed: 40 µm: DAB: Cytoplasm: Max',\n",
       " 'Smoothed: 40 µm: DAB: Cytoplasm: Std.Dev.',\n",
       " 'Smoothed: 40 µm: DAB: Membrane: Mean',\n",
       " 'Smoothed: 40 µm: DAB: Membrane: Median',\n",
       " 'Smoothed: 40 µm: DAB: Membrane: Min',\n",
       " 'Smoothed: 40 µm: DAB: Membrane: Max',\n",
       " 'Smoothed: 40 µm: DAB: Membrane: Std.Dev.',\n",
       " 'Smoothed: 40 µm: DAB: Cell: Mean',\n",
       " 'Smoothed: 40 µm: DAB: Cell: Median',\n",
       " 'Smoothed: 40 µm: DAB: Cell: Min',\n",
       " 'Smoothed: 40 µm: DAB: Cell: Max',\n",
       " 'Smoothed: 40 µm: DAB: Cell: Std.Dev.',\n",
       " 'Smoothed: 40 µm: tau: Necrosis area µm^2',\n",
       " 'Smoothed: 40 µm: Nearby detection counts',\n",
       " 'Smoothed: 50 µm: Detection probability',\n",
       " 'Smoothed: 50 µm: Nucleus: Area µm^2',\n",
       " 'Smoothed: 50 µm: Nucleus: Length µm',\n",
       " 'Smoothed: 50 µm: Nucleus: Circularity',\n",
       " 'Smoothed: 50 µm: Nucleus: Solidity',\n",
       " 'Smoothed: 50 µm: Nucleus: Max diameter µm',\n",
       " 'Smoothed: 50 µm: Nucleus: Min diameter µm',\n",
       " 'Smoothed: 50 µm: Cell: Area µm^2',\n",
       " 'Smoothed: 50 µm: Cell: Length µm',\n",
       " 'Smoothed: 50 µm: Cell: Circularity',\n",
       " 'Smoothed: 50 µm: Cell: Solidity',\n",
       " 'Smoothed: 50 µm: Cell: Max diameter µm',\n",
       " 'Smoothed: 50 µm: Cell: Min diameter µm',\n",
       " 'Smoothed: 50 µm: Nucleus/Cell area ratio',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Nucleus: Mean',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Nucleus: Median',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Nucleus: Min',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Nucleus: Max',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Nucleus: Std.Dev.',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Cytoplasm: Mean',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Cytoplasm: Median',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Cytoplasm: Min',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Cytoplasm: Max',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Cytoplasm: Std.Dev.',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Membrane: Mean',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Membrane: Median',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Membrane: Min',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Membrane: Max',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Membrane: Std.Dev.',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Cell: Mean',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Cell: Median',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Cell: Min',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Cell: Max',\n",
       " 'Smoothed: 50 µm: Hematoxylin: Cell: Std.Dev.',\n",
       " 'Smoothed: 50 µm: DAB: Nucleus: Mean',\n",
       " 'Smoothed: 50 µm: DAB: Nucleus: Median',\n",
       " 'Smoothed: 50 µm: DAB: Nucleus: Min',\n",
       " 'Smoothed: 50 µm: DAB: Nucleus: Max',\n",
       " 'Smoothed: 50 µm: DAB: Nucleus: Std.Dev.',\n",
       " 'Smoothed: 50 µm: DAB: Cytoplasm: Mean',\n",
       " 'Smoothed: 50 µm: DAB: Cytoplasm: Median',\n",
       " 'Smoothed: 50 µm: DAB: Cytoplasm: Min',\n",
       " 'Smoothed: 50 µm: DAB: Cytoplasm: Max',\n",
       " 'Smoothed: 50 µm: DAB: Cytoplasm: Std.Dev.',\n",
       " 'Smoothed: 50 µm: DAB: Membrane: Mean',\n",
       " 'Smoothed: 50 µm: DAB: Membrane: Median',\n",
       " 'Smoothed: 50 µm: DAB: Membrane: Min',\n",
       " 'Smoothed: 50 µm: DAB: Membrane: Max',\n",
       " 'Smoothed: 50 µm: DAB: Membrane: Std.Dev.',\n",
       " 'Smoothed: 50 µm: DAB: Cell: Mean',\n",
       " 'Smoothed: 50 µm: DAB: Cell: Median',\n",
       " 'Smoothed: 50 µm: DAB: Cell: Min',\n",
       " 'Smoothed: 50 µm: DAB: Cell: Max',\n",
       " 'Smoothed: 50 µm: DAB: Cell: Std.Dev.',\n",
       " 'Smoothed: 50 µm: tau: Necrosis area µm^2',\n",
       " 'Smoothed: 50 µm: Nearby detection counts',\n",
       " 'NN_10_um',\n",
       " 'NN_20_um',\n",
       " 'NN_30_um',\n",
       " 'NN_40_um',\n",
       " 'NN_50_um',\n",
       " 'NN_60_um',\n",
       " 'NN_70_um',\n",
       " 'NN_80_um',\n",
       " 'NN_90_um',\n",
       " 'NN_100_um',\n",
       " 'Image_name']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cleaned_inputs[0].shape)\n",
    "list(cleaned_inputs[0].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing DAB & tau necrosis & Image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial n_features: 353 , After removal: 51\n",
      "Initial n_features: 353 , After removal: 51\n",
      "Initial n_features: 353 , After removal: 51\n",
      "Initial n_features: 73 , After removal: 51\n",
      "Initial n_features: 353 , After removal: 51\n",
      "Initial n_features: 353 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n"
     ]
    }
   ],
   "source": [
    "## Removing DAB & tau necrosis ** making sure same dimension\n",
    "cleaned_inputs_ = []\n",
    "for i in cleaned_inputs:\n",
    "    # To remove all DAB features\n",
    "    to_drop1 = list(i.filter(regex='DAB'))\n",
    "    dat1 = i[i.columns.drop(to_drop1)]\n",
    "    # To remove tau necrosis features\n",
    "    to_drop2 = list(dat1.filter(regex='tau'))\n",
    "    dat2= dat1[dat1.columns.drop(to_drop2)]\n",
    "    # To remove Smoothed ****\n",
    "    to_drop3 = list(dat2.filter(regex='Smoothed'))\n",
    "    dat3= dat2[dat2.columns.drop(to_drop3)]\n",
    "    #Remove Image_name\n",
    "    dat = dat3.drop(columns=['Image_name'])\n",
    "    \n",
    "    cleaned_inputs_.append(dat)\n",
    "    print(\"Initial n_features:\",i.shape[1], \", After removal:\", dat.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting the slides together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4717, 51)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Class</th>\n",
       "      <th>Centroid_X</th>\n",
       "      <th>Centroid_Y</th>\n",
       "      <th>Detection probability</th>\n",
       "      <th>Nucleus: Area ¬µm^2</th>\n",
       "      <th>Nucleus: Length ¬µm</th>\n",
       "      <th>Nucleus: Circularity</th>\n",
       "      <th>Nucleus: Solidity</th>\n",
       "      <th>Nucleus: Max diameter ¬µm</th>\n",
       "      <th>...</th>\n",
       "      <th>NN_10_um</th>\n",
       "      <th>NN_20_um</th>\n",
       "      <th>NN_30_um</th>\n",
       "      <th>NN_40_um</th>\n",
       "      <th>NN_50_um</th>\n",
       "      <th>NN_60_um</th>\n",
       "      <th>NN_70_um</th>\n",
       "      <th>NN_80_um</th>\n",
       "      <th>NN_90_um</th>\n",
       "      <th>NN_100_um</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>703484.svs</td>\n",
       "      <td>fragmented</td>\n",
       "      <td>2758.4</td>\n",
       "      <td>5064.2</td>\n",
       "      <td>0.7102</td>\n",
       "      <td>10.4438</td>\n",
       "      <td>11.7588</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>4.2279</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>703484.svs</td>\n",
       "      <td>Epithelial</td>\n",
       "      <td>2865.6</td>\n",
       "      <td>5210.4</td>\n",
       "      <td>0.7737</td>\n",
       "      <td>34.4719</td>\n",
       "      <td>24.9365</td>\n",
       "      <td>0.6966</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>10.6183</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>703484.svs</td>\n",
       "      <td>Epithelial</td>\n",
       "      <td>2929.0</td>\n",
       "      <td>5210.6</td>\n",
       "      <td>0.7337</td>\n",
       "      <td>23.0844</td>\n",
       "      <td>20.5225</td>\n",
       "      <td>0.6888</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>8.7795</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>703484.svs</td>\n",
       "      <td>Ignore</td>\n",
       "      <td>2736.6</td>\n",
       "      <td>5224.5</td>\n",
       "      <td>0.5949</td>\n",
       "      <td>31.9419</td>\n",
       "      <td>20.3826</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>7.1633</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>703484.svs</td>\n",
       "      <td>fragmented</td>\n",
       "      <td>5262.3</td>\n",
       "      <td>5460.8</td>\n",
       "      <td>0.7159</td>\n",
       "      <td>9.8636</td>\n",
       "      <td>13.0301</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>0.9790</td>\n",
       "      <td>5.4442</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image       Class  Centroid_X  Centroid_Y  Detection probability  \\\n",
       "0  703484.svs  fragmented      2758.4      5064.2                 0.7102   \n",
       "1  703484.svs  Epithelial      2865.6      5210.4                 0.7737   \n",
       "2  703484.svs  Epithelial      2929.0      5210.6                 0.7337   \n",
       "3  703484.svs      Ignore      2736.6      5224.5                 0.5949   \n",
       "4  703484.svs  fragmented      5262.3      5460.8                 0.7159   \n",
       "\n",
       "   Nucleus: Area ¬µm^2  Nucleus: Length ¬µm  Nucleus: Circularity  \\\n",
       "0              10.4438              11.7588                0.9492   \n",
       "1              34.4719              24.9365                0.6966   \n",
       "2              23.0844              20.5225                0.6888   \n",
       "3              31.9419              20.3826                0.9662   \n",
       "4               9.8636              13.0301                0.7300   \n",
       "\n",
       "   Nucleus: Solidity  Nucleus: Max diameter ¬µm  ...  NN_10_um  NN_20_um  \\\n",
       "0             1.0000                     4.2279  ...         1         2   \n",
       "1             0.9739                    10.6183  ...         0         1   \n",
       "2             0.9821                     8.7795  ...         0         0   \n",
       "3             1.0000                     7.1633  ...         0         0   \n",
       "4             0.9790                     5.4442  ...         1         4   \n",
       "\n",
       "   NN_30_um  NN_40_um  NN_50_um  NN_60_um  NN_70_um  NN_80_um  NN_90_um  \\\n",
       "0         3         5         7        10        16        21        25   \n",
       "1         3         3         4         7        14        25        32   \n",
       "2         1         2         5         5        10        15        18   \n",
       "3         0         1         7        13        15        20        28   \n",
       "4         7         8        13        16        17        19        22   \n",
       "\n",
       "   NN_100_um  \n",
       "0         36  \n",
       "1         35  \n",
       "2         25  \n",
       "3         35  \n",
       "4         30  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Variables: labelled_orig, labelled_data \n",
    "#1) Put the slides together\n",
    "\n",
    "labelled_orig = pd.concat(cleaned_inputs_)\n",
    "print(labelled_orig.shape)\n",
    "\n",
    "# 2) Extract relevant columns \n",
    "dat = labelled_orig.drop(columns=['Name','Parent','ROI']) \n",
    "dat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Image',\n",
       " 'Class',\n",
       " 'Centroid_X',\n",
       " 'Centroid_Y',\n",
       " 'Detection probability',\n",
       " 'Nucleus: Area ¬µm^2',\n",
       " 'Nucleus: Length ¬µm',\n",
       " 'Nucleus: Circularity',\n",
       " 'Nucleus: Solidity',\n",
       " 'Nucleus: Max diameter ¬µm',\n",
       " 'Nucleus: Min diameter ¬µm',\n",
       " 'Cell: Area ¬µm^2',\n",
       " 'Cell: Length ¬µm',\n",
       " 'Cell: Circularity',\n",
       " 'Cell: Solidity',\n",
       " 'Cell: Max diameter ¬µm',\n",
       " 'Cell: Min diameter ¬µm',\n",
       " 'Nucleus/Cell area ratio',\n",
       " 'Hematoxylin: Nucleus: Mean',\n",
       " 'Hematoxylin: Nucleus: Median',\n",
       " 'Hematoxylin: Nucleus: Min',\n",
       " 'Hematoxylin: Nucleus: Max',\n",
       " 'Hematoxylin: Nucleus: Std.Dev.',\n",
       " 'Hematoxylin: Cytoplasm: Mean',\n",
       " 'Hematoxylin: Cytoplasm: Median',\n",
       " 'Hematoxylin: Cytoplasm: Min',\n",
       " 'Hematoxylin: Cytoplasm: Max',\n",
       " 'Hematoxylin: Cytoplasm: Std.Dev.',\n",
       " 'Hematoxylin: Membrane: Mean',\n",
       " 'Hematoxylin: Membrane: Median',\n",
       " 'Hematoxylin: Membrane: Min',\n",
       " 'Hematoxylin: Membrane: Max',\n",
       " 'Hematoxylin: Membrane: Std.Dev.',\n",
       " 'Hematoxylin: Cell: Mean',\n",
       " 'Hematoxylin: Cell: Median',\n",
       " 'Hematoxylin: Cell: Min',\n",
       " 'Hematoxylin: Cell: Max',\n",
       " 'Hematoxylin: Cell: Std.Dev.',\n",
       " 'NN_10_um',\n",
       " 'NN_20_um',\n",
       " 'NN_30_um',\n",
       " 'NN_40_um',\n",
       " 'NN_50_um',\n",
       " 'NN_60_um',\n",
       " 'NN_70_um',\n",
       " 'NN_80_um',\n",
       " 'NN_90_um',\n",
       " 'NN_100_um']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dat.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting relevant cell classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 4717 cells\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Oligo_New         461\n",
       "Neuron_new        445\n",
       "Neuron_New        440\n",
       "Ignore            356\n",
       "Oligo_new         331\n",
       "Epithelial        330\n",
       "Epithelial_new    310\n",
       "fragmented        304\n",
       "Neuron            302\n",
       "Astro             297\n",
       "Oligo             295\n",
       "Epithelial_New    247\n",
       "Ignore_New        201\n",
       "Ignore_new        143\n",
       "Astro_New          97\n",
       "Astro_new          82\n",
       "Stardist_error     35\n",
       "Tumor              16\n",
       "fragmented_new     15\n",
       "Fragmented_New     10\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Check no. of cells / class of our data\n",
    "print(\"Total\",sum(dat['Class'].value_counts()),\"cells\")\n",
    "dat['Class'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neuron_new        885\n",
       "oligo_new         792\n",
       "epithelial_new    557\n",
       "ignore            356\n",
       "ignore_new        344\n",
       "epithelial        330\n",
       "fragmented        304\n",
       "neuron            302\n",
       "astro             297\n",
       "oligo             295\n",
       "astro_new         179\n",
       "stardist_error     35\n",
       "fragmented_new     25\n",
       "tumor              16\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Making all class names lower case - easier for later selection.\n",
    "\n",
    "dat_lower_class = [i.lower() for i in dat['Class']]\n",
    "dat__ = dat.copy()\n",
    "dat__['Class'] = dat_lower_class \n",
    "dat__['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Selecting only relevant cell classes (Using stardist_error instead of ignore_new)\n",
    "orig = dat__.copy()\n",
    "dat_ = dat__[(dat__['Class'] == 'oligo_new') | (dat__['Class'] == 'neuron_new')\n",
    "          | (dat__['Class'] == 'astro_new')| (dat__['Class'] == 'epithelial_new')\n",
    "          | (dat__['Class'] == 'stardist_error')| (dat__['Class'] == 'fragmented_new')]\n",
    "dat_=dat_.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neuron_new        885\n",
       "oligo_new         792\n",
       "epithelial_new    557\n",
       "astro_new         179\n",
       "stardist_error     35\n",
       "fragmented_new     25\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Checking results from 3)\n",
    "dat_['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neuron        885\n",
       "Oligo         792\n",
       "Epithelial    557\n",
       "Astro         179\n",
       "Stardist_e     35\n",
       "Fragmented     25\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) Re-name these classes so it has no '_new'\n",
    "class_new = dat_['Class']\n",
    "x = [(i[0:-4].capitalize()) for i in class_new]\n",
    "#dat = dat_ \n",
    "dat_['Class'] = x\n",
    "dat_['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Neuron    885\n",
       "Oligo     792\n",
       "Others    617\n",
       "Astro     179\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) Group Ignore, Epithelial & Fragmented cells as a single class called 'Others'\n",
    "class_ = dat_['Class']\n",
    "y = ['Others'if i == 'Epithelial' or i == 'Stardist_e' or i == 'Fragmented' else i for i in class_new ]\n",
    "dat = dat_\n",
    "dat['Class'] = y \n",
    "print(dat['Class'].value_counts().sum())\n",
    "dat['Class'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neuron    295.000000\n",
       "Oligo     264.000000\n",
       "Others    205.666667\n",
       "Astro      59.666667\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if cv=3\n",
    "dat['Class'].value_counts()/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neuron    177.0\n",
       "Oligo     158.4\n",
       "Others    123.4\n",
       "Astro      35.8\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if cv=5 \n",
    "dat['Class'].value_counts()/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for any NA in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any NA in the data?:  False\n"
     ]
    }
   ],
   "source": [
    "#checking for NAN \n",
    "## NEW \n",
    "print(\"Any NA in the data?: \",dat.isnull().sum().sum()==1)\n",
    "\n",
    "#dat = dat.dropna()\n",
    "#dat.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train, test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (2473, 47)\n"
     ]
    }
   ],
   "source": [
    "#We are using the entire dataset to train the model, test data will be provided later by Sanne \n",
    "X_train_l = dat.drop(columns=['Class'])\n",
    "X_train = X_train_l.drop(columns=['Image','Centroid_X','Centroid_Y'])\n",
    "print('training data shape:',X_train_l.shape)\n",
    "y_train = dat['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detection probability</th>\n",
       "      <th>Nucleus: Area ¬µm^2</th>\n",
       "      <th>Nucleus: Length ¬µm</th>\n",
       "      <th>Nucleus: Circularity</th>\n",
       "      <th>Nucleus: Solidity</th>\n",
       "      <th>Nucleus: Max diameter ¬µm</th>\n",
       "      <th>Nucleus: Min diameter ¬µm</th>\n",
       "      <th>Cell: Area ¬µm^2</th>\n",
       "      <th>Cell: Length ¬µm</th>\n",
       "      <th>Cell: Circularity</th>\n",
       "      <th>...</th>\n",
       "      <th>NN_10_um</th>\n",
       "      <th>NN_20_um</th>\n",
       "      <th>NN_30_um</th>\n",
       "      <th>NN_40_um</th>\n",
       "      <th>NN_50_um</th>\n",
       "      <th>NN_60_um</th>\n",
       "      <th>NN_70_um</th>\n",
       "      <th>NN_80_um</th>\n",
       "      <th>NN_90_um</th>\n",
       "      <th>NN_100_um</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8929</td>\n",
       "      <td>70.4335</td>\n",
       "      <td>30.1589</td>\n",
       "      <td>0.9731</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.5379</td>\n",
       "      <td>8.6989</td>\n",
       "      <td>258.8036</td>\n",
       "      <td>60.0120</td>\n",
       "      <td>0.9030</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6650</td>\n",
       "      <td>69.3602</td>\n",
       "      <td>30.0618</td>\n",
       "      <td>0.9645</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>10.3145</td>\n",
       "      <td>8.9289</td>\n",
       "      <td>289.4437</td>\n",
       "      <td>60.9183</td>\n",
       "      <td>0.9801</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9025</td>\n",
       "      <td>21.2553</td>\n",
       "      <td>16.7824</td>\n",
       "      <td>0.9483</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.1317</td>\n",
       "      <td>4.5305</td>\n",
       "      <td>132.4307</td>\n",
       "      <td>42.3046</td>\n",
       "      <td>0.9299</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7240</td>\n",
       "      <td>91.2679</td>\n",
       "      <td>34.9913</td>\n",
       "      <td>0.9367</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>12.8068</td>\n",
       "      <td>8.8117</td>\n",
       "      <td>321.6940</td>\n",
       "      <td>65.4879</td>\n",
       "      <td>0.9426</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8682</td>\n",
       "      <td>18.5580</td>\n",
       "      <td>15.5796</td>\n",
       "      <td>0.9608</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>5.4150</td>\n",
       "      <td>4.4888</td>\n",
       "      <td>163.2746</td>\n",
       "      <td>45.8910</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Detection probability  Nucleus: Area ¬µm^2  Nucleus: Length ¬µm  \\\n",
       "0                 0.8929              70.4335              30.1589   \n",
       "1                 0.6650              69.3602              30.0618   \n",
       "2                 0.9025              21.2553              16.7824   \n",
       "3                 0.7240              91.2679              34.9913   \n",
       "4                 0.8682              18.5580              15.5796   \n",
       "\n",
       "   Nucleus: Circularity  Nucleus: Solidity  Nucleus: Max diameter ¬µm  \\\n",
       "0                0.9731             1.0000                    10.5379   \n",
       "1                0.9645             1.0000                    10.3145   \n",
       "2                0.9483             1.0000                     6.1317   \n",
       "3                0.9367             0.9992                    12.8068   \n",
       "4                0.9608             1.0000                     5.4150   \n",
       "\n",
       "   Nucleus: Min diameter ¬µm  Cell: Area ¬µm^2  Cell: Length ¬µm  \\\n",
       "0                     8.6989          258.8036           60.0120   \n",
       "1                     8.9289          289.4437           60.9183   \n",
       "2                     4.5305          132.4307           42.3046   \n",
       "3                     8.8117          321.6940           65.4879   \n",
       "4                     4.4888          163.2746           45.8910   \n",
       "\n",
       "   Cell: Circularity  ...  NN_10_um  NN_20_um  NN_30_um  NN_40_um  NN_50_um  \\\n",
       "0             0.9030  ...         0         2         3         7         9   \n",
       "1             0.9801  ...         0         3         4         8         8   \n",
       "2             0.9299  ...         0         2         4         5        10   \n",
       "3             0.9426  ...         0         2         2         5         8   \n",
       "4             0.9743  ...         0         0         1         7        12   \n",
       "\n",
       "   NN_60_um  NN_70_um  NN_80_um  NN_90_um  NN_100_um  \n",
       "0        12        14        18        28         36  \n",
       "1         9        17        22        27         35  \n",
       "2        13        15        18        22         35  \n",
       "3        14        19        26        33         40  \n",
       "4        15        17        22        28         37  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My own functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for custom classification metrics \n",
    "\n",
    "## Accuracy per class \n",
    "def astro_acc(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    acc_c = cm.diagonal()\n",
    "    return acc_c[0] #astrocytes acc\n",
    "\n",
    "def neuron_acc(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    acc_c = cm.diagonal()\n",
    "    return acc_c[1] #neuron acc\n",
    "\n",
    "def oligo_acc(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    acc_c = cm.diagonal()\n",
    "    return acc_c[2] #oligo acc\n",
    "\n",
    "def others_acc(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    acc_c = cm.diagonal()\n",
    "    return acc_c[3] #ignore acc\n",
    "\n",
    "\n",
    "\n",
    "## Confusion per class: \n",
    "\n",
    "## Astro\n",
    "def A_as_N(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[0][1] # percentage that A is wrongly classified as N   \n",
    "\n",
    "def A_as_O(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[0][2] # percentage that A is wrongly classified as O       \n",
    "\n",
    "\n",
    "def A_as_Others(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[0][3]   \n",
    "\n",
    "##Neurons \n",
    "\n",
    "def N_as_A(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[1][0] \n",
    "\n",
    "def N_as_O(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[1][2] \n",
    "\n",
    "def N_as_Others(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[1][3] \n",
    "\n",
    "\n",
    "## Oligo \n",
    "\n",
    "def O_as_A(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[2][0] \n",
    "\n",
    "def O_as_N(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[2][1] \n",
    "\n",
    "def O_as_Others(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[2][3] \n",
    "\n",
    "## Others \n",
    "\n",
    "def Others_as_A(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[3][0] \n",
    "\n",
    "def Others_as_N(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[3][1] \n",
    "\n",
    "def Others_as_O(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[3][2] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for custom classification metrics: RAW VALUES \n",
    "\n",
    "\n",
    "## Confusion per class: \n",
    "\n",
    "## Astro\n",
    "def A_as_N_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[0][1] # percentage that A is wrongly classified as N   \n",
    "\n",
    "def A_as_O_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[0][2] # percentage that A is wrongly classified as O       \n",
    "\n",
    "\n",
    "def A_as_Others_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[0][3]   \n",
    "\n",
    "##Neurons \n",
    "\n",
    "def N_as_A_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[1][0] \n",
    "\n",
    "def N_as_O_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[1][2] \n",
    "\n",
    "def N_as_Others_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[1][3] \n",
    "\n",
    "\n",
    "## Oligo \n",
    "\n",
    "def O_as_A_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[2][0] \n",
    "\n",
    "def O_as_N_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[2][1] \n",
    "\n",
    "def O_as_Others_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[2][3] \n",
    "\n",
    "## Others \n",
    "\n",
    "def Others_as_A_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[3][0] \n",
    "\n",
    "def Others_as_N_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[3][1] \n",
    "\n",
    "def Others_as_O_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[3][2] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Precision-recall score\n",
    "def precision_recall_auc(clf,X,y):\n",
    "    #Variables\n",
    "    pr_score={}\n",
    "    \n",
    "    #get y prob predictions\n",
    "    y_prob_pred = clf.predict_proba(X)\n",
    "    \n",
    "    #Convert true y name into numerical classes\n",
    "    y_true_numeric = name_to_numeric_classes(y)\n",
    "    \n",
    "    #get number of classes\n",
    "    n_class = list(set(y))\n",
    "    \n",
    "    #create PR curve using OVR approach \n",
    "    for i in range(len(n_class)): # for each class, calculate roc_curve \n",
    "        p, r, thresh = precision_recall_curve(y_true_numeric, y_prob_pred[:,i], pos_label=i)\n",
    "        pr_score[i] = auc(r,p) #recall on x axis, precision on y axis\n",
    "        \n",
    "    #Combine all pr-scores using 'macro' method\n",
    "    pr_auc = mean(pr_score.values())\n",
    "    return pr_auc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDITIONAL FUNCTIONS\n",
    "\n",
    "#FUNCTIONS\n",
    "\n",
    "# Get all class-specific thresholds from best params\n",
    "\n",
    "def get_threshold(best_params):\n",
    "    class_thresholds=[]\n",
    "    for i in best_params:\n",
    "        t = best_params[i][0]\n",
    "        class_thresholds.append(t)\n",
    "    return class_thresholds \n",
    "\n",
    "#Thresholding method 5: using ratio, ambiguous cells are: \n",
    "# 1) When predicted probabilities < thresholds, i.e. diff = -ve (lower end)\n",
    "# 2) When more than 1 class-specific threshold is passed, i.e. more than 1 positive diff scores (upper end)\n",
    "\n",
    "def threshold_list_of_classes_5(y_pred_prob,best_params):\n",
    "    \n",
    "    thresholded_classes=[]\n",
    "    for i in y_pred_prob: #for each cell (containing 4 class probabilities)\n",
    "        \n",
    "        #Get cell 4 class-specific threshold values: \n",
    "        thresholds = get_threshold(best_params)\n",
    "        \n",
    "        # Calculate predicted probability - threshold = difference for each of the 4 classes \n",
    "        differences = (i-thresholds)/thresholds\n",
    "        \n",
    "        #Count number of positive or equal (0) differences \n",
    "        count = np.count_nonzero(differences>=0)\n",
    "        \n",
    "        if (count==1): #only assign class when 1 class passes the threshold \n",
    "            pred_class = np.argmax(differences)\n",
    "        else: #Otherwise, label as ambiguous (when more than 1 class passes, or when no class passes)\n",
    "            pred_class=4\n",
    "\n",
    "        #putting prediction in a list\n",
    "        thresholded_classes.append(pred_class)\n",
    "\n",
    "    thresholded_classes_ = numeric_to_name_classes(thresholded_classes)\n",
    "    return thresholded_classes_\n",
    "             \n",
    "#Thresholding method 4  using ratio instead of raw difference\n",
    "def threshold_list_of_classes_4 (y_pred_prob,best_params):\n",
    "    \n",
    "    thresholded_classes=[]\n",
    "    for i in y_pred_prob: #for each cell (containing 4 class probabilities)\n",
    "        \n",
    "        #Get cell 4 class-specific threshold values: \n",
    "        thresholds = get_threshold(best_params)\n",
    "        \n",
    "        # Calculate predicted probability - threshold = difference for each of the 4 classes \n",
    "        differences = (i-thresholds)/thresholds\n",
    "        \n",
    "        #Check if there is at last one positive diff probability\n",
    "        if (np.any(differences>0)): # If true, \n",
    "            \n",
    "            #get index (indicative of class) of the highest probability difference\n",
    "            pred_class = np.argmax(differences) \n",
    "            \n",
    "        else: #If all diff probabilities are NEGATIVE\n",
    "            pred_class = 4 # Assign cell class as 'ambiguous'\n",
    "\n",
    "        #putting prediction in a list\n",
    "        thresholded_classes.append(pred_class)\n",
    "\n",
    "    thresholded_classes_ = numeric_to_name_classes(thresholded_classes)\n",
    "    return thresholded_classes_\n",
    "\n",
    "\n",
    "#Thresholding method 3)\n",
    "\n",
    "def threshold_list_of_classes_3 (y_pred_prob,best_params):\n",
    "    \n",
    "    thresholded_classes=[]\n",
    "    for i in y_pred_prob: #for each cell (containing 4 class probabilities)\n",
    "        \n",
    "        #Get cell 4 class-specific threshold values: \n",
    "        thresholds = get_threshold(best_params)\n",
    "        \n",
    "        # Calculate predicted probability - threshold = difference for each of the 4 classes \n",
    "        differences = i-thresholds\n",
    "        \n",
    "        #Check if there is at last one positive diff probability\n",
    "        if (np.any(differences>0)): # If true, \n",
    "            \n",
    "            #get index (indicative of class) of the highest probability difference\n",
    "            pred_class = np.argmax(differences) \n",
    "            \n",
    "        else: #If all diff probabilities are NEGATIVE\n",
    "            pred_class = 4 # Assign cell class as 'ambiguous'\n",
    "\n",
    "        #putting prediction in a list\n",
    "        thresholded_classes.append(pred_class)\n",
    "\n",
    "    thresholded_classes_ = numeric_to_name_classes(thresholded_classes)\n",
    "    return thresholded_classes_\n",
    "\n",
    "#Thresholding method 2)\n",
    "def threshold_list_of_classes_2(y_pred_prob,best_params):\n",
    "    \n",
    "    thresholded_classes=[]\n",
    "    for i in y_pred_prob: #for each cell \n",
    "        \n",
    "        #Get threshold values: \n",
    "        thresholds = get_threshold(best_params)\n",
    "        \n",
    "        # Calculate predicted probability - threshold = difference \n",
    "        differences = i-thresholds\n",
    "               \n",
    "        #get index (indicative of class) of the highest probability\n",
    "        pred_class = np.argmax(differences)         \n",
    "\n",
    "        #putting prediction in a list\n",
    "        thresholded_classes.append(pred_class)\n",
    "\n",
    "        \n",
    "    thresholded_classes_ = numeric_to_name_classes(thresholded_classes)\n",
    "    return thresholded_classes_\n",
    "\n",
    "\n",
    "# To convert numeric classes to its corresponding name classes \n",
    "def numeric_to_name_classes(numeric_classes):\n",
    "    output=[]\n",
    "    for i in numeric_classes:\n",
    "        if (i==0):\n",
    "            c = 'Astro'\n",
    "        elif(i==1):\n",
    "            c='Neuron'\n",
    "        elif(i==2):\n",
    "            c='Oligo'\n",
    "        elif(i==3):\n",
    "            c='Others'\n",
    "        elif(i==4):\n",
    "            c='Ambiguous'\n",
    "        else:\n",
    "            print('SOMETHING IS WRONG')\n",
    "        output.append(c)\n",
    "    return output\n",
    "\n",
    "# To convert name classes to its corresponding numeric classes: \n",
    "def name_to_numeric_classes(name_classes):\n",
    "    output=[]\n",
    "    for i in name_classes: \n",
    "        if (i == 'Astro'): \n",
    "            x=0\n",
    "        elif(i == 'Neuron'): \n",
    "            x=1\n",
    "        elif(i == 'Oligo'): \n",
    "            x=2\n",
    "        elif(i=='Others'):\n",
    "            x=3\n",
    "        elif(i=='Ambiguous'):\n",
    "            x=4\n",
    "        else:\n",
    "            print('SOMETHING IS WRONG')\n",
    "            break\n",
    "        output.append(x)\n",
    "    return output\n",
    "    \n",
    "# Create roc curve for each class in multi-classification problem\n",
    "\n",
    "def multiclass_roc_curves(n_class,test_y_numeric,predy):\n",
    "    \n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    thresh ={}\n",
    "    \n",
    "    #calcualte roc curve locations \n",
    "    for i in range(n_class): # for each class, calculate roc_curve \n",
    "        fpr[i], tpr[i], thresh[i] = roc_curve(test_y_numeric, predy[:,i], pos_label=i)\n",
    "    \n",
    "    return fpr,tpr,thresh\n",
    "\n",
    "#Find the best position on the roc curve for multi-classification problem\n",
    "def best_param_gmean(n_class,fpr,tpr,thresh):\n",
    "    #calculate g-mean for each threshold \n",
    "    #gmeans={}\n",
    "    best_params={}\n",
    "    class_names=['Astro','Neuron','Oligo','Others']\n",
    "    for i in range(n_class):\n",
    "        tpr_ = tpr[i]\n",
    "        fpr_ = fpr[i]\n",
    "        gm = np.sqrt(tpr_*(1-fpr_))\n",
    "        t = thresh[i]\n",
    "        #gmeans[i]=gm\n",
    "        ix = np.argmax(gm)\n",
    "        best_params[i] = (t[ix],gm[ix],fpr_[ix],tpr_[ix])\n",
    "        #print(gm)\n",
    "       # print(class_names[i],'Best Threshold=%f, G-Mean=%.3f, fpr=%f, tpr=%f' % (t[ix], gm[ix],fpr_[ix],tpr_[ix]))\n",
    "        #print('--------------------------------------------------')\n",
    "    return best_params\n",
    "\n",
    "def multiclass_PR_curves(n_class,test_y_numeric,predy):\n",
    "    \n",
    "    precision = {}\n",
    "    recall = {}\n",
    "    thresh ={}\n",
    "    \n",
    "    #calcualte roc curve locations \n",
    "    for i in range(n_class): # for each class, calculate roc_curve \n",
    "        precision[i], recall[i], thresh[i] = precision_recall_curve(test_y_numeric, predy[:,i], pos_label=i)\n",
    "    \n",
    "    return precision,recall,thresh\n",
    "\n",
    "#Find the best position on the roc curve for multi-classification problem\n",
    "def best_param_f_score(n_class,precision,recall,thresh):\n",
    "    #calculate g-mean for each threshold \n",
    "    #f_scores={}\n",
    "    best_params={}\n",
    "    class_names=['Astro','Neuron','Oligo','Others']\n",
    "    for i in range(n_class):\n",
    "        p = precision[i]\n",
    "        r = recall[i]\n",
    "        nu=(2*p*r)\n",
    "        de=(p+r) \n",
    "        f_score = np.divide(nu,de,out=np.zeros_like(nu),where=de != 0) #(2*p*r)/(p+r)\n",
    "        t = thresh[i]\n",
    "        #f_scores[i]=f_score\n",
    "        ix = np.argmax(f_score)\n",
    "        best_params[i] = (t[ix],f_score[ix],p[ix],r[ix])\n",
    "        #print(gm)\n",
    "       # print(class_names[i],'Best Threshold=%f, G-Mean=%.3f, fpr=%f, tpr=%f' % (t[ix], gm[ix],fpr_[ix],tpr_[ix]))\n",
    "        #print('--------------------------------------------------')\n",
    "    return best_params\n",
    "\n",
    "#Thresholding function\n",
    "def prob_thresholding(y_pred_prob,y_pred,threshold):\n",
    "    thresholded_class =[]\n",
    "    for i in range(0,len(y_pred_prob)):\n",
    "        if(max(y_pred_prob[i])<threshold):\n",
    "            c='Ambiguous'\n",
    "        else:\n",
    "            c=y_pred[i]\n",
    "        thresholded_class.append(c)\n",
    "    return thresholded_class\n",
    "\n",
    "#Removing ambiguous class from thresholded class & y_predict\n",
    "def remove_amb_class(t_class,y_test):\n",
    "    \n",
    "    #Get indices of instances with no ambiguous label \n",
    "    x = pd.Series(t_class)\n",
    "    y_pred_no_amb = x[x!='Ambiguous']\n",
    "    y_pred_no_amb_indices = y_pred_no_amb.index\n",
    "    \n",
    "    #Extract these instances fom y_pred\n",
    "    #y_predict_no_amb = y_predict.iloc[pred_no_amb_indices]\n",
    "    \n",
    "    #Subset y_test\n",
    "    y_test_no_amb = y_test.iloc[y_pred_no_amb_indices]\n",
    "    \n",
    "    return (y_pred_no_amb,y_test_no_amb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning - random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('normalizer', MinMaxScaler()),\n",
       " ('selector', RFE(estimator=SVC(kernel='linear'))),\n",
       " ('clf', BalancedRandomForestClassifier())]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('normalizer',MinMaxScaler()),\n",
    "    ('selector',RFE(SVC(kernel='linear'))), \n",
    "    ('clf',BalancedRandomForestClassifier())\n",
    "])\n",
    "#pipeline.set_params(clf=RandomForestClassifier())\n",
    "pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.005, 0.01, 0.015, 0.02, 0.025, 0.03]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccp_alphas = [float(x) for x in np.linspace(start=0, stop=0.03, num=7) ]\n",
    "ccp_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.005, 0.01, 0.015, 0.02, 0.025, 0.03]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccp_alphas = [float(x) for x in np.linspace(start=0, stop=0.03, num=7) ]#[float(x) for x in np.linspace(start=0, stop=1, num=10) ]\n",
    "ccp_alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyper parameters to tune\n",
    "\n",
    "#Number of trees in random forest \n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "#Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "#Maximum number of levels in tree \n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "#Minimum number of samples required to split an internal node \n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "#Minimum number of samples required at each leaf node \n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "#Method for selecting samples for training each tree \n",
    "bootstrap = [True, False]\n",
    "\n",
    "#sampling strategy\n",
    "sampling_strategy=['auto','all','not majority','majority']\n",
    "\n",
    "#ccp_alphas \n",
    "ccp_alphas = [float(x) for x in np.linspace(start=0, stop=0.03, num=7) ]#[float(x) for x in np.linspace(start=0, stop=1, num=10) ]\n",
    "\n",
    "# ## Create the random grid \n",
    "# random_grid = {'selector__n_features_to_select':[30,32,34,36,38,40],\n",
    "#                 'clf__n_estimators': n_estimators,\n",
    "#                'clf__max_features': max_features,\n",
    "#                'clf__max_depth': max_depth,\n",
    "#                'clf__min_samples_split': min_samples_split,\n",
    "#                'clf__min_samples_leaf': min_samples_leaf,\n",
    "#               'clf__bootstrap': bootstrap,\n",
    "#               'clf__random_state':[42],\n",
    "#                'clf__sampling_strategy':sampling_strategy, \n",
    "#                'clf__ccp_alpha':ccp_alphas\n",
    "#              # 'clf__class_weight':['balanced']\n",
    "#               } # newly added\n",
    "# #pprint(random_grid)\n",
    "\n",
    "# rf_random = RandomizedSearchCV(pipeline,\n",
    "#                              param_distributions=random_grid, \n",
    "#                              n_iter=100,\n",
    "#                              cv=10,\n",
    "#                              verbose=2,\n",
    "#                             random_state=42,\n",
    "#                             n_jobs=-1,\n",
    "#                               refit='PR_AUC', # use this metric to evaluate performance of parameters \n",
    "#                       scoring={'PR_AUC':precision_recall_auc,\n",
    "#                           'roc_auc_ovr_weighted':'roc_auc_ovr_weighted',\n",
    "#                             'roc_auc_ovo':'roc_auc_ovo',\n",
    "#                               'balanced_accuracy':'balanced_accuracy',\n",
    "#                                'f1_weighted':'f1_weighted',\n",
    "#                                'Astro_accuracy': astro_acc,\n",
    "#                                'Neuron_accuracy':neuron_acc,\n",
    "#                                'Oligo_accuracy':oligo_acc,\n",
    "#                                'Others_accuracy':others_acc,\n",
    "#                                'A_as_N':A_as_N,\n",
    "#                                'A_as_O':A_as_O,\n",
    "#                                'A_as_Others':A_as_Others,\n",
    "#                                'N_as_A':N_as_A,\n",
    "#                                'N_as_O':N_as_O,\n",
    "#                                'N_as_Others':N_as_Others,\n",
    "#                                'O_as_A':O_as_A,\n",
    "#                                'O_as_N':O_as_N,\n",
    "#                                'O_as_Others':O_as_Others,\n",
    "#                                'Others_as_A':Others_as_A,\n",
    "#                                'Others_as_N':Others_as_N,\n",
    "#                                'Others_as_O':Others_as_O\n",
    "#                               })\n",
    "\n",
    "# rf_random.fit(X_train,y_train)\n",
    "\n",
    "# print(rf_random.best_score_)\n",
    "# print(rf_random.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
    "0.8092402569869004\n",
    "{'selector__n_features_to_select': 32, 'clf__sampling_strategy': 'all', 'clf__random_state': 42, 'clf__n_estimators': 1400, 'clf__min_samples_split': 2,\n",
    " 'clf__min_samples_leaf': 4, 'clf__max_features': 'sqrt', 'clf__max_depth': 10, 'clf__bootstrap': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Digging into more details \n",
    "# print(\"PR-AUC:\",\n",
    "#      rf_random.cv_results_['mean_test_PR_AUC'][rf_random.best_index_]*100)\n",
    "# print(\"ROC-AUC:\",\n",
    "#      rf_random.cv_results_['mean_test_roc_auc_ovr_weighted'][rf_random.best_index_]*100)\n",
    "# print(\"ROC-AUC:\",\n",
    "#      rf_random.cv_results_['mean_test_roc_auc_ovo'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Balanced accuracy:\",\n",
    "#       rf_random.cv_results_['mean_test_balanced_accuracy'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"F1_weighted:\",\n",
    "#       rf_random.cv_results_['mean_test_f1_weighted'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Astrocyte accuracy:\",\n",
    "#       rf_random.cv_results_['mean_test_Astro_accuracy'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Neuron accuracy:\",\n",
    "#       rf_random.cv_results_['mean_test_Neuron_accuracy'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Oligo accuracy:\",\n",
    "#       rf_random.cv_results_['mean_test_Oligo_accuracy'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Others accuracy:\",\n",
    "#       rf_random.cv_results_['mean_test_Others_accuracy'][rf_random.best_index_]*100)\n",
    "\n",
    "\n",
    "# print(\"Classified A as N:\",\n",
    "#       rf_random.cv_results_['mean_test_A_as_N'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified A as O:\",\n",
    "#       rf_random.cv_results_['mean_test_A_as_O'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified A as Others:\",\n",
    "#       rf_random.cv_results_['mean_test_A_as_Others'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified N as A:\",\n",
    "#       rf_random.cv_results_['mean_test_N_as_A'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified N as O:\",\n",
    "#       rf_random.cv_results_['mean_test_N_as_O'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified N as Others:\",\n",
    "#       rf_random.cv_results_['mean_test_N_as_Others'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified O as A:\",\n",
    "#       rf_random.cv_results_['mean_test_O_as_A'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified O as N:\",\n",
    "#       rf_random.cv_results_['mean_test_O_as_N'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified O as Others:\",\n",
    "#       rf_random.cv_results_['mean_test_O_as_Others'][rf_random.best_index_]*100)\n",
    "\n",
    "\n",
    "# print(\"Classified Others as A:\",\n",
    "#       rf_random.cv_results_['mean_test_Others_as_A'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified Others as N:\",\n",
    "#       rf_random.cv_results_['mean_test_Others_as_N'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified Others as O:\",\n",
    "#       rf_random.cv_results_['mean_test_Others_as_O'][rf_random.best_index_]*100)\n",
    "                                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False:\n",
    "PR-AUC: 80.92402569869004\n",
    "ROC-AUC: 95.57920955659537\n",
    "ROC-AUC: 94.42973203783929\n",
    "Balanced accuracy: 79.2362046769988\n",
    "F1_weighted: 80.27764195252072\n",
    "Astrocyte accuracy: 82.05882352941177\n",
    "Neuron accuracy: 82.56894790602655\n",
    "Oligo accuracy: 78.29272151898734\n",
    "Others accuracy: 74.02432575356954\n",
    "Classified A as N: 5.555555555555556\n",
    "Classified A as O: 7.908496732026143\n",
    "Classified A as Others: 4.477124183006537\n",
    "Classified N as A: 14.259448416751788\n",
    "Classified N as O: 0.45454545454545453\n",
    "Classified N as Others: 2.7170582226762003\n",
    "Classified O as A: 9.859177215189874\n",
    "Classified O as N: 0.12658227848101267\n",
    "Classified O as Others: 11.721518987341772\n",
    "Classified Others as A: 7.771020624008461\n",
    "Classified Others as N: 7.810682178741408\n",
    "Classified Others as O: 10.393971443680591"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual cross validation, using PR curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=None, shuffle=False)\n",
      "mean ROC AUC: 0.9571905149600852\n",
      "--------------------------------\n",
      "mean log loss: 0.5317302788856928\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "### manual cross-validation method \n",
    "x= X_train\n",
    "y=y_train\n",
    "## Setting up cross-validation \n",
    "skf = StratifiedKFold(n_splits=10) # shuffling = False, no need to set random_state\n",
    "skf.get_n_splits(x,y) # using only training data\n",
    "print(skf)\n",
    "\n",
    "#for train_index, test_index in skf.split(x,y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    #print(\"Train_size:\", train_index.size, \"Test_size:\", test_index.size)\n",
    "    \n",
    "## Training \n",
    "accuracies = []\n",
    "accuracies_c = []\n",
    "\n",
    "t_accuracies= []\n",
    "t_accuracies_c= []\n",
    "\n",
    "reports = []\n",
    "reports_c = []\n",
    "\n",
    "t_reports= []\n",
    "t_reports_c= []\n",
    "\n",
    "confusion_matrices = []\n",
    "confusion_matrices_c = [] \n",
    "\n",
    "t_confusion_matrices=[]\n",
    "t_confusion_matrices_c=[]\n",
    "\n",
    "#train_features =[] \n",
    "#train_n_features=[]\n",
    "y_preds = []\n",
    "y_preds_c = []\n",
    "\n",
    "y_preds_t =[]\n",
    "y_preds_t_c =[]\n",
    "\n",
    "y_prob_preds = []\n",
    "y_prob_preds_c = []\n",
    "\n",
    "y_cv_test=[]\n",
    "x_cv_test=[]\n",
    "\n",
    "roc_auc_scores=[]\n",
    "roc_auc_scores_c=[]\n",
    "\n",
    "log_losses=[]\n",
    "log_losses_c=[]\n",
    "\n",
    "#brier_scores=[]\n",
    "#brier_scores_c=[]\n",
    "\n",
    "best_parameters=[]\n",
    "best_parameters_c=[]\n",
    "\n",
    "for train_index, test_index in skf.split(x,y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    #print(\"Train_size:\", train_index.size, \"Test_size:\", test_index.size)\n",
    "    x_train_, x_test_ = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train_, y_test_ = y[train_index], y[test_index]\n",
    "    x_test_l = X_train_l.iloc[test_index]\n",
    "    #print(\"n of each cell types at test:\\n\", y_test_.value_counts())\n",
    "    \n",
    "    ## 1) Create classifier \n",
    "    \n",
    "    model=Pipeline([\n",
    "    ('normalizer',MinMaxScaler()),\n",
    "    ('selector',RFE(SVC(kernel='linear'),n_features_to_select=36)), #cv=5, =30\n",
    "        #cv=3\n",
    "    ('clf', BalancedRandomForestClassifier(random_state= 42, sampling_strategy='all', \n",
    "                                           n_estimators= 1800, min_samples_split= 2,\n",
    "                                           min_samples_leaf= 1, max_features= 'auto',\n",
    "                                           max_depth= 60, bootstrap= False))\n",
    "                                           ### MAKE SURE THESE ARE CORRECT \n",
    "        \n",
    "        #with alpha, sampling strategy\n",
    "#        {'selector__n_features_to_select': 36, 'clf__sampling_strategy': 'all', 'clf__random_state': 42,\n",
    "#         'clf__n_estimators': 1800, 'clf__min_samples_split': 2, 'clf__min_samples_leaf': 1,\n",
    "#         'clf__max_features': 'auto', 'clf__max_depth': 60, 'clf__ccp_alpha': 0.0, 'clf__bootstrap': False}\n",
    "        \n",
    "        \n",
    "])\n",
    "\n",
    "    # 2) Train the calibrated classifier with 'training' data (x,y) \n",
    "    model.fit(x_train_,y_train_)\n",
    "    \n",
    "    # 3) Get class probability predictions for 'test' data \n",
    "    y_prob_predict = model.predict_proba(x_test_)\n",
    "    \n",
    "    # 4.1) For thresholding: convert y_test_ from name classes to numeric classes\n",
    "    y_test_numeric = name_to_numeric_classes(y_test_)\n",
    "    \n",
    "    # 4.2) For thresholding: use predicted class probabilities to calculate ROC curve for each class vs rest\n",
    "    \n",
    "    precision,recall,thresh = multiclass_PR_curves(4,y_test_numeric,y_prob_predict)\n",
    "    \n",
    "    # 4.3) For thresholding: from ROC curves, find the best location (fpr,tpr,thresh) for each class \n",
    "    # Evaluated based on g-mean \n",
    "    best_params_ = best_param_f_score(4,precision,recall,thresh)\n",
    "    best_parameters.append(best_params_)\n",
    "    \n",
    "    # 4.4) For thresholding: apply thresholding to each class to create crisp class label \n",
    "    t_class = threshold_list_of_classes_5(y_prob_predict,best_params_)\n",
    "    \n",
    "    # 5) Get class labels using default thresholding value (0.5)\n",
    "    y_predict = model.predict(x_test_)\n",
    "    \n",
    "    # 6) Put predictions (labels &probabilities & t_labels) in the corresponding list\n",
    "    y_preds.append(y_predict)\n",
    "    \n",
    "    y_prob_preds.append(y_prob_predict)\n",
    "    \n",
    "    y_preds_t.append(t_class)\n",
    "    \n",
    "    y_cv_test.append(y_test_) # for visualisation purposes later on\n",
    "    x_cv_test.append(x_test_l)\n",
    "    \n",
    "    # 7) Remove 'ambiguous class' from t_class & y_test_ - for accuracy calculation\n",
    "    (y_predict_no_amb,y_test_no_amb) = remove_amb_class(t_class,y_test_)\n",
    "    \n",
    "    # 8) Calculate and put Performance metric (balanced accuracy) per fold into a list\n",
    "    accuracies.append(balanced_accuracy_score(y_test_,y_predict)) ## using BALANCED ACC.\n",
    "    \n",
    "    t_accuracies.append(balanced_accuracy_score(y_test_no_amb,y_predict_no_amb))\n",
    "    \n",
    "    #8.1) Compute classification reports\n",
    "    reports.append(classification_report(y_test_,y_predict,output_dict=True)) \n",
    "  #  reports_c.append(classification_report(y_test_,y_predict_c,output_dict=True)) \n",
    "    \n",
    "    t_reports.append(classification_report(y_test_no_amb,y_predict_no_amb,output_dict=True))\n",
    "    \n",
    "    # 9) Calculate and put ROC AUC scores per fold into a list \n",
    "    roc_auc_scores.append(roc_auc_score(y_test_,y_prob_predict,multi_class='ovr',average='weighted'))\n",
    "    \n",
    "    #9.1) Calculate and put log loss per fold into a list\n",
    "    log_losses.append(log_loss(y_test_,y_prob_predict))\n",
    "\n",
    "    \n",
    "    # 10) Create confusion matrices for default & thresholded results per fold then put in a list \n",
    "    cm = confusion_matrix(y_test_,y_predict, labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"]) #,normalize='true'\n",
    "    \n",
    "    cm_t = confusion_matrix(y_test_no_amb,y_predict_no_amb, labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])#,normalize='true'\n",
    "    \n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    t_confusion_matrices.append(cm_t)\n",
    "\n",
    "print('mean ROC AUC:',mean(roc_auc_scores))\n",
    "print('--------------------------------')\n",
    "print('mean log loss:',mean(log_losses))\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting information from best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thresholds \n",
    "astro_t = [] \n",
    "neuron_t=[]\n",
    "oligo_t=[]\n",
    "others_t=[]\n",
    "#G-means\n",
    "astro_gm=[]\n",
    "neuron_gm=[]\n",
    "oligo_gm=[]\n",
    "others_gm=[]\n",
    "\n",
    "#Info extraction \n",
    "for fold in best_parameters:\n",
    "    a_t = fold[0][0]\n",
    "    n_t = fold[1][0]\n",
    "    o_t = fold[2][0]\n",
    "    ot_t = fold[3][0]\n",
    "    \n",
    "    a_gm = fold[0][1]\n",
    "    n_gm = fold[1][1]\n",
    "    o_gm = fold[2][1]\n",
    "    ot_gm = fold[3][1]\n",
    "    \n",
    "    astro_t.append(a_t)\n",
    "    neuron_t.append(n_t)\n",
    "    oligo_t.append(o_t)\n",
    "    others_t.append(ot_t)\n",
    "    \n",
    "    astro_gm.append(a_gm)\n",
    "    neuron_gm.append(n_gm)\n",
    "    oligo_gm.append(o_gm)\n",
    "    others_gm.append(ot_gm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON CALIBRATED\n",
      "mean astro threshold: 0.5700555555555555 , mean f1_macro: 0.6145856278064705\n",
      "mean neuron threshold: 0.33294444444444443 , mean f1_macro: 0.9139441941756347\n",
      "mean oligo threshold: 0.32716666666666666 , mean f1_macro: 0.8737302506308778\n",
      "mean others threshold: 0.3637222222222222 , mean f1_macro: 0.8022441895278665\n",
      "1.593888888888889\n"
     ]
    }
   ],
   "source": [
    "print(\"NON CALIBRATED\")\n",
    "print('mean astro threshold:', mean(astro_t), ', mean f1_macro:',mean(astro_gm))\n",
    "print('mean neuron threshold:', mean(neuron_t), ', mean f1_macro:',mean(neuron_gm))\n",
    "print('mean oligo threshold:', mean(oligo_t), ', mean f1_macro:',mean(oligo_gm))\n",
    "print('mean others threshold:', mean(others_t), ', mean f1_macro:',mean(others_gm))\n",
    "print(mean(astro_t)+mean(neuron_t)+mean(oligo_t)+mean(others_t)) #is it okay that it is above 1? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NO Thresholding:** Non-calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Confusion matrix across 10 folds, WITHOUT thresholding \n",
    "# print('with no thresholding:',mean(accuracies)*100)\n",
    "# print('Macro avg F1 ',mean([i['macro avg']['f1-score'] for i in reports])*100)\n",
    "# print('Weighted avg F1 ',mean([i['weighted avg']['f1-score'] for i in reports])*100)\n",
    "\n",
    "# print(\"--------------------------\")\n",
    "# C=sum(confusion_matrices)\n",
    "# final_cm =  C.astype('float') / C.sum(axis=1)[:, np.newaxis]*100 #normalize(sum(confusion_matrices))*100\n",
    "# print(C)\n",
    "# print(final_cm)\n",
    "# print(\"--------------------------\")\n",
    "# print(\"Astro accuracy\",final_cm[0][0])\n",
    "# print(\"Neuron accuracy\",final_cm[1][1])\n",
    "# print(\"Oligo accuracy\",final_cm[2][2])\n",
    "# print(\"Others accuracy\",final_cm[3][3])\n",
    "# print(\"--------------------------\")\n",
    "# # F1-score per class: \n",
    "# print('Astro f1-score ',mean([i['Astro']['f1-score'] for i in reports])*100)\n",
    "# print('Neuron f1-score ',mean([i['Neuron']['f1-score'] for i in reports])*100)\n",
    "# print('Oligo f1-score ',mean([i['Oligo']['f1-score'] for i in reports])*100)\n",
    "# print('Others f1-score ',mean([i['Others']['f1-score'] for i in reports])*100)\n",
    "# print(\"--------------------------\")\n",
    "# print('Macro avg precision',mean([i['macro avg']['precision'] for i in reports])*100)\n",
    "# print('Macro avg recall ',mean([i['macro avg']['recall'] for i in reports])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NO Thresholding:** calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Confusion matrix across 10 folds, WITHOUT thresholding \n",
    "# print('with no thresholding, calibrated ACC:',mean(accuracies_c)*100)\n",
    "# print('Macro avg F1 ',mean([i['macro avg']['f1-score'] for i in reports_c])*100)\n",
    "# print('Weighted avg F1 ',mean([i['weighted avg']['f1-score'] for i in reports_c])*100)\n",
    "# print(\"--------------------------\")\n",
    "# C=sum(confusion_matrices_c)\n",
    "# final_cm =  C.astype('float') / C.sum(axis=1)[:, np.newaxis]*100 #normalize(sum(confusion_matrices))*100\n",
    "# print(C)\n",
    "# print(final_cm)\n",
    "# print(\"--------------------------\")\n",
    "# print(\"Astro accuracy\",final_cm[0][0])\n",
    "# print(\"Neuron accuracy\",final_cm[1][1])\n",
    "# print(\"Oligo accuracy\",final_cm[2][2])\n",
    "# print(\"Others accuracy\",final_cm[3][3])\n",
    "# print(\"--------------------------\")\n",
    "# # F1-score per class: \n",
    "# print('Astro f1-score ',mean([i['Astro']['f1-score'] for i in reports_c])*100)\n",
    "# print('Neuron f1-score ',mean([i['Neuron']['f1-score'] for i in reports_c])*100)\n",
    "# print('Oligo f1-score ',mean([i['Oligo']['f1-score'] for i in reports_c])*100)\n",
    "# print('Others f1-score ',mean([i['Others']['f1-score'] for i in reports_c])*100)\n",
    "# print(\"--------------------------\")\n",
    "# print('Macro avg precision',mean([i['macro avg']['precision'] for i in reports_c])*100)\n",
    "# print('Macro avg recall ',mean([i['macro avg']['recall'] for i in reports_c])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thresholding:** Non-calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with thresholding (non-calibrated) ACC : 86.62040920073237\n",
      "Macro avg F1  84.45393181277237\n",
      "Weighted avg F1  89.15483466055369\n",
      "--------------------------\n",
      "[[120  15   7  10]\n",
      " [ 47 758   1  16]\n",
      " [ 24   0 627  38]\n",
      " [ 14  20  46 423]]\n",
      "[[78.94736842  9.86842105  4.60526316  6.57894737]\n",
      " [ 5.71776156 92.21411192  0.1216545   1.94647202]\n",
      " [ 3.48330914  0.         91.00145138  5.51523948]\n",
      " [ 2.7833002   3.97614314  9.14512922 84.09542744]]\n",
      "--------------------------\n",
      "Astro accuracy 78.94736842105263\n",
      "Neuron accuracy 92.21411192214111\n",
      "Oligo accuracy 91.00145137880988\n",
      "Others accuracy 84.09542743538768\n",
      "------------------------------\n",
      "Astro f1-score  67.70262703312568\n",
      "Astro precision  59.36722689075631\n",
      "Astro recall  79.9140989729225\n",
      "--------------------------\n",
      "Neuron f1-score  93.7921007501118\n",
      "Neuron precision  95.69018452882193\n",
      "Neuron recall  92.07723123213515\n",
      "--------------------------\n",
      "Oligo f1-score  91.17474966549538\n",
      "Oligo precision  91.89491568477203\n",
      "Oligo recall  90.6836019030072\n",
      "--------------------------\n",
      "Others f1-score  85.14624980235664\n",
      "Others precision  87.0864185191192\n",
      "Others recall  83.80670469486459\n",
      "--------------------------\n",
      "Macro avg precision 83.50968640586737\n",
      "Macro avg recall  86.62040920073237\n",
      "Agreement:  2061 / 2473 =>  (83.34007278608976, '%')\n",
      "Disagreement:  412 / 2473 =>  (16.65992721391023, '%')\n",
      "------------------------------\n",
      "Of the disagreements, what are they?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Astro     168\n",
       "Others    135\n",
       "Oligo      61\n",
       "Neuron     48\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.5 \n",
    "#Confusion matrix across 10 folds, WITH thresholding \n",
    "print('with thresholding (non-calibrated) ACC :',mean(t_accuracies)*100)\n",
    "print('Macro avg F1 ',mean([i['macro avg']['f1-score'] for i in t_reports])*100)\n",
    "print('Weighted avg F1 ',mean([i['weighted avg']['f1-score'] for i in t_reports])*100)\n",
    "print(\"--------------------------\")\n",
    "C_t=sum(t_confusion_matrices)\n",
    "final_cm_t =  C_t.astype('float') / C_t.sum(axis=1)[:, np.newaxis]*100\n",
    "print(C_t)\n",
    "print(final_cm_t)\n",
    "print(\"--------------------------\")\n",
    "print(\"Astro accuracy\",final_cm_t[0][0])\n",
    "print(\"Neuron accuracy\",final_cm_t[1][1])\n",
    "print(\"Oligo accuracy\",final_cm_t[2][2])\n",
    "print(\"Others accuracy\",final_cm_t[3][3])\n",
    "print('------------------------------')\n",
    "# F1-score per class: \n",
    "print('Astro f1-score ',mean([i['Astro']['f1-score'] for i in t_reports])*100)\n",
    "print('Astro precision ',mean([i['Astro']['precision'] for i in t_reports])*100)\n",
    "print('Astro recall ',mean([i['Astro']['recall'] for i in t_reports])*100)\n",
    "print(\"--------------------------\")\n",
    "print('Neuron f1-score ',mean([i['Neuron']['f1-score'] for i in t_reports])*100)\n",
    "print('Neuron precision ',mean([i['Neuron']['precision'] for i in t_reports])*100)\n",
    "print('Neuron recall ',mean([i['Neuron']['recall'] for i in t_reports])*100)\n",
    "print(\"--------------------------\")\n",
    "print('Oligo f1-score ',mean([i['Oligo']['f1-score'] for i in t_reports])*100)\n",
    "print('Oligo precision ',mean([i['Oligo']['precision'] for i in t_reports])*100)\n",
    "print('Oligo recall ',mean([i['Oligo']['recall'] for i in t_reports])*100)\n",
    "print(\"--------------------------\")\n",
    "print('Others f1-score ',mean([i['Others']['f1-score'] for i in t_reports])*100)\n",
    "print('Others precision ',mean([i['Others']['precision'] for i in t_reports])*100)\n",
    "print('Others recall ',mean([i['Others']['recall'] for i in t_reports])*100)\n",
    "print(\"--------------------------\")\n",
    "print('Macro avg precision',mean([i['macro avg']['precision'] for i in t_reports])*100)\n",
    "print('Macro avg recall ',mean([i['macro avg']['recall'] for i in t_reports])*100)\n",
    "\n",
    "# Checking on disagreements \n",
    "\n",
    "\n",
    "thresholded_preds = pd.concat([pd.DataFrame(i) for i in y_preds_t])\n",
    "thresholded_preds = thresholded_preds.rename(columns={0:'t_Class'})\n",
    "thresholded_preds = thresholded_preds.reset_index(drop=True)\n",
    "\n",
    "\n",
    "preds = pd.concat([pd.DataFrame(i) for i in y_preds])\n",
    "preds = preds.rename(columns={0:'Class'})\n",
    "preds = preds.reset_index(drop=True)\n",
    "\n",
    "truth = pd.concat([pd.DataFrame(i) for i in y_cv_test])\n",
    "truth = truth.rename(columns={'Class':'Truth'})\n",
    "truth = truth.reset_index(drop=True)\n",
    "\n",
    "# x_truth = pd.concat([pd.DataFrame(i[['Image','Centroid_X','Centroid_Y']]) for i in x_cv_test])\n",
    "\n",
    "#Combine absolute prediction to thresholded prediction\n",
    "\n",
    "#get predicted probabilities\n",
    "p_probs=pd.concat([pd.DataFrame(i) for i in y_prob_preds])\n",
    "p_probs= p_probs.rename(columns={0:'Astro',1:'Neuron',2:'Oligo',3:'Others'})\n",
    "p_probs = p_probs.reset_index(drop=True)\n",
    "\n",
    "results = thresholded_preds.copy()\n",
    "results.loc[:,'Class']=preds\n",
    "results.loc[:,'Truth'] = truth\n",
    "results.loc[:,'Astro'] = p_probs['Astro']\n",
    "results.loc[:,'Neuron'] = p_probs['Neuron']\n",
    "results.loc[:,'Oligo'] = p_probs['Oligo']\n",
    "results.loc[:,'Others'] = p_probs['Others']\n",
    "# results.loc[:,'Image'] = x_truth['Image']\n",
    "# results.loc[:,'Centroid_X'] = x_truth['Centroid_X']\n",
    "# results.loc[:,'Centroid_Y'] = x_truth['Centroid_Y']\n",
    "\n",
    "\n",
    "#Calculate agreement between the two \n",
    "results.loc[:,'agreement'] = (results['t_Class']==results['Class'])*1\n",
    "agreements = results['agreement'].value_counts()\n",
    "print('Agreement: ',agreements[1],'/',agreements[1]+agreements[0],'=> ',(agreements[1]/(agreements[1]+agreements[0])*100,'%') )\n",
    "print('Disagreement: ',agreements[0],'/',agreements[1]+agreements[0],'=> ',(agreements[0]/(agreements[1]+agreements[0])*100,'%') )\n",
    "print('------------------------------')\n",
    "# Of those disagreed, what are they? (those with prob < 0.5)\n",
    "print('Of the disagreements, what are they?')\n",
    "disagreed = results[results['agreement']==0]\n",
    "disagreed['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neuron       793\n",
       "Oligo        681\n",
       "Others       487\n",
       "Ambiguous    307\n",
       "Astro        205\n",
       "Name: t_Class, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholded_preds['t_Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_Class</th>\n",
       "      <th>Class</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Astro</th>\n",
       "      <th>Neuron</th>\n",
       "      <th>Oligo</th>\n",
       "      <th>Others</th>\n",
       "      <th>agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.082222</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.828333</td>\n",
       "      <td>0.081111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>0.942222</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.935556</td>\n",
       "      <td>0.058889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t_Class   Class   Truth     Astro    Neuron     Oligo    Others  agreement\n",
       "0  Neuron  Neuron  Neuron  0.005000  0.991667  0.000000  0.003333          1\n",
       "1  Neuron  Neuron  Neuron  0.002222  0.996667  0.000000  0.001111          1\n",
       "2   Oligo   Oligo   Oligo  0.082222  0.008333  0.828333  0.081111          1\n",
       "3  Neuron  Neuron  Neuron  0.025556  0.942222  0.003889  0.028333          1\n",
       "4   Oligo   Oligo   Oligo  0.005556  0.000000  0.935556  0.058889          1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_Class</th>\n",
       "      <th>Class</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Astro</th>\n",
       "      <th>Neuron</th>\n",
       "      <th>Oligo</th>\n",
       "      <th>Others</th>\n",
       "      <th>agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Others</td>\n",
       "      <td>Others</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.050556</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Astro</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.785556</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.181667</td>\n",
       "      <td>0.019444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Astro</td>\n",
       "      <td>0.169444</td>\n",
       "      <td>0.656111</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.162778</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>0.489444</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.405556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Astro</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.082778</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.040556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>Astro</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.742222</td>\n",
       "      <td>0.148889</td>\n",
       "      <td>0.053889</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>Others</td>\n",
       "      <td>Others</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.218889</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.031111</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Others</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.019444</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>0.187222</td>\n",
       "      <td>0.789444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>Others</td>\n",
       "      <td>Others</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.047778</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.096667</td>\n",
       "      <td>0.845556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>Others</td>\n",
       "      <td>Others</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.037222</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>545 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        t_Class   Class   Truth     Astro    Neuron     Oligo    Others  \\\n",
       "9        Others  Others   Oligo  0.090000  0.050556  0.305000  0.554444   \n",
       "10        Astro   Astro   Oligo  0.785556  0.013333  0.181667  0.019444   \n",
       "11       Neuron  Neuron   Astro  0.169444  0.656111  0.011667  0.162778   \n",
       "13    Ambiguous  Neuron  Neuron  0.091667  0.489444  0.013333  0.405556   \n",
       "21        Astro   Astro  Others  0.766667  0.082778  0.110000  0.040556   \n",
       "...         ...     ...     ...       ...       ...       ...       ...   \n",
       "2466      Astro   Astro   Oligo  0.742222  0.148889  0.053889  0.055000   \n",
       "2468     Others  Others  Neuron  0.218889  0.155000  0.031111  0.595000   \n",
       "2470  Ambiguous  Others   Oligo  0.019444  0.003889  0.187222  0.789444   \n",
       "2471     Others  Others   Oligo  0.047778  0.010000  0.096667  0.845556   \n",
       "2472     Others  Others   Oligo  0.186667  0.037222  0.069444  0.706667   \n",
       "\n",
       "      agreement  \n",
       "9             1  \n",
       "10            1  \n",
       "11            1  \n",
       "13            0  \n",
       "21            1  \n",
       "...         ...  \n",
       "2466          1  \n",
       "2468          1  \n",
       "2470          0  \n",
       "2471          1  \n",
       "2472          1  \n",
       "\n",
       "[545 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['t_Class']!=results['Truth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test =pd.concat(x_cv_test)\n",
    "x_test=x_test.reset_index(drop=True)\n",
    "x_test_subset=x_test[['Image','Centroid_X','Centroid_Y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_=results.copy()\n",
    "results_=results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ = results_.join(x_test_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_Class</th>\n",
       "      <th>Class</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Astro</th>\n",
       "      <th>Neuron</th>\n",
       "      <th>Oligo</th>\n",
       "      <th>Others</th>\n",
       "      <th>agreement</th>\n",
       "      <th>Image</th>\n",
       "      <th>Centroid_X</th>\n",
       "      <th>Centroid_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4916.2</td>\n",
       "      <td>10545.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4933.9</td>\n",
       "      <td>10550.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.082222</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.828333</td>\n",
       "      <td>0.081111</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4912.0</td>\n",
       "      <td>10557.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>0.942222</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4789.5</td>\n",
       "      <td>10559.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.935556</td>\n",
       "      <td>0.058889</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4829.5</td>\n",
       "      <td>10563.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t_Class   Class   Truth     Astro    Neuron     Oligo    Others  agreement  \\\n",
       "0  Neuron  Neuron  Neuron  0.005000  0.991667  0.000000  0.003333          1   \n",
       "1  Neuron  Neuron  Neuron  0.002222  0.996667  0.000000  0.001111          1   \n",
       "2   Oligo   Oligo   Oligo  0.082222  0.008333  0.828333  0.081111          1   \n",
       "3  Neuron  Neuron  Neuron  0.025556  0.942222  0.003889  0.028333          1   \n",
       "4   Oligo   Oligo   Oligo  0.005556  0.000000  0.935556  0.058889          1   \n",
       "\n",
       "        Image  Centroid_X  Centroid_Y  \n",
       "0  703484.svs      4916.2     10545.9  \n",
       "1  703484.svs      4933.9     10550.1  \n",
       "2  703484.svs      4912.0     10557.6  \n",
       "3  703484.svs      4789.5     10559.3  \n",
       "4  703484.svs      4829.5     10563.8  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "755472.svs    247\n",
       "703484.svs    246\n",
       "755480.svs    245\n",
       "721735.svs    231\n",
       "755485.svs    228\n",
       "722215.svs    215\n",
       "755525.svs    198\n",
       "721856.svs    181\n",
       "755481.svs    179\n",
       "755486.svs    178\n",
       "721771.svs    168\n",
       "721701.svs    157\n",
       "Name: Image, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_['Image'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_Class</th>\n",
       "      <th>Class</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Astro</th>\n",
       "      <th>Neuron</th>\n",
       "      <th>Oligo</th>\n",
       "      <th>Others</th>\n",
       "      <th>agreement</th>\n",
       "      <th>Image</th>\n",
       "      <th>Centroid_X</th>\n",
       "      <th>Centroid_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Others</td>\n",
       "      <td>Others</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.050556</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>5179.2</td>\n",
       "      <td>10567.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Astro</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.785556</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.181667</td>\n",
       "      <td>0.019444</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>5018.0</td>\n",
       "      <td>10568.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Astro</td>\n",
       "      <td>0.169444</td>\n",
       "      <td>0.656111</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.162778</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4958.4</td>\n",
       "      <td>10568.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>0.489444</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.405556</td>\n",
       "      <td>0</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4756.0</td>\n",
       "      <td>10573.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Astro</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.082778</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.040556</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4697.9</td>\n",
       "      <td>10581.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Others</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.097778</td>\n",
       "      <td>0.154444</td>\n",
       "      <td>0.067222</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4969.8</td>\n",
       "      <td>10599.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.082222</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.468889</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>5412.2</td>\n",
       "      <td>10559.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.912222</td>\n",
       "      <td>0.082778</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>5359.6</td>\n",
       "      <td>10585.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Others</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>0.158889</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>5348.4</td>\n",
       "      <td>10586.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Astro</td>\n",
       "      <td>0.032222</td>\n",
       "      <td>0.818333</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>0.142222</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>3562.3</td>\n",
       "      <td>10558.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Others</td>\n",
       "      <td>Others</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.352778</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.289444</td>\n",
       "      <td>0.354444</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>2875.6</td>\n",
       "      <td>10559.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Others</td>\n",
       "      <td>Others</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.202222</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.201667</td>\n",
       "      <td>0.562778</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>2943.6</td>\n",
       "      <td>10559.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.601667</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.096667</td>\n",
       "      <td>0</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>2700.4</td>\n",
       "      <td>10563.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.228889</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.062778</td>\n",
       "      <td>0</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>2902.6</td>\n",
       "      <td>10563.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Astro</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.857222</td>\n",
       "      <td>0.121111</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.017222</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>2793.1</td>\n",
       "      <td>10567.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.009444</td>\n",
       "      <td>0.728333</td>\n",
       "      <td>0.128889</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>2771.8</td>\n",
       "      <td>10572.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.975556</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>3081.4</td>\n",
       "      <td>10577.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.553889</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>3433.1</td>\n",
       "      <td>10581.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Others</td>\n",
       "      <td>Others</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.142222</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.756111</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>2832.7</td>\n",
       "      <td>10587.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Others</td>\n",
       "      <td>Others</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.205556</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>2732.1</td>\n",
       "      <td>10588.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.563889</td>\n",
       "      <td>0.051111</td>\n",
       "      <td>0.239444</td>\n",
       "      <td>0.145556</td>\n",
       "      <td>0</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>2596.7</td>\n",
       "      <td>10598.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.017222</td>\n",
       "      <td>0.340556</td>\n",
       "      <td>0.082222</td>\n",
       "      <td>0</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>2645.6</td>\n",
       "      <td>10599.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982222</td>\n",
       "      <td>0.017222</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>3050.6</td>\n",
       "      <td>10599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Astro</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.711667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.205556</td>\n",
       "      <td>0.066111</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>3286.2</td>\n",
       "      <td>10605.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Astro</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.207778</td>\n",
       "      <td>0.046111</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>3669.3</td>\n",
       "      <td>10613.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Astro</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.810556</td>\n",
       "      <td>0.086111</td>\n",
       "      <td>0.017222</td>\n",
       "      <td>0.086111</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>2763.6</td>\n",
       "      <td>10613.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.675556</td>\n",
       "      <td>0.259444</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.061667</td>\n",
       "      <td>0</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>2435.6</td>\n",
       "      <td>10613.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.213889</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>0.352778</td>\n",
       "      <td>0</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>2950.2</td>\n",
       "      <td>10619.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Others</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.392778</td>\n",
       "      <td>0.182778</td>\n",
       "      <td>0.017222</td>\n",
       "      <td>0.407222</td>\n",
       "      <td>0</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>2871.4</td>\n",
       "      <td>10626.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.895556</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4052.1</td>\n",
       "      <td>10570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>3995.9</td>\n",
       "      <td>10581.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.074444</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.400556</td>\n",
       "      <td>0</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4313.7</td>\n",
       "      <td>10589.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.236111</td>\n",
       "      <td>0.665556</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.096111</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>3727.1</td>\n",
       "      <td>10599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.270556</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.414444</td>\n",
       "      <td>0.298333</td>\n",
       "      <td>0</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>3878.2</td>\n",
       "      <td>10607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.023889</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>0</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>3955.0</td>\n",
       "      <td>10629.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.983889</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>5404.4</td>\n",
       "      <td>10618.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Others</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.607778</td>\n",
       "      <td>0</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>5008.8</td>\n",
       "      <td>10615.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.018889</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.551667</td>\n",
       "      <td>0.422778</td>\n",
       "      <td>0</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>5106.3</td>\n",
       "      <td>10621.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.799444</td>\n",
       "      <td>0.187222</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>5253.3</td>\n",
       "      <td>10619.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.226111</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.205556</td>\n",
       "      <td>0</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4518.1</td>\n",
       "      <td>10624.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       t_Class   Class   Truth     Astro    Neuron     Oligo    Others  \\\n",
       "9       Others  Others   Oligo  0.090000  0.050556  0.305000  0.554444   \n",
       "10       Astro   Astro   Oligo  0.785556  0.013333  0.181667  0.019444   \n",
       "11      Neuron  Neuron   Astro  0.169444  0.656111  0.011667  0.162778   \n",
       "13   Ambiguous  Neuron  Neuron  0.091667  0.489444  0.013333  0.405556   \n",
       "21       Astro   Astro  Others  0.766667  0.082778  0.110000  0.040556   \n",
       "37   Ambiguous  Others  Neuron  0.097778  0.154444  0.067222  0.680556   \n",
       "38   Ambiguous   Oligo   Oligo  0.082222  0.002222  0.468889  0.446667   \n",
       "42       Oligo   Oligo  Others  0.004444  0.000556  0.912222  0.082778   \n",
       "43   Ambiguous  Others  Others  0.220556  0.158889  0.069444  0.551111   \n",
       "47      Neuron  Neuron   Astro  0.032222  0.818333  0.007222  0.142222   \n",
       "48      Others  Others  Neuron  0.352778  0.003333  0.289444  0.354444   \n",
       "49      Others  Others  Neuron  0.202222  0.033333  0.201667  0.562778   \n",
       "51   Ambiguous   Astro   Oligo  0.601667  0.018333  0.283333  0.096667   \n",
       "52   Ambiguous   Astro  Neuron  0.694444  0.228889  0.013889  0.062778   \n",
       "58       Astro   Astro  Neuron  0.857222  0.121111  0.004444  0.017222   \n",
       "64       Oligo   Oligo  Others  0.133333  0.009444  0.728333  0.128889   \n",
       "68       Oligo   Oligo  Others  0.000556  0.000556  0.975556  0.023333   \n",
       "75   Ambiguous   Astro  Others  0.553889  0.013333  0.327778  0.105000   \n",
       "83      Others  Others  Neuron  0.142222  0.076667  0.025000  0.756111   \n",
       "85      Others  Others   Oligo  0.027778  0.011667  0.205556  0.755000   \n",
       "96   Ambiguous   Astro   Oligo  0.563889  0.051111  0.239444  0.145556   \n",
       "97   Ambiguous   Astro   Oligo  0.560000  0.017222  0.340556  0.082222   \n",
       "98       Oligo   Oligo  Others  0.000556  0.000000  0.982222  0.017222   \n",
       "107      Astro   Astro  Others  0.711667  0.016667  0.205556  0.066111   \n",
       "109      Astro   Astro   Oligo  0.735000  0.011111  0.207778  0.046111   \n",
       "110      Astro   Astro  Others  0.810556  0.086111  0.017222  0.086111   \n",
       "111  Ambiguous   Astro  Neuron  0.675556  0.259444  0.003333  0.061667   \n",
       "116  Ambiguous   Oligo   Oligo  0.213889  0.002778  0.430556  0.352778   \n",
       "126  Ambiguous  Others  Neuron  0.392778  0.182778  0.017222  0.407222   \n",
       "143      Oligo   Oligo  Others  0.002778  0.001667  0.895556  0.100000   \n",
       "150      Oligo   Oligo  Others  0.007222  0.001111  0.977778  0.013889   \n",
       "159  Ambiguous  Neuron  Neuron  0.074444  0.516667  0.008333  0.400556   \n",
       "166     Neuron  Neuron  Others  0.236111  0.665556  0.002222  0.096111   \n",
       "174  Ambiguous   Oligo  Others  0.270556  0.016667  0.414444  0.298333   \n",
       "189  Ambiguous   Oligo   Oligo  0.023889  0.001111  0.540000  0.435000   \n",
       "210      Oligo   Oligo  Others  0.000000  0.001111  0.983889  0.015000   \n",
       "224  Ambiguous  Others   Oligo  0.011111  0.001111  0.380000  0.607778   \n",
       "227  Ambiguous   Oligo   Oligo  0.018889  0.006667  0.551667  0.422778   \n",
       "228      Oligo   Oligo  Others  0.008889  0.004444  0.799444  0.187222   \n",
       "255  Ambiguous   Astro  Others  0.554444  0.226111  0.013889  0.205556   \n",
       "\n",
       "     agreement       Image  Centroid_X  Centroid_Y  \n",
       "9            1  703484.svs      5179.2     10567.4  \n",
       "10           1  703484.svs      5018.0     10568.8  \n",
       "11           1  703484.svs      4958.4     10568.8  \n",
       "13           0  703484.svs      4756.0     10573.3  \n",
       "21           1  703484.svs      4697.9     10581.6  \n",
       "37           0  703484.svs      4969.8     10599.5  \n",
       "38           0  703484.svs      5412.2     10559.8  \n",
       "42           1  703484.svs      5359.6     10585.8  \n",
       "43           0  703484.svs      5348.4     10586.2  \n",
       "47           1  703484.svs      3562.3     10558.0  \n",
       "48           1  703484.svs      2875.6     10559.8  \n",
       "49           1  703484.svs      2943.6     10559.8  \n",
       "51           0  703484.svs      2700.4     10563.3  \n",
       "52           0  703484.svs      2902.6     10563.6  \n",
       "58           1  703484.svs      2793.1     10567.4  \n",
       "64           1  703484.svs      2771.8     10572.0  \n",
       "68           1  703484.svs      3081.4     10577.4  \n",
       "75           0  703484.svs      3433.1     10581.1  \n",
       "83           1  703484.svs      2832.7     10587.4  \n",
       "85           1  703484.svs      2732.1     10588.5  \n",
       "96           0  703484.svs      2596.7     10598.1  \n",
       "97           0  703484.svs      2645.6     10599.3  \n",
       "98           1  703484.svs      3050.6     10599.0  \n",
       "107          1  703484.svs      3286.2     10605.8  \n",
       "109          1  703484.svs      3669.3     10613.3  \n",
       "110          1  703484.svs      2763.6     10613.5  \n",
       "111          0  703484.svs      2435.6     10613.9  \n",
       "116          0  703484.svs      2950.2     10619.1  \n",
       "126          0  703484.svs      2871.4     10626.9  \n",
       "143          1  703484.svs      4052.1     10570.0  \n",
       "150          1  703484.svs      3995.9     10581.7  \n",
       "159          0  703484.svs      4313.7     10589.9  \n",
       "166          1  703484.svs      3727.1     10599.0  \n",
       "174          0  703484.svs      3878.2     10607.0  \n",
       "189          0  703484.svs      3955.0     10629.7  \n",
       "210          1  703484.svs      5404.4     10618.0  \n",
       "224          0  703484.svs      5008.8     10615.8  \n",
       "227          0  703484.svs      5106.3     10621.5  \n",
       "228          1  703484.svs      5253.3     10619.3  \n",
       "255          0  703484.svs      4518.1     10624.7  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = results_[results_['Image']=='703484.svs']\n",
    "i[i['Truth']!=i['t_Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_Class</th>\n",
       "      <th>Class</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Astro</th>\n",
       "      <th>Neuron</th>\n",
       "      <th>Oligo</th>\n",
       "      <th>Others</th>\n",
       "      <th>agreement</th>\n",
       "      <th>Image</th>\n",
       "      <th>Centroid_X</th>\n",
       "      <th>Centroid_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Others</td>\n",
       "      <td>Others</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.050556</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>5179.2</td>\n",
       "      <td>10567.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Astro</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.785556</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.181667</td>\n",
       "      <td>0.019444</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>5018.0</td>\n",
       "      <td>10568.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Astro</td>\n",
       "      <td>0.169444</td>\n",
       "      <td>0.656111</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.162778</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4958.4</td>\n",
       "      <td>10568.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>0.489444</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.405556</td>\n",
       "      <td>0</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4756.0</td>\n",
       "      <td>10573.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Astro</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.082778</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.040556</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4697.9</td>\n",
       "      <td>10581.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      t_Class   Class   Truth     Astro    Neuron     Oligo    Others  \\\n",
       "9      Others  Others   Oligo  0.090000  0.050556  0.305000  0.554444   \n",
       "10      Astro   Astro   Oligo  0.785556  0.013333  0.181667  0.019444   \n",
       "11     Neuron  Neuron   Astro  0.169444  0.656111  0.011667  0.162778   \n",
       "13  Ambiguous  Neuron  Neuron  0.091667  0.489444  0.013333  0.405556   \n",
       "21      Astro   Astro  Others  0.766667  0.082778  0.110000  0.040556   \n",
       "\n",
       "    agreement       Image  Centroid_X  Centroid_Y  \n",
       "9           1  703484.svs      5179.2     10567.4  \n",
       "10          1  703484.svs      5018.0     10568.8  \n",
       "11          1  703484.svs      4958.4     10568.8  \n",
       "13          0  703484.svs      4756.0     10573.3  \n",
       "21          1  703484.svs      4697.9     10581.6  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect = results_[results_['t_Class']!=results_['Truth']]\n",
    "incorrect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_as_file = incorrect[['Image','Truth','Centroid_X','Centroid_Y','t_Class']]\n",
    "path_ = 'D:/Tanrada_classification/imbalance_cortical_training/cortical_full_slide_predictions/Probabilistic_classification/Model8_corrected_PR/Cell_inspection/incorrect.txt'\n",
    "incorrect_as_file.to_csv(path_, sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_Class</th>\n",
       "      <th>Class</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Astro</th>\n",
       "      <th>Neuron</th>\n",
       "      <th>Oligo</th>\n",
       "      <th>Others</th>\n",
       "      <th>agreement</th>\n",
       "      <th>Image</th>\n",
       "      <th>Centroid_X</th>\n",
       "      <th>Centroid_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4916.2</td>\n",
       "      <td>10545.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4933.9</td>\n",
       "      <td>10550.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.082222</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.828333</td>\n",
       "      <td>0.081111</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4912.0</td>\n",
       "      <td>10557.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>0.942222</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4789.5</td>\n",
       "      <td>10559.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.935556</td>\n",
       "      <td>0.058889</td>\n",
       "      <td>1</td>\n",
       "      <td>703484.svs</td>\n",
       "      <td>4829.5</td>\n",
       "      <td>10563.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t_Class   Class   Truth     Astro    Neuron     Oligo    Others  agreement  \\\n",
       "0  Neuron  Neuron  Neuron  0.005000  0.991667  0.000000  0.003333          1   \n",
       "1  Neuron  Neuron  Neuron  0.002222  0.996667  0.000000  0.001111          1   \n",
       "2   Oligo   Oligo   Oligo  0.082222  0.008333  0.828333  0.081111          1   \n",
       "3  Neuron  Neuron  Neuron  0.025556  0.942222  0.003889  0.028333          1   \n",
       "4   Oligo   Oligo   Oligo  0.005556  0.000000  0.935556  0.058889          1   \n",
       "\n",
       "        Image  Centroid_X  Centroid_Y  \n",
       "0  703484.svs      4916.2     10545.9  \n",
       "1  703484.svs      4933.9     10550.1  \n",
       "2  703484.svs      4912.0     10557.6  \n",
       "3  703484.svs      4789.5     10559.3  \n",
       "4  703484.svs      4829.5     10563.8  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = results_[results_['t_Class']==results_['Truth']]\n",
    "correct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_as_file = correct[['Image','Truth','Centroid_X','Centroid_Y','t_Class']]\n",
    "path_ = 'D:/Tanrada_classification/imbalance_cortical_training/cortical_full_slide_predictions/Probabilistic_classification/Model8_corrected_PR/Cell_inspection/correct.txt'\n",
    "correct_as_file.to_csv(path_, sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thresholding:** Calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with thresholding (calibrated) ACC: 85.36068938459995\n",
      "Macro avg F1  83.74867031298476\n",
      "Weighted avg F1  88.22661256240006\n",
      "--------------------------\n",
      "[[115  22   8   8]\n",
      " [ 42 782   1  17]\n",
      " [ 20   1 648  56]\n",
      " [ 14  25  54 445]]\n",
      "[[75.16339869 14.37908497  5.22875817  5.22875817]\n",
      " [ 4.98812352 92.87410926  0.11876485  2.01900238]\n",
      " [ 2.75862069  0.13793103 89.37931034  7.72413793]\n",
      " [ 2.60223048  4.64684015 10.03717472 82.71375465]]\n",
      "--------------------------\n",
      "Astro accuracy 75.16339869281046\n",
      "Neuron accuracy 92.87410926365796\n",
      "Oligo accuracy 89.37931034482759\n",
      "Others accuracy 82.71375464684016\n",
      "------------------------------\n",
      "Astro f1-score  67.93304850274961\n",
      "Neuron f1-score  93.59111059295563\n",
      "Oligo f1-score  89.8708065290597\n",
      "Others f1-score  83.5997156271741\n",
      "--------------------------\n",
      "Macro avg precision 83.18000797391211\n",
      "Macro avg recall  85.36068938459995\n",
      "Agreement:  2170 / 2473 =>  (87.74767488879903, '%')\n",
      "Disagreement:  303 / 2473 =>  (12.252325111200971, '%')\n",
      "------------------------------\n",
      "Of the disagreements, what are they?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Others    94\n",
       "Astro     72\n",
       "Oligo     69\n",
       "Neuron    68\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.5 \n",
    "#Confusion matrix across 10 folds, WITH thresholding \n",
    "print('with thresholding (calibrated) ACC:',mean(t_accuracies_c)*100)\n",
    "print('Macro avg F1 ',mean([i['macro avg']['f1-score'] for i in t_reports_c])*100)\n",
    "print('Weighted avg F1 ',mean([i['weighted avg']['f1-score'] for i in t_reports_c])*100)\n",
    "print(\"--------------------------\")\n",
    "C_t=sum(t_confusion_matrices_c)\n",
    "final_cm_t =  C_t.astype('float') / C_t.sum(axis=1)[:, np.newaxis]*100\n",
    "print(C_t)\n",
    "print(final_cm_t)\n",
    "print(\"--------------------------\")\n",
    "print(\"Astro accuracy\",final_cm_t[0][0])\n",
    "print(\"Neuron accuracy\",final_cm_t[1][1])\n",
    "print(\"Oligo accuracy\",final_cm_t[2][2])\n",
    "print(\"Others accuracy\",final_cm_t[3][3])\n",
    "print('------------------------------')\n",
    "# F1-score per class: \n",
    "print('Astro f1-score ',mean([i['Astro']['f1-score'] for i in t_reports_c])*100)\n",
    "print('Neuron f1-score ',mean([i['Neuron']['f1-score'] for i in t_reports_c])*100)\n",
    "print('Oligo f1-score ',mean([i['Oligo']['f1-score'] for i in t_reports_c])*100)\n",
    "print('Others f1-score ',mean([i['Others']['f1-score'] for i in t_reports_c])*100)\n",
    "print(\"--------------------------\")\n",
    "print('Macro avg precision',mean([i['macro avg']['precision'] for i in t_reports_c])*100)\n",
    "print('Macro avg recall ',mean([i['macro avg']['recall'] for i in t_reports_c])*100)\n",
    "# Checking on disagreements \n",
    "thresholded_preds = pd.concat([pd.DataFrame(i) for i in y_preds_t_c])\n",
    "thresholded_preds = thresholded_preds.rename(columns={0:'t_Class'})\n",
    "\n",
    "preds = pd.concat([pd.DataFrame(i) for i in y_preds_c])\n",
    "preds = preds.rename(columns={0:'Class'})\n",
    "\n",
    "#Combine absolute prediction to thresholded prediction\n",
    "results = thresholded_preds.copy()\n",
    "results.loc[:,'Class']=preds\n",
    "\n",
    "#Calculate agreement between the two \n",
    "results.loc[:,'agreement'] = (results['t_Class']==results['Class'])*1\n",
    "agreements = results['agreement'].value_counts()\n",
    "print('Agreement: ',agreements[1],'/',agreements[1]+agreements[0],'=> ',(agreements[1]/(agreements[1]+agreements[0])*100,'%') )\n",
    "print('Disagreement: ',agreements[0],'/',agreements[1]+agreements[0],'=> ',(agreements[0]/(agreements[1]+agreements[0])*100,'%') )\n",
    "print('------------------------------')\n",
    "# Of those disagreed, what are they? (those with prob < 0.5)\n",
    "print('Of the disagreements, what are they?')\n",
    "disagreed = results[results['agreement']==0]\n",
    "disagreed['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f49f039f1826f29992caaab1300810c8c9e5d31d3955aed133543fc6668591e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
