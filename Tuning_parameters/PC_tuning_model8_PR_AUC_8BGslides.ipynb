{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic classification: RF & adjust tuning step using 8 BG slides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thresholding in the context of:\n",
    "\n",
    "1) Compute the difference between p(class) - t(class) **\n",
    "\n",
    "1) Sorted in descending order\n",
    "\n",
    "2) Compare max to threshold, if less then we move on to compare the next most likely class against the threshold\n",
    "\n",
    "3) Continue until probability is equal or greater than threshold, assign that class\n",
    "\n",
    "4) If no classes get assigned, then that cell is labelled as 'ambiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import random \n",
    "\n",
    "from sklearn import preprocessing \n",
    "from statistics import mean\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from pprint import pprint \n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "#import ml_insights as mli "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Require: \n",
    "1. input_files.txt - to contian filenames I want to use. ** currently .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in:  20 files\n",
      "721708_Globus Pallidus_cell_annotations.csv  number of features:  62\n",
      "721708_Striatum_cell_annotations.csv  number of features:  62\n",
      "721708_Subthalamic Nucleus_cell_annotations.csv  number of features:  62\n",
      "747308_Globus Pallidus_cell_annotations.csv  number of features:  62\n",
      "747308_Striatum_cell_annotations.csv  number of features:  62\n",
      "747370_Globus Pallidus_cell_annotations.csv  number of features:  62\n",
      "747370_Striatum_cell_annotations.csv  number of features:  62\n",
      "747370_Subthalamic Nucleus_cell_annotations.csv  number of features:  62\n",
      "747814_Globus Pallidus_cell_annotations.csv  number of features:  62\n",
      "747814_Striatum_cell_annotations.csv  number of features:  62\n",
      "747814_Subthalamic Nucleus_cell_annotations.csv  number of features:  62\n",
      "747820_Globus Pallidus_cell_annotations.csv  number of features:  62\n",
      "747820_Striatum_cell_annotations.csv  number of features:  62\n",
      "747820_Subthalamic Nucleus_cell_annotations.csv  number of features:  62\n",
      "747828_Globus Pallidus_cell_annotations.csv  number of features:  62\n",
      "747828_Striatum_cell_annotations.csv  number of features:  62\n",
      "755497_Globus Pallidus_cell_annotations.csv  number of features:  61\n",
      "755497_Striatum_cell_annotations.csv  number of features:  61\n",
      "771885_Globus Pallidus_cell_annotations.csv  number of features:  62\n",
      "771885_Striatum_cell_annotations.csv  number of features:  62\n",
      "Extracted: 20 files\n",
      "Note: inconsistencies come from tau necrosis - will be removed later\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Name</th>\n",
       "      <th>Class</th>\n",
       "      <th>Parent</th>\n",
       "      <th>ROI</th>\n",
       "      <th>Centroid_X</th>\n",
       "      <th>Centroid_Y</th>\n",
       "      <th>Detection probability</th>\n",
       "      <th>Nucleus: Area ¬µm^2</th>\n",
       "      <th>Nucleus: Length ¬µm</th>\n",
       "      <th>...</th>\n",
       "      <th>DAB: Membrane: Median</th>\n",
       "      <th>DAB: Membrane: Min</th>\n",
       "      <th>DAB: Membrane: Max</th>\n",
       "      <th>DAB: Membrane: Std.Dev.</th>\n",
       "      <th>DAB: Cell: Mean</th>\n",
       "      <th>DAB: Cell: Median</th>\n",
       "      <th>DAB: Cell: Min</th>\n",
       "      <th>DAB: Cell: Max</th>\n",
       "      <th>DAB: Cell: Std.Dev.</th>\n",
       "      <th>tau: Necrosis area µm^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Striatum</td>\n",
       "      <td>Ignore</td>\n",
       "      <td>PathAnnotationObject</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>7987.5</td>\n",
       "      <td>1949.5</td>\n",
       "      <td>0.7316</td>\n",
       "      <td>22.9312</td>\n",
       "      <td>17.4807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>-0.0237</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.0636</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>-0.0334</td>\n",
       "      <td>0.4475</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>10.1613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Striatum</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>PathAnnotationObject</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>7983.8</td>\n",
       "      <td>1959.7</td>\n",
       "      <td>0.8573</td>\n",
       "      <td>23.5197</td>\n",
       "      <td>17.4146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>-0.0240</td>\n",
       "      <td>0.1807</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>0.0553</td>\n",
       "      <td>-0.0642</td>\n",
       "      <td>0.6111</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>21.5369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Striatum</td>\n",
       "      <td>Astro</td>\n",
       "      <td>PathAnnotationObject</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>7989.2</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>0.8765</td>\n",
       "      <td>21.6119</td>\n",
       "      <td>16.6321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>-0.0340</td>\n",
       "      <td>0.1679</td>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>-0.0673</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>10.0974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Striatum</td>\n",
       "      <td>Ignore</td>\n",
       "      <td>PathAnnotationObject</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>7974.9</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>0.7854</td>\n",
       "      <td>12.4837</td>\n",
       "      <td>13.1234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0493</td>\n",
       "      <td>-0.0155</td>\n",
       "      <td>0.2983</td>\n",
       "      <td>0.0511</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.0646</td>\n",
       "      <td>-0.0548</td>\n",
       "      <td>0.2983</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>7.6689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Striatum</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>PathAnnotationObject</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>7952.9</td>\n",
       "      <td>1996.9</td>\n",
       "      <td>0.8648</td>\n",
       "      <td>49.3439</td>\n",
       "      <td>25.1681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3993</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>-0.0533</td>\n",
       "      <td>0.4499</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>25.9466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image      Name   Class                Parent      ROI  Centroid_X  \\\n",
       "0  721708.svs  Striatum  Ignore  PathAnnotationObject  Polygon      7987.5   \n",
       "1  721708.svs  Striatum   Oligo  PathAnnotationObject  Polygon      7983.8   \n",
       "2  721708.svs  Striatum   Astro  PathAnnotationObject  Polygon      7989.2   \n",
       "3  721708.svs  Striatum  Ignore  PathAnnotationObject  Polygon      7974.9   \n",
       "4  721708.svs  Striatum  Neuron  PathAnnotationObject  Polygon      7952.9   \n",
       "\n",
       "   Centroid_Y  Detection probability  Nucleus: Area ¬µm^2  \\\n",
       "0      1949.5                 0.7316              22.9312   \n",
       "1      1959.7                 0.8573              23.5197   \n",
       "2      1986.0                 0.8765              21.6119   \n",
       "3      1988.0                 0.7854              12.4837   \n",
       "4      1996.9                 0.8648              49.3439   \n",
       "\n",
       "   Nucleus: Length ¬µm  ...  DAB: Membrane: Median  DAB: Membrane: Min  \\\n",
       "0              17.4807  ...                 0.0369             -0.0237   \n",
       "1              17.4146  ...                 0.0423             -0.0240   \n",
       "2              16.6321  ...                 0.0462             -0.0340   \n",
       "3              13.1234  ...                 0.0493             -0.0155   \n",
       "4              25.1681  ...                 0.0350              0.0005   \n",
       "\n",
       "   DAB: Membrane: Max  DAB: Membrane: Std.Dev.  DAB: Cell: Mean  \\\n",
       "0              0.1842                   0.0403           0.0636   \n",
       "1              0.1807                   0.0395           0.0802   \n",
       "2              0.1679                   0.0411           0.0581   \n",
       "3              0.2983                   0.0511           0.0700   \n",
       "4              0.3993                   0.0522           0.0684   \n",
       "\n",
       "   DAB: Cell: Median  DAB: Cell: Min  DAB: Cell: Max  DAB: Cell: Std.Dev.  \\\n",
       "0             0.0533         -0.0334          0.4475               0.0533   \n",
       "1             0.0553         -0.0642          0.6111               0.0919   \n",
       "2             0.0479         -0.0673          0.3571               0.0508   \n",
       "3             0.0646         -0.0548          0.2983               0.0504   \n",
       "4             0.0488         -0.0533          0.4499               0.0665   \n",
       "\n",
       "   tau: Necrosis area µm^2  \n",
       "0                  10.1613  \n",
       "1                  21.5369  \n",
       "2                  10.0974  \n",
       "3                   7.6689  \n",
       "4                  25.9466  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 1) Importing annotated cells \n",
    "#Variables: mylist, inputs \n",
    "\n",
    "## obtaining list of files \n",
    "with open(\"D:/Tanrada_classification/imbalance_subcortical_training/annotated/training_slides.txt\") as f: \n",
    "    mylist= f.read().splitlines()\n",
    "    \n",
    "print(\"Read in: \",len(mylist),\"files\")\n",
    "\n",
    "## 2) reading in all those files \n",
    "inputs = [] \n",
    "for i in mylist: \n",
    "    dat = pd.read_csv('D:/Tanrada_classification/imbalance_subcortical_training/annotated/'+i,sep=\",\")\n",
    "    ## Changing column names - since these names tend to be inconsistent causing problems \n",
    "    dat.columns.values[5] = 'Centroid_X'\n",
    "    dat.columns.values[6] = 'Centroid_Y'\n",
    "    dat.columns.values[8] = 'Nucleus: Area ¬µm^2'\n",
    "    dat.columns.values[9] = 'Nucleus: Length ¬µm'\n",
    "    dat.columns.values[12] = 'Nucleus: Max diameter ¬µm'\n",
    "    dat.columns.values[13] = 'Nucleus: Min diameter ¬µm'\n",
    "    dat.columns.values[14] = 'Cell: Area ¬µm^2'\n",
    "    dat.columns.values[15] = 'Cell: Length ¬µm'\n",
    "    dat.columns.values[18] = 'Cell: Max diameter ¬µm'\n",
    "    dat.columns.values[19] = 'Cell: Min diameter ¬µm'\n",
    "    #dat_cleaned = dat.iloc[:,0:61] ## SELECTING ONLY RELELVANT COLUMNS \n",
    "    print(i,\" number of features: \", dat.shape[1])\n",
    "    inputs.append(dat)\n",
    "\n",
    "print(\"Extracted:\", len(inputs),\"files\")\n",
    "print(\"Note: inconsistencies come from tau necrosis - will be removed later\")\n",
    "#Example\n",
    "inputs[1].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in: 20  NUMBER OF neighbouring cells files\n",
      "Extracted: 20 files\n"
     ]
    }
   ],
   "source": [
    "# 2.5) Importing in neghbouring cells info (numbers)\n",
    "\n",
    "nb_mylist = [i[0:6]+'_all_neighbours.csv' for i in mylist]\n",
    "print(\"Read in:\",len(nb_mylist),\" NUMBER OF neighbouring cells files\")\n",
    "\n",
    "# reading in all those files \n",
    "nb_inputs = [] \n",
    "for i in nb_mylist: \n",
    "    dat = pd.read_csv(\"D:/number_of_neighbours/\"+i,sep=\",\")\n",
    "    nb_inputs.append(dat)\n",
    "    \n",
    "print(\"Extracted:\", len(nb_inputs),\"files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: since we use mylist to generate nb_mylist, file order is gauranteed to be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features  18\n",
      "Number of features  18\n",
      "Number of features  18\n",
      "Number of features  18\n",
      "Number of features  18\n",
      "Number of features  18\n",
      "Number of features  18\n",
      "Number of features  18\n",
      "Number of features  18\n",
      "Number of features  18\n",
      "Number of features  18\n",
      "Number of features  18\n",
      "Number of features  18\n",
      "Number of features  18\n",
      "Number of features  18\n",
      "Number of features  18\n",
      "Number of features  18\n",
      "Number of features  18\n",
      "Number of features  13\n",
      "Number of features  13\n"
     ]
    }
   ],
   "source": [
    "# Inspecting number of columns in NNB files: \n",
    "for i in nb_inputs:\n",
    "    print(\"Number of features \",i.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_dat shape: (746312, 12)\n",
      "dat shape: (89, 62)\n",
      "Expected shape: 89 72  Resulting shape: (89, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (746312, 12)\n",
      "dat shape: (102, 62)\n",
      "Expected shape: 102 72  Resulting shape: (102, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (746312, 12)\n",
      "dat shape: (79, 62)\n",
      "Expected shape: 79 72  Resulting shape: (79, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (450168, 12)\n",
      "dat shape: (75, 62)\n",
      "Expected shape: 75 72  Resulting shape: (75, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (450168, 12)\n",
      "dat shape: (110, 62)\n",
      "Expected shape: 110 72  Resulting shape: (110, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (789034, 12)\n",
      "dat shape: (63, 62)\n",
      "Expected shape: 63 72  Resulting shape: (63, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (789034, 12)\n",
      "dat shape: (103, 62)\n",
      "Expected shape: 103 72  Resulting shape: (103, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (789034, 12)\n",
      "dat shape: (79, 62)\n",
      "Expected shape: 79 72  Resulting shape: (79, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (694839, 12)\n",
      "dat shape: (94, 62)\n",
      "Expected shape: 94 72  Resulting shape: (94, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (694839, 12)\n",
      "dat shape: (112, 62)\n",
      "Expected shape: 112 72  Resulting shape: (112, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (694839, 12)\n",
      "dat shape: (93, 62)\n",
      "Expected shape: 93 72  Resulting shape: (93, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (792783, 12)\n",
      "dat shape: (78, 62)\n",
      "Expected shape: 78 72  Resulting shape: (78, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (792783, 12)\n",
      "dat shape: (88, 62)\n",
      "Expected shape: 88 72  Resulting shape: (88, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (792783, 12)\n",
      "dat shape: (57, 62)\n",
      "Expected shape: 57 72  Resulting shape: (57, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (609511, 12)\n",
      "dat shape: (68, 62)\n",
      "Expected shape: 68 72  Resulting shape: (68, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (609511, 12)\n",
      "dat shape: (83, 62)\n",
      "Expected shape: 83 72  Resulting shape: (83, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (409910, 12)\n",
      "dat shape: (61, 61)\n",
      "Expected shape: 61 71  Resulting shape: (61, 71)\n",
      "--------------------------\n",
      "nb_dat shape: (409910, 12)\n",
      "dat shape: (68, 61)\n",
      "Expected shape: 68 71  Resulting shape: (68, 71)\n",
      "--------------------------\n",
      "nb_dat shape: (602155, 12)\n",
      "dat shape: (66, 62)\n",
      "Expected shape: 66 72  Resulting shape: (66, 72)\n",
      "--------------------------\n",
      "nb_dat shape: (602155, 12)\n",
      "dat shape: (142, 62)\n",
      "Expected shape: 142 72  Resulting shape: (142, 72)\n",
      "--------------------------\n",
      "Succesfully combined nb cell counts to main data\n"
     ]
    }
   ],
   "source": [
    "## Extracting only annotated cells from nb files \n",
    "inputs_=[]\n",
    "n=len(inputs)\n",
    "for i in range(0,n):\n",
    "    #all cells on slide\n",
    "    nb_dat_ = nb_inputs[i]\n",
    "    nb_dat_ = nb_dat_.rename(columns={'X':'Centroid_X','Y':'Centroid_Y'})\n",
    "    nb_dat = nb_dat_[['Centroid_X','Centroid_Y','NN_10_um','NN_20_um','NN_30_um','NN_40_um','NN_50_um'\n",
    "                    ,'NN_60_um','NN_70_um','NN_80_um','NN_90_um','NN_100_um']] #so we have removed 'slice_id' or 'Image'\n",
    "    print(\"nb_dat shape:\", nb_dat.shape)\n",
    "    #annotated cells with no nb info\n",
    "    dat = inputs[i]\n",
    "    print(\"dat shape:\", dat.shape)\n",
    "    \n",
    "    #annotated cells with nb info: intersect between 2 dataframes \n",
    "    combined = dat.merge(nb_dat,on=['Centroid_X','Centroid_Y'],how='inner',validate='1:1') \n",
    "    inputs_.append(combined)\n",
    "    print(\"Expected shape:\", dat.shape[0],dat.shape[1]+nb_dat.shape[1]-2,\" Resulting shape:\",combined.shape)\n",
    "    print(\"--------------------------\")\n",
    "    \n",
    "print(\"Succesfully combined nb cell counts to main data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in: 20 hema files\n",
      "Extracted: 20 hema files\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Centroid_X</th>\n",
       "      <th>Centroid_Y</th>\n",
       "      <th>Hematoxylin: Nucleus: Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7828.8</td>\n",
       "      <td>554.15</td>\n",
       "      <td>0.5298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7849.7</td>\n",
       "      <td>575.58</td>\n",
       "      <td>0.5649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7383.8</td>\n",
       "      <td>579.98</td>\n",
       "      <td>0.2996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7371.3</td>\n",
       "      <td>586.91</td>\n",
       "      <td>0.3383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7360.5</td>\n",
       "      <td>594.38</td>\n",
       "      <td>0.4680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Centroid_X  Centroid_Y  Hematoxylin: Nucleus: Mean\n",
       "0      7828.8      554.15                      0.5298\n",
       "1      7849.7      575.58                      0.5649\n",
       "2      7383.8      579.98                      0.2996\n",
       "3      7371.3      586.91                      0.3383\n",
       "4      7360.5      594.38                      0.4680"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 2) Importing hema nucleus mean of all detected cells & location coordinates \n",
    "# Variables: hema_mylist, hema_inputs \n",
    "\n",
    "hema_mylist = [i[0:6]+'_hema.csv' for i in mylist]    \n",
    "print(\"Read in:\",len(hema_mylist),\"hema files\")    \n",
    "\n",
    "\n",
    "## 4) reading in all those files \n",
    "hema_inputs = [] \n",
    "for i in hema_mylist: \n",
    "    dat = pd.read_csv('D:/Tanrada_classification/hema_novel/'+i,sep=\",\")\n",
    "    dat.columns.values[0] = 'Centroid_X' # To fix naming inconsistency problem \n",
    "    dat.columns.values[1] = 'Centroid_Y'\n",
    "    hema_inputs.append(dat)\n",
    "\n",
    "print(\"Extracted:\",len(hema_inputs),\"hema files\")  \n",
    "\n",
    "#Example \n",
    "hema_inputs[2].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mylist & nb_list matched?: True\n",
      "mylist & hema_list matched?: True\n"
     ]
    }
   ],
   "source": [
    "# Checking if filenames & order of them from mylist, nb_mylist & hema_mylist match\n",
    "x_nb = [i[0:6] for i in nb_mylist]\n",
    "x = [i[0:6] for i in mylist]\n",
    "x_h = [i[0:6] for i in hema_mylist]\n",
    "print(\"mylist & nb_list matched?:\", x==x_nb)\n",
    "print(\"mylist & hema_list matched?:\",x==x_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalising hematoxlyin per brain side & discard top 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  No. of cells with normalised Hema >1: 7455 from 746312 detected cells\n",
      "1  No. of cells with normalised Hema >1: 7455 from 746312 detected cells\n",
      "2  No. of cells with normalised Hema >1: 7455 from 746312 detected cells\n",
      "3  No. of cells with normalised Hema >1: 4499 from 450168 detected cells\n",
      "4  No. of cells with normalised Hema >1: 4499 from 450168 detected cells\n",
      "5  No. of cells with normalised Hema >1: 7888 from 789034 detected cells\n",
      "6  No. of cells with normalised Hema >1: 7888 from 789034 detected cells\n",
      "7  No. of cells with normalised Hema >1: 7888 from 789034 detected cells\n",
      "8  No. of cells with normalised Hema >1: 6935 from 694839 detected cells\n",
      "9  No. of cells with normalised Hema >1: 6935 from 694839 detected cells\n",
      "10  No. of cells with normalised Hema >1: 6935 from 694839 detected cells\n",
      "11  No. of cells with normalised Hema >1: 7917 from 792783 detected cells\n",
      "12  No. of cells with normalised Hema >1: 7917 from 792783 detected cells\n",
      "13  No. of cells with normalised Hema >1: 7917 from 792783 detected cells\n",
      "14  No. of cells with normalised Hema >1: 6092 from 609511 detected cells\n",
      "15  No. of cells with normalised Hema >1: 6092 from 609511 detected cells\n",
      "16  No. of cells with normalised Hema >1: 4099 from 409910 detected cells\n",
      "17  No. of cells with normalised Hema >1: 4099 from 409910 detected cells\n",
      "18  No. of cells with normalised Hema >1: 6019 from 602155 detected cells\n",
      "19  No. of cells with normalised Hema >1: 6019 from 602155 detected cells\n"
     ]
    }
   ],
   "source": [
    "### 1) Get instances needed to be remove for each slide\n",
    "#Variables: hema_to_remove, hema_inputs \n",
    "hema_to_remove = [] \n",
    "for h in hema_inputs: \n",
    "    h2 = h.copy() \n",
    "    hema = h2['Hematoxylin: Nucleus: Mean']\n",
    "    threshold = hema.quantile(0.99)\n",
    "    hema_norm = hema/threshold \n",
    "    h2['Hematoxylin: Nucleus: Mean'] = hema_norm \n",
    "    h2 = h2[h2['Hematoxylin: Nucleus: Mean']>1] # to select instances need removing (keep <=1)\n",
    "    hema_to_remove.append(h2)\n",
    "\n",
    "for i in range(0,len(hema_to_remove)): \n",
    "    print(i, \" No. of cells with normalised Hema >1:\",len(hema_to_remove[i]), \"from\", len(hema_inputs[i]),\"detected cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721708_Globus Pallidus_cell_annotations.csv : 0 cells removed\n",
      "721708_Striatum_cell_annotations.csv : 0 cells removed\n",
      "721708_Subthalamic Nucleus_cell_annotations.csv : 1 cells removed\n",
      "747308_Globus Pallidus_cell_annotations.csv : 1 cells removed\n",
      "747308_Striatum_cell_annotations.csv : 0 cells removed\n",
      "747370_Globus Pallidus_cell_annotations.csv : 0 cells removed\n",
      "747370_Striatum_cell_annotations.csv : 0 cells removed\n",
      "747370_Subthalamic Nucleus_cell_annotations.csv : 1 cells removed\n",
      "747814_Globus Pallidus_cell_annotations.csv : 0 cells removed\n",
      "747814_Striatum_cell_annotations.csv : 4 cells removed\n",
      "747814_Subthalamic Nucleus_cell_annotations.csv : 0 cells removed\n",
      "747820_Globus Pallidus_cell_annotations.csv : 0 cells removed\n",
      "747820_Striatum_cell_annotations.csv : 0 cells removed\n",
      "747820_Subthalamic Nucleus_cell_annotations.csv : 0 cells removed\n",
      "747828_Globus Pallidus_cell_annotations.csv : 0 cells removed\n",
      "747828_Striatum_cell_annotations.csv : 2 cells removed\n",
      "755497_Globus Pallidus_cell_annotations.csv : 2 cells removed\n",
      "755497_Striatum_cell_annotations.csv : 0 cells removed\n",
      "771885_Globus Pallidus_cell_annotations.csv : 0 cells removed\n",
      "771885_Striatum_cell_annotations.csv : 5 cells removed\n"
     ]
    }
   ],
   "source": [
    "## 2) Discarding annotated cells if they fit the criteria above \n",
    "#Variables: cleaned_inputs, removed  \n",
    "\n",
    "cleaned_inputs = []\n",
    "removed = [] \n",
    "for n in range(0,(len(inputs_))): #looping through annotated % hema (detected) slides \n",
    "    \n",
    "    i = inputs_[n] #annotated cells \n",
    "    h = hema_to_remove[n] #cells we need to remove, may or may not contain annotated cells \n",
    "    \n",
    "    #Find cells that exist in both 'i' & 'h' = cells we want to remove \n",
    "    to_remove = i.merge(h,on=['Centroid_X','Centroid_Y'],how='inner',validate='1:1')\n",
    "    \n",
    "    #Find cells that only exist in 'i' but not in 'h' = cells we want to retain \n",
    "    to_retain = i.merge(h,on=['Centroid_X','Centroid_Y'],how='left',indicator=True,validate='1:1')\n",
    "    \n",
    "    #Extract cells we want to retain \n",
    "    retained = i[to_retain['_merge']=='left_only']\n",
    "    \n",
    "    cleaned_inputs.append(retained)\n",
    "    removed.append(to_remove)\n",
    "    print(mylist[n],\":\",i.shape[0]-retained.shape[0],\"cells removed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 72)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Image',\n",
       " 'Name',\n",
       " 'Class',\n",
       " 'Parent',\n",
       " 'ROI',\n",
       " 'Centroid_X',\n",
       " 'Centroid_Y',\n",
       " 'Detection probability',\n",
       " 'Nucleus: Area ¬µm^2',\n",
       " 'Nucleus: Length ¬µm',\n",
       " 'Nucleus: Circularity',\n",
       " 'Nucleus: Solidity',\n",
       " 'Nucleus: Max diameter ¬µm',\n",
       " 'Nucleus: Min diameter ¬µm',\n",
       " 'Cell: Area ¬µm^2',\n",
       " 'Cell: Length ¬µm',\n",
       " 'Cell: Circularity',\n",
       " 'Cell: Solidity',\n",
       " 'Cell: Max diameter ¬µm',\n",
       " 'Cell: Min diameter ¬µm',\n",
       " 'Nucleus/Cell area ratio',\n",
       " 'Hematoxylin: Nucleus: Mean',\n",
       " 'Hematoxylin: Nucleus: Median',\n",
       " 'Hematoxylin: Nucleus: Min',\n",
       " 'Hematoxylin: Nucleus: Max',\n",
       " 'Hematoxylin: Nucleus: Std.Dev.',\n",
       " 'Hematoxylin: Cytoplasm: Mean',\n",
       " 'Hematoxylin: Cytoplasm: Median',\n",
       " 'Hematoxylin: Cytoplasm: Min',\n",
       " 'Hematoxylin: Cytoplasm: Max',\n",
       " 'Hematoxylin: Cytoplasm: Std.Dev.',\n",
       " 'Hematoxylin: Membrane: Mean',\n",
       " 'Hematoxylin: Membrane: Median',\n",
       " 'Hematoxylin: Membrane: Min',\n",
       " 'Hematoxylin: Membrane: Max',\n",
       " 'Hematoxylin: Membrane: Std.Dev.',\n",
       " 'Hematoxylin: Cell: Mean',\n",
       " 'Hematoxylin: Cell: Median',\n",
       " 'Hematoxylin: Cell: Min',\n",
       " 'Hematoxylin: Cell: Max',\n",
       " 'Hematoxylin: Cell: Std.Dev.',\n",
       " 'DAB: Nucleus: Mean',\n",
       " 'DAB: Nucleus: Median',\n",
       " 'DAB: Nucleus: Min',\n",
       " 'DAB: Nucleus: Max',\n",
       " 'DAB: Nucleus: Std.Dev.',\n",
       " 'DAB: Cytoplasm: Mean',\n",
       " 'DAB: Cytoplasm: Median',\n",
       " 'DAB: Cytoplasm: Min',\n",
       " 'DAB: Cytoplasm: Max',\n",
       " 'DAB: Cytoplasm: Std.Dev.',\n",
       " 'DAB: Membrane: Mean',\n",
       " 'DAB: Membrane: Median',\n",
       " 'DAB: Membrane: Min',\n",
       " 'DAB: Membrane: Max',\n",
       " 'DAB: Membrane: Std.Dev.',\n",
       " 'DAB: Cell: Mean',\n",
       " 'DAB: Cell: Median',\n",
       " 'DAB: Cell: Min',\n",
       " 'DAB: Cell: Max',\n",
       " 'DAB: Cell: Std.Dev.',\n",
       " 'tau: Necrosis area µm^2',\n",
       " 'NN_10_um',\n",
       " 'NN_20_um',\n",
       " 'NN_30_um',\n",
       " 'NN_40_um',\n",
       " 'NN_50_um',\n",
       " 'NN_60_um',\n",
       " 'NN_70_um',\n",
       " 'NN_80_um',\n",
       " 'NN_90_um',\n",
       " 'NN_100_um']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cleaned_inputs[0].shape)\n",
    "list(cleaned_inputs[0].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing DAB & tau necrosis & Image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 71 , After removal: 51\n",
      "Initial n_features: 71 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n",
      "Initial n_features: 72 , After removal: 51\n"
     ]
    }
   ],
   "source": [
    "## Removing DAB & tau necrosis ** making sure same dimension\n",
    "cleaned_inputs_ = []\n",
    "for i in cleaned_inputs:\n",
    "    # To remove all DAB features\n",
    "    to_drop1 = list(i.filter(regex='DAB'))\n",
    "    dat1 = i[i.columns.drop(to_drop1)]\n",
    "    # To remove tau necrosis features\n",
    "    to_drop2 = list(dat1.filter(regex='tau'))\n",
    "    dat2= dat1[dat1.columns.drop(to_drop2)]\n",
    "    # To remove Smoothed ****\n",
    "    to_drop3 = list(dat2.filter(regex='Smoothed'))\n",
    "    dat3= dat2[dat2.columns.drop(to_drop3)]\n",
    "    #Remove Image_name\n",
    "    if ('image_name' in list(dat3.columns)):\n",
    "        dat =dat3.drop(columns=['Image_name'])\n",
    "    else:\n",
    "        dat=dat3\n",
    "    \n",
    "    cleaned_inputs_.append(dat)\n",
    "    print(\"Initial n_features:\",i.shape[1], \", After removal:\", dat.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting the slides together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1694, 51)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Name</th>\n",
       "      <th>Class</th>\n",
       "      <th>Centroid_X</th>\n",
       "      <th>Centroid_Y</th>\n",
       "      <th>Detection probability</th>\n",
       "      <th>Nucleus: Area ¬µm^2</th>\n",
       "      <th>Nucleus: Length ¬µm</th>\n",
       "      <th>Nucleus: Circularity</th>\n",
       "      <th>Nucleus: Solidity</th>\n",
       "      <th>...</th>\n",
       "      <th>NN_10_um</th>\n",
       "      <th>NN_20_um</th>\n",
       "      <th>NN_30_um</th>\n",
       "      <th>NN_40_um</th>\n",
       "      <th>NN_50_um</th>\n",
       "      <th>NN_60_um</th>\n",
       "      <th>NN_70_um</th>\n",
       "      <th>NN_80_um</th>\n",
       "      <th>NN_90_um</th>\n",
       "      <th>NN_100_um</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>12022.2</td>\n",
       "      <td>8715.8</td>\n",
       "      <td>0.8575</td>\n",
       "      <td>13.1628</td>\n",
       "      <td>13.2907</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>12029.8</td>\n",
       "      <td>8722.0</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>15.2611</td>\n",
       "      <td>14.0081</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>10048.5</td>\n",
       "      <td>9974.4</td>\n",
       "      <td>0.8670</td>\n",
       "      <td>16.7321</td>\n",
       "      <td>14.7662</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>52</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>10029.8</td>\n",
       "      <td>9984.5</td>\n",
       "      <td>0.8827</td>\n",
       "      <td>18.6383</td>\n",
       "      <td>15.5263</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>47</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>10031.0</td>\n",
       "      <td>9993.5</td>\n",
       "      <td>0.8682</td>\n",
       "      <td>21.4955</td>\n",
       "      <td>16.7517</td>\n",
       "      <td>0.9626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "      <td>49</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image             Name  Class  Centroid_X  Centroid_Y  \\\n",
       "0  721708.svs  Globus Pallidus  Oligo     12022.2      8715.8   \n",
       "1  721708.svs  Globus Pallidus  Oligo     12029.8      8722.0   \n",
       "2  721708.svs  Globus Pallidus  Oligo     10048.5      9974.4   \n",
       "3  721708.svs  Globus Pallidus  Oligo     10029.8      9984.5   \n",
       "4  721708.svs  Globus Pallidus  Oligo     10031.0      9993.5   \n",
       "\n",
       "   Detection probability  Nucleus: Area ¬µm^2  Nucleus: Length ¬µm  \\\n",
       "0                 0.8575              13.1628              13.2907   \n",
       "1                 0.8796              15.2611              14.0081   \n",
       "2                 0.8670              16.7321              14.7662   \n",
       "3                 0.8827              18.6383              15.5263   \n",
       "4                 0.8682              21.4955              16.7517   \n",
       "\n",
       "   Nucleus: Circularity  Nucleus: Solidity  ...  NN_10_um  NN_20_um  NN_30_um  \\\n",
       "0                0.9364                1.0  ...         1         1         2   \n",
       "1                0.9773                1.0  ...         1         1         1   \n",
       "2                0.9643                1.0  ...         1         3         5   \n",
       "3                0.9716                1.0  ...         1         1         4   \n",
       "4                0.9626                1.0  ...         1         1         4   \n",
       "\n",
       "   NN_40_um  NN_50_um  NN_60_um  NN_70_um  NN_80_um  NN_90_um  NN_100_um  \n",
       "0         7        10        15        22        30        37         50  \n",
       "1         4        10        17        24        34        38         49  \n",
       "2         7        11        14        25        35        52         65  \n",
       "3         6         9        17        26        36        47         63  \n",
       "4         6        11        18        24        35        49         64  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Variables: labelled_orig, labelled_data \n",
    "#1) Put the slides together\n",
    "\n",
    "labelled_orig = pd.concat(cleaned_inputs_)\n",
    "print(labelled_orig.shape)\n",
    "\n",
    "# 2) Extract relevant columns \n",
    "dat = labelled_orig.drop(columns=['Parent','ROI']) #we're not dropping 'NAME' here as with other scripts.\n",
    "dat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Image',\n",
       " 'Name',\n",
       " 'Class',\n",
       " 'Centroid_X',\n",
       " 'Centroid_Y',\n",
       " 'Detection probability',\n",
       " 'Nucleus: Area ¬µm^2',\n",
       " 'Nucleus: Length ¬µm',\n",
       " 'Nucleus: Circularity',\n",
       " 'Nucleus: Solidity',\n",
       " 'Nucleus: Max diameter ¬µm',\n",
       " 'Nucleus: Min diameter ¬µm',\n",
       " 'Cell: Area ¬µm^2',\n",
       " 'Cell: Length ¬µm',\n",
       " 'Cell: Circularity',\n",
       " 'Cell: Solidity',\n",
       " 'Cell: Max diameter ¬µm',\n",
       " 'Cell: Min diameter ¬µm',\n",
       " 'Nucleus/Cell area ratio',\n",
       " 'Hematoxylin: Nucleus: Mean',\n",
       " 'Hematoxylin: Nucleus: Median',\n",
       " 'Hematoxylin: Nucleus: Min',\n",
       " 'Hematoxylin: Nucleus: Max',\n",
       " 'Hematoxylin: Nucleus: Std.Dev.',\n",
       " 'Hematoxylin: Cytoplasm: Mean',\n",
       " 'Hematoxylin: Cytoplasm: Median',\n",
       " 'Hematoxylin: Cytoplasm: Min',\n",
       " 'Hematoxylin: Cytoplasm: Max',\n",
       " 'Hematoxylin: Cytoplasm: Std.Dev.',\n",
       " 'Hematoxylin: Membrane: Mean',\n",
       " 'Hematoxylin: Membrane: Median',\n",
       " 'Hematoxylin: Membrane: Min',\n",
       " 'Hematoxylin: Membrane: Max',\n",
       " 'Hematoxylin: Membrane: Std.Dev.',\n",
       " 'Hematoxylin: Cell: Mean',\n",
       " 'Hematoxylin: Cell: Median',\n",
       " 'Hematoxylin: Cell: Min',\n",
       " 'Hematoxylin: Cell: Max',\n",
       " 'Hematoxylin: Cell: Std.Dev.',\n",
       " 'NN_10_um',\n",
       " 'NN_20_um',\n",
       " 'NN_30_um',\n",
       " 'NN_40_um',\n",
       " 'NN_50_um',\n",
       " 'NN_60_um',\n",
       " 'NN_70_um',\n",
       " 'NN_80_um',\n",
       " 'NN_90_um',\n",
       " 'NN_100_um']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dat.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting relevant cell classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1694 cells\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Oligo              783\n",
       "Endo               289\n",
       "Neuron             200\n",
       "Astro              187\n",
       "Ignore             142\n",
       "Epi                 28\n",
       "fragmented          27\n",
       "tuftedastrocyte     13\n",
       "Ambiguous           12\n",
       "ambiguous           10\n",
       "Tumor                2\n",
       "neuronaltau          1\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Check no. of cells / class of our data\n",
    "print(\"Total\",sum(dat['Class'].value_counts()),\"cells\")\n",
    "dat['Class'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note that we did not use 'ambiguous cells' & I have removed 'tufted astrocyte' & 'neuronal tau' for now***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Selecting only relevant cell classes (Using stardist_error instead of ignore_new)\n",
    "orig = dat.copy()\n",
    "dat__ = dat[(dat['Class'] == 'Oligo') | (dat['Class'] == 'Neuron')\n",
    "          | (dat['Class'] == 'Astro')| (dat['Class'] == 'Epi')\n",
    "          | (dat['Class'] == 'Ignore')| (dat['Class'] == 'fragmented')| (dat['Class'] == 'Endo')]\n",
    "dat__=dat__.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Changing Epithelial to Endothelial\n",
    "classes = dat__['Class']\n",
    "formatted_classes = ['Endo'  if (i == 'Epi') else i for i in classes]\n",
    "dat_ = dat__.copy()\n",
    "dat_['Class']=formatted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oligo         783\n",
       "Endo          317\n",
       "Neuron        200\n",
       "Astro         187\n",
       "Ignore        142\n",
       "fragmented     27\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Checking results from 3)\n",
    "dat_['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Oligo     783\n",
       "Others    486\n",
       "Neuron    200\n",
       "Astro     187\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) Group Ignore, Endo & Fragmented cells as a single class called 'Others'\n",
    "class_ = dat_['Class']\n",
    "y = ['Others'if i == 'Endo' or i == 'Ignore' or i == 'fragmented' else i for i in class_ ]\n",
    "dat = dat_\n",
    "dat['Class'] = y \n",
    "print(dat['Class'].value_counts().sum())\n",
    "dat['Class'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_dat = dat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oligo     78.3\n",
       "Others    48.6\n",
       "Neuron    20.0\n",
       "Astro     18.7\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if cv=10\n",
    "dat['Class'].value_counts()/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for any NA in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any NA in the data?:  False\n"
     ]
    }
   ],
   "source": [
    "#checking for NAN \n",
    "## NEW \n",
    "print(\"Any NA in the data?: \",dat.isnull().sum().sum()==1)\n",
    "\n",
    "#dat = dat.dropna()\n",
    "# dat.isnull().sum().sum()\n",
    "#print(\"Any NA in the data?: \",dat.isnull().sum().sum()==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train, test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Image', 'Name', 'Class', 'Centroid_X', 'Centroid_Y',\n",
       "       'Detection probability', 'Nucleus: Area ¬µm^2', 'Nucleus: Length ¬µm',\n",
       "       'Nucleus: Circularity', 'Nucleus: Solidity',\n",
       "       'Nucleus: Max diameter ¬µm', 'Nucleus: Min diameter ¬µm',\n",
       "       'Cell: Area ¬µm^2', 'Cell: Length ¬µm', 'Cell: Circularity',\n",
       "       'Cell: Solidity', 'Cell: Max diameter ¬µm', 'Cell: Min diameter ¬µm',\n",
       "       'Nucleus/Cell area ratio', 'Hematoxylin: Nucleus: Mean',\n",
       "       'Hematoxylin: Nucleus: Median', 'Hematoxylin: Nucleus: Min',\n",
       "       'Hematoxylin: Nucleus: Max', 'Hematoxylin: Nucleus: Std.Dev.',\n",
       "       'Hematoxylin: Cytoplasm: Mean', 'Hematoxylin: Cytoplasm: Median',\n",
       "       'Hematoxylin: Cytoplasm: Min', 'Hematoxylin: Cytoplasm: Max',\n",
       "       'Hematoxylin: Cytoplasm: Std.Dev.', 'Hematoxylin: Membrane: Mean',\n",
       "       'Hematoxylin: Membrane: Median', 'Hematoxylin: Membrane: Min',\n",
       "       'Hematoxylin: Membrane: Max', 'Hematoxylin: Membrane: Std.Dev.',\n",
       "       'Hematoxylin: Cell: Mean', 'Hematoxylin: Cell: Median',\n",
       "       'Hematoxylin: Cell: Min', 'Hematoxylin: Cell: Max',\n",
       "       'Hematoxylin: Cell: Std.Dev.', 'NN_10_um', 'NN_20_um', 'NN_30_um',\n",
       "       'NN_40_um', 'NN_50_um', 'NN_60_um', 'NN_70_um', 'NN_80_um', 'NN_90_um',\n",
       "       'NN_100_um'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (1656, 44)\n"
     ]
    }
   ],
   "source": [
    "#We are using the entire dataset to train the model, test data will be provided later by Sanne \n",
    "X_train_l = dat.drop(columns=['Class']) #,'Image_name','Image_x', 'Image_y'\n",
    "X_train = X_train_l.drop(columns=['Image','Name','Centroid_X','Centroid_Y']) \n",
    "print('training data shape:',X_train.shape)\n",
    "y_train = dat['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detection probability</th>\n",
       "      <th>Nucleus: Area ¬µm^2</th>\n",
       "      <th>Nucleus: Length ¬µm</th>\n",
       "      <th>Nucleus: Circularity</th>\n",
       "      <th>Nucleus: Solidity</th>\n",
       "      <th>Nucleus: Max diameter ¬µm</th>\n",
       "      <th>Nucleus: Min diameter ¬µm</th>\n",
       "      <th>Cell: Area ¬µm^2</th>\n",
       "      <th>Cell: Length ¬µm</th>\n",
       "      <th>Cell: Circularity</th>\n",
       "      <th>...</th>\n",
       "      <th>NN_10_um</th>\n",
       "      <th>NN_20_um</th>\n",
       "      <th>NN_30_um</th>\n",
       "      <th>NN_40_um</th>\n",
       "      <th>NN_50_um</th>\n",
       "      <th>NN_60_um</th>\n",
       "      <th>NN_70_um</th>\n",
       "      <th>NN_80_um</th>\n",
       "      <th>NN_90_um</th>\n",
       "      <th>NN_100_um</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8575</td>\n",
       "      <td>13.1628</td>\n",
       "      <td>13.2907</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.9150</td>\n",
       "      <td>3.4944</td>\n",
       "      <td>103.1323</td>\n",
       "      <td>37.8404</td>\n",
       "      <td>0.9051</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8796</td>\n",
       "      <td>15.2611</td>\n",
       "      <td>14.0081</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.7992</td>\n",
       "      <td>4.1628</td>\n",
       "      <td>120.9785</td>\n",
       "      <td>40.6755</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8670</td>\n",
       "      <td>16.7321</td>\n",
       "      <td>14.7662</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0758</td>\n",
       "      <td>4.3099</td>\n",
       "      <td>100.9326</td>\n",
       "      <td>38.6687</td>\n",
       "      <td>0.8482</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>52</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8827</td>\n",
       "      <td>18.6383</td>\n",
       "      <td>15.5263</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.3159</td>\n",
       "      <td>4.4388</td>\n",
       "      <td>124.4651</td>\n",
       "      <td>42.9339</td>\n",
       "      <td>0.8485</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>47</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8682</td>\n",
       "      <td>21.4955</td>\n",
       "      <td>16.7517</td>\n",
       "      <td>0.9626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.7030</td>\n",
       "      <td>5.0028</td>\n",
       "      <td>136.2816</td>\n",
       "      <td>44.2523</td>\n",
       "      <td>0.8745</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "      <td>49</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Detection probability  Nucleus: Area ¬µm^2  Nucleus: Length ¬µm  \\\n",
       "0                 0.8575              13.1628              13.2907   \n",
       "1                 0.8796              15.2611              14.0081   \n",
       "2                 0.8670              16.7321              14.7662   \n",
       "3                 0.8827              18.6383              15.5263   \n",
       "4                 0.8682              21.4955              16.7517   \n",
       "\n",
       "   Nucleus: Circularity  Nucleus: Solidity  Nucleus: Max diameter ¬µm  \\\n",
       "0                0.9364                1.0                     4.9150   \n",
       "1                0.9773                1.0                     4.7992   \n",
       "2                0.9643                1.0                     5.0758   \n",
       "3                0.9716                1.0                     5.3159   \n",
       "4                0.9626                1.0                     5.7030   \n",
       "\n",
       "   Nucleus: Min diameter ¬µm  Cell: Area ¬µm^2  Cell: Length ¬µm  \\\n",
       "0                     3.4944          103.1323           37.8404   \n",
       "1                     4.1628          120.9785           40.6755   \n",
       "2                     4.3099          100.9326           38.6687   \n",
       "3                     4.4388          124.4651           42.9339   \n",
       "4                     5.0028          136.2816           44.2523   \n",
       "\n",
       "   Cell: Circularity  ...  NN_10_um  NN_20_um  NN_30_um  NN_40_um  NN_50_um  \\\n",
       "0             0.9051  ...         1         1         2         7        10   \n",
       "1             0.9189  ...         1         1         1         4        10   \n",
       "2             0.8482  ...         1         3         5         7        11   \n",
       "3             0.8485  ...         1         1         4         6         9   \n",
       "4             0.8745  ...         1         1         4         6        11   \n",
       "\n",
       "   NN_60_um  NN_70_um  NN_80_um  NN_90_um  NN_100_um  \n",
       "0        15        22        30        37         50  \n",
       "1        17        24        34        38         49  \n",
       "2        14        25        35        52         65  \n",
       "3        17        26        36        47         63  \n",
       "4        18        24        35        49         64  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Detection probability', 'Nucleus: Area ¬µm^2', 'Nucleus: Length ¬µm',\n",
       "       'Nucleus: Circularity', 'Nucleus: Solidity',\n",
       "       'Nucleus: Max diameter ¬µm', 'Nucleus: Min diameter ¬µm',\n",
       "       'Cell: Area ¬µm^2', 'Cell: Length ¬µm', 'Cell: Circularity',\n",
       "       'Cell: Solidity', 'Cell: Max diameter ¬µm', 'Cell: Min diameter ¬µm',\n",
       "       'Nucleus/Cell area ratio', 'Hematoxylin: Nucleus: Mean',\n",
       "       'Hematoxylin: Nucleus: Median', 'Hematoxylin: Nucleus: Min',\n",
       "       'Hematoxylin: Nucleus: Max', 'Hematoxylin: Nucleus: Std.Dev.',\n",
       "       'Hematoxylin: Cytoplasm: Mean', 'Hematoxylin: Cytoplasm: Median',\n",
       "       'Hematoxylin: Cytoplasm: Min', 'Hematoxylin: Cytoplasm: Max',\n",
       "       'Hematoxylin: Cytoplasm: Std.Dev.', 'Hematoxylin: Membrane: Mean',\n",
       "       'Hematoxylin: Membrane: Median', 'Hematoxylin: Membrane: Min',\n",
       "       'Hematoxylin: Membrane: Max', 'Hematoxylin: Membrane: Std.Dev.',\n",
       "       'Hematoxylin: Cell: Mean', 'Hematoxylin: Cell: Median',\n",
       "       'Hematoxylin: Cell: Min', 'Hematoxylin: Cell: Max',\n",
       "       'Hematoxylin: Cell: Std.Dev.', 'NN_10_um', 'NN_20_um', 'NN_30_um',\n",
       "       'NN_40_um', 'NN_50_um', 'NN_60_um', 'NN_70_um', 'NN_80_um', 'NN_90_um',\n",
       "       'NN_100_um'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My own functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for custom classification metrics \n",
    "\n",
    "## Accuracy per class \n",
    "def astro_acc(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    acc_c = cm.diagonal()\n",
    "    return acc_c[0] #astrocytes acc\n",
    "\n",
    "def neuron_acc(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    acc_c = cm.diagonal()\n",
    "    return acc_c[1] #neuron acc\n",
    "\n",
    "def oligo_acc(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    acc_c = cm.diagonal()\n",
    "    return acc_c[2] #oligo acc\n",
    "\n",
    "def others_acc(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    acc_c = cm.diagonal()\n",
    "    return acc_c[3] #ignore acc\n",
    "\n",
    "\n",
    "\n",
    "## Confusion per class: \n",
    "\n",
    "## Astro\n",
    "def A_as_N(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[0][1] # percentage that A is wrongly classified as N   \n",
    "\n",
    "def A_as_O(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[0][2] # percentage that A is wrongly classified as O       \n",
    "\n",
    "\n",
    "def A_as_Others(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[0][3]   \n",
    "\n",
    "##Neurons \n",
    "\n",
    "def N_as_A(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[1][0] \n",
    "\n",
    "def N_as_O(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[1][2] \n",
    "\n",
    "def N_as_Others(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[1][3] \n",
    "\n",
    "\n",
    "## Oligo \n",
    "\n",
    "def O_as_A(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[2][0] \n",
    "\n",
    "def O_as_N(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[2][1] \n",
    "\n",
    "def O_as_Others(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[2][3] \n",
    "\n",
    "## Others \n",
    "\n",
    "def Others_as_A(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[3][0] \n",
    "\n",
    "def Others_as_N(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[3][1] \n",
    "\n",
    "def Others_as_O(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')\n",
    "    return cm[3][2] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for custom classification metrics: RAW VALUES \n",
    "\n",
    "\n",
    "## Confusion per class: \n",
    "\n",
    "## Astro\n",
    "def A_as_N_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[0][1] # percentage that A is wrongly classified as N   \n",
    "\n",
    "def A_as_O_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[0][2] # percentage that A is wrongly classified as O       \n",
    "\n",
    "\n",
    "def A_as_Others_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[0][3]   \n",
    "\n",
    "##Neurons \n",
    "\n",
    "def N_as_A_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[1][0] \n",
    "\n",
    "def N_as_O_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[1][2] \n",
    "\n",
    "def N_as_Others_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[1][3] \n",
    "\n",
    "\n",
    "## Oligo \n",
    "\n",
    "def O_as_A_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[2][0] \n",
    "\n",
    "def O_as_N_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[2][1] \n",
    "\n",
    "def O_as_Others_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[2][3] \n",
    "\n",
    "## Others \n",
    "\n",
    "def Others_as_A_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[3][0] \n",
    "\n",
    "def Others_as_N_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[3][1] \n",
    "\n",
    "def Others_as_O_r(clf,X,y): \n",
    "    y_pred = clf.predict(X)\n",
    "    cm = confusion_matrix(y,y_pred,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "    return cm[3][2] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Precision-recall score\n",
    "def precision_recall_auc(clf,X,y):\n",
    "    #Variables\n",
    "    pr_score={}\n",
    "    \n",
    "    #get y prob predictions\n",
    "    y_prob_pred = clf.predict_proba(X)\n",
    "    \n",
    "    #Convert true y name into numerical classes\n",
    "    y_true_numeric = name_to_numeric_classes(y)\n",
    "    \n",
    "    #get number of classes\n",
    "    n_class = list(set(y))\n",
    "    \n",
    "    #create PR curve using OVR approach \n",
    "    for i in range(len(n_class)): # for each class, calculate roc_curve \n",
    "        p, r, thresh = precision_recall_curve(y_true_numeric, y_prob_pred[:,i], pos_label=i)\n",
    "        pr_score[i] = auc(r,p) #recall on x axis, precision on y axis\n",
    "        \n",
    "    #Combine all pr-scores using 'macro' method\n",
    "    pr_auc = mean(pr_score.values())\n",
    "    return pr_auc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDITIONAL FUNCTIONS\n",
    "\n",
    "#FUNCTIONS\n",
    "\n",
    "# Get all class-specific thresholds from best params\n",
    "\n",
    "def get_threshold(best_params):\n",
    "    class_thresholds=[]\n",
    "    for i in best_params:\n",
    "        t = best_params[i][0]\n",
    "        class_thresholds.append(t)\n",
    "    return class_thresholds \n",
    "\n",
    "#Thresholding method 5: using ratio, ambiguous cells are: \n",
    "# 1) When predicted probabilities < thresholds, i.e. diff = -ve (lower end)\n",
    "# 2) When more than 1 class-specific threshold is passed, i.e. more than 1 positive diff scores (upper end)\n",
    "\n",
    "def threshold_list_of_classes_5(y_pred_prob,best_params):\n",
    "    \n",
    "    thresholded_classes=[]\n",
    "    for i in y_pred_prob: #for each cell (containing 4 class probabilities)\n",
    "        \n",
    "        #Get cell 4 class-specific threshold values: \n",
    "        thresholds = get_threshold(best_params)\n",
    "        \n",
    "        # Calculate predicted probability - threshold = difference for each of the 4 classes \n",
    "        differences = (i-thresholds)/thresholds\n",
    "        \n",
    "        #Count number of positive or equal (0) differences \n",
    "        count = np.count_nonzero(differences>=0)\n",
    "        \n",
    "        if (count==1): #only assign class when 1 class passes the threshold \n",
    "            pred_class = np.argmax(differences)\n",
    "        else: #Otherwise, label as ambiguous (when more than 1 class passes, or when no class passes)\n",
    "            pred_class=4\n",
    "\n",
    "        #putting prediction in a list\n",
    "        thresholded_classes.append(pred_class)\n",
    "\n",
    "    thresholded_classes_ = numeric_to_name_classes(thresholded_classes)\n",
    "    return thresholded_classes_\n",
    "             \n",
    "#Thresholding method 4  using ratio instead of raw difference\n",
    "def threshold_list_of_classes_4 (y_pred_prob,best_params):\n",
    "    \n",
    "    thresholded_classes=[]\n",
    "    for i in y_pred_prob: #for each cell (containing 4 class probabilities)\n",
    "        \n",
    "        #Get cell 4 class-specific threshold values: \n",
    "        thresholds = get_threshold(best_params)\n",
    "        \n",
    "        # Calculate predicted probability - threshold = difference for each of the 4 classes \n",
    "        differences = (i-thresholds)/thresholds\n",
    "        \n",
    "        #Check if there is at last one positive diff probability\n",
    "        if (np.any(differences>0)): # If true, \n",
    "            \n",
    "            #get index (indicative of class) of the highest probability difference\n",
    "            pred_class = np.argmax(differences) \n",
    "            \n",
    "        else: #If all diff probabilities are NEGATIVE\n",
    "            pred_class = 4 # Assign cell class as 'ambiguous'\n",
    "\n",
    "        #putting prediction in a list\n",
    "        thresholded_classes.append(pred_class)\n",
    "\n",
    "    thresholded_classes_ = numeric_to_name_classes(thresholded_classes)\n",
    "    return thresholded_classes_\n",
    "\n",
    "\n",
    "#Thresholding method 3)\n",
    "\n",
    "def threshold_list_of_classes_3 (y_pred_prob,best_params):\n",
    "    \n",
    "    thresholded_classes=[]\n",
    "    for i in y_pred_prob: #for each cell (containing 4 class probabilities)\n",
    "        \n",
    "        #Get cell 4 class-specific threshold values: \n",
    "        thresholds = get_threshold(best_params)\n",
    "        \n",
    "        # Calculate predicted probability - threshold = difference for each of the 4 classes \n",
    "        differences = i-thresholds\n",
    "        \n",
    "        #Check if there is at last one positive diff probability\n",
    "        if (np.any(differences>0)): # If true, \n",
    "            \n",
    "            #get index (indicative of class) of the highest probability difference\n",
    "            pred_class = np.argmax(differences) \n",
    "            \n",
    "        else: #If all diff probabilities are NEGATIVE\n",
    "            pred_class = 4 # Assign cell class as 'ambiguous'\n",
    "\n",
    "        #putting prediction in a list\n",
    "        thresholded_classes.append(pred_class)\n",
    "\n",
    "    thresholded_classes_ = numeric_to_name_classes(thresholded_classes)\n",
    "    return thresholded_classes_\n",
    "\n",
    "#Thresholding method 2)\n",
    "def threshold_list_of_classes_2(y_pred_prob,best_params):\n",
    "    \n",
    "    thresholded_classes=[]\n",
    "    for i in y_pred_prob: #for each cell \n",
    "        \n",
    "        #Get threshold values: \n",
    "        thresholds = get_threshold(best_params)\n",
    "        \n",
    "        # Calculate predicted probability - threshold = difference \n",
    "        differences = i-thresholds\n",
    "               \n",
    "        #get index (indicative of class) of the highest probability\n",
    "        pred_class = np.argmax(differences)         \n",
    "\n",
    "        #putting prediction in a list\n",
    "        thresholded_classes.append(pred_class)\n",
    "\n",
    "        \n",
    "    thresholded_classes_ = numeric_to_name_classes(thresholded_classes)\n",
    "    return thresholded_classes_\n",
    "\n",
    "\n",
    "# To convert numeric classes to its corresponding name classes \n",
    "def numeric_to_name_classes(numeric_classes):\n",
    "    output=[]\n",
    "    for i in numeric_classes:\n",
    "        if (i==0):\n",
    "            c = 'Astro'\n",
    "        elif(i==1):\n",
    "            c='Neuron'\n",
    "        elif(i==2):\n",
    "            c='Oligo'\n",
    "        elif(i==3):\n",
    "            c='Others'\n",
    "        elif(i==4):\n",
    "            c='Ambiguous'\n",
    "        else:\n",
    "            print('SOMETHING IS WRONG')\n",
    "        output.append(c)\n",
    "    return output\n",
    "\n",
    "# To convert name classes to its corresponding numeric classes: \n",
    "def name_to_numeric_classes(name_classes):\n",
    "    output=[]\n",
    "    for i in name_classes: \n",
    "        if (i == 'Astro'): \n",
    "            x=0\n",
    "        elif(i == 'Neuron'): \n",
    "            x=1\n",
    "        elif(i == 'Oligo'): \n",
    "            x=2\n",
    "        elif(i=='Others'):\n",
    "            x=3\n",
    "        elif(i=='Ambiguous'):\n",
    "            x=4\n",
    "        else:\n",
    "            print('SOMETHING IS WRONG')\n",
    "            break\n",
    "        output.append(x)\n",
    "    return output\n",
    "    \n",
    "# Create roc curve for each class in multi-classification problem\n",
    "\n",
    "def multiclass_roc_curves(n_class,test_y_numeric,predy):\n",
    "    \n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    thresh ={}\n",
    "    \n",
    "    #calcualte roc curve locations \n",
    "    for i in range(n_class): # for each class, calculate roc_curve \n",
    "        fpr[i], tpr[i], thresh[i] = roc_curve(test_y_numeric, predy[:,i], pos_label=i)\n",
    "    \n",
    "    return fpr,tpr,thresh\n",
    "\n",
    "#Find the best position on the roc curve for multi-classification problem\n",
    "def best_param_gmean(n_class,fpr,tpr,thresh):\n",
    "    #calculate g-mean for each threshold \n",
    "    #gmeans={}\n",
    "    best_params={}\n",
    "    class_names=['Astro','Neuron','Oligo','Others']\n",
    "    for i in range(n_class):\n",
    "        tpr_ = tpr[i]\n",
    "        fpr_ = fpr[i]\n",
    "        gm = np.sqrt(tpr_*(1-fpr_))\n",
    "        t = thresh[i]\n",
    "        #gmeans[i]=gm\n",
    "        ix = np.argmax(gm)\n",
    "        best_params[i] = (t[ix],gm[ix],fpr_[ix],tpr_[ix])\n",
    "        #print(gm)\n",
    "       # print(class_names[i],'Best Threshold=%f, G-Mean=%.3f, fpr=%f, tpr=%f' % (t[ix], gm[ix],fpr_[ix],tpr_[ix]))\n",
    "        #print('--------------------------------------------------')\n",
    "    return best_params\n",
    "\n",
    "def multiclass_PR_curves(n_class,test_y_numeric,predy):\n",
    "    \n",
    "    precision = {}\n",
    "    recall = {}\n",
    "    thresh ={}\n",
    "    \n",
    "    #calcualte roc curve locations \n",
    "    for i in range(n_class): # for each class, calculate roc_curve \n",
    "        precision[i], recall[i], thresh[i] = precision_recall_curve(test_y_numeric, predy[:,i], pos_label=i)\n",
    "    \n",
    "    return precision,recall,thresh\n",
    "\n",
    "#Find the best position on the roc curve for multi-classification problem\n",
    "def best_param_f_score(n_class,precision,recall,thresh):\n",
    "    #calculate g-mean for each threshold \n",
    "    #f_scores={}\n",
    "    best_params={}\n",
    "    class_names=['Astro','Neuron','Oligo','Others']\n",
    "    for i in range(n_class):\n",
    "        p = precision[i]\n",
    "        r = recall[i]\n",
    "        nu=(2*p*r)\n",
    "        de=(p+r) \n",
    "        f_score = np.divide(nu,de,out=np.zeros_like(nu),where=de != 0) #(2*p*r)/(p+r)\n",
    "        t = thresh[i]\n",
    "        #f_scores[i]=f_score\n",
    "        ix = np.argmax(f_score)\n",
    "        best_params[i] = (t[ix],f_score[ix],p[ix],r[ix])\n",
    "        #print(gm)\n",
    "       # print(class_names[i],'Best Threshold=%f, G-Mean=%.3f, fpr=%f, tpr=%f' % (t[ix], gm[ix],fpr_[ix],tpr_[ix]))\n",
    "        #print('--------------------------------------------------')\n",
    "    return best_params\n",
    "\n",
    "#Thresholding function\n",
    "def prob_thresholding(y_pred_prob,y_pred,threshold):\n",
    "    thresholded_class =[]\n",
    "    for i in range(0,len(y_pred_prob)):\n",
    "        if(max(y_pred_prob[i])<threshold):\n",
    "            c='Ambiguous'\n",
    "        else:\n",
    "            c=y_pred[i]\n",
    "        thresholded_class.append(c)\n",
    "    return thresholded_class\n",
    "\n",
    "#Removing ambiguous class from thresholded class & y_predict\n",
    "def remove_amb_class(t_class,y_test):\n",
    "    \n",
    "    #Get indices of instances with no ambiguous label \n",
    "    x = pd.Series(t_class)\n",
    "    y_pred_no_amb = x[x!='Ambiguous']\n",
    "    y_pred_no_amb_indices = y_pred_no_amb.index\n",
    "    \n",
    "    #Extract these instances fom y_pred\n",
    "    #y_predict_no_amb = y_predict.iloc[pred_no_amb_indices]\n",
    "    \n",
    "    #Subset y_test\n",
    "    y_test_no_amb = y_test.iloc[y_pred_no_amb_indices]\n",
    "    \n",
    "    return (y_pred_no_amb,y_test_no_amb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning - random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('normalizer', MinMaxScaler()),\n",
       " ('selector', RFE(estimator=SVC(kernel='linear'))),\n",
       " ('clf', BalancedRandomForestClassifier())]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('normalizer',MinMaxScaler()),\n",
    "    ('selector',RFE(SVC(kernel='linear'))), \n",
    "    ('clf',BalancedRandomForestClassifier())\n",
    "])\n",
    "#pipeline.set_params(clf=RandomForestClassifier())\n",
    "pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.005, 0.01, 0.015, 0.02, 0.025, 0.03]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccp_alphas = [float(x) for x in np.linspace(start=0, stop=0.03, num=7) ]\n",
    "ccp_alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-7facb1f5bd31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m                               })\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m \u001b[0mrf_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1631\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m         \u001b[1;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1633\u001b[1;33m         evaluate_candidates(ParameterSampler(\n\u001b[0m\u001b[0;32m   1634\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1635\u001b[0m             random_state=self.random_state))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ### Hyper parameters to tune\n",
    "\n",
    "# #Number of trees in random forest \n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# #Number of features to consider at every split\n",
    "# max_features = ['auto', 'sqrt']\n",
    "\n",
    "# #Maximum number of levels in tree \n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "\n",
    "# #Minimum number of samples required to split an internal node \n",
    "# min_samples_split = [2, 5, 10]\n",
    "\n",
    "# #Minimum number of samples required at each leaf node \n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# #Method for selecting samples for training each tree \n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# #sampling strategy\n",
    "# sampling_strategy=['auto','all','not majority','majority']\n",
    "\n",
    "# #ccp_alphas \n",
    "# ccp_alphas = [float(x) for x in np.linspace(start=0, stop=0.03, num=7) ]#[float(x) for x in np.linspace(start=0, stop=1, num=10) ]\n",
    "\n",
    "# ## Create the random grid \n",
    "# random_grid = {'selector__n_features_to_select':[30,32,34,36,38,40],\n",
    "#                 'clf__n_estimators': n_estimators,\n",
    "#                'clf__max_features': max_features,\n",
    "#                'clf__max_depth': max_depth,\n",
    "#                'clf__min_samples_split': min_samples_split,\n",
    "#                'clf__min_samples_leaf': min_samples_leaf,\n",
    "#               'clf__bootstrap': bootstrap,\n",
    "#               'clf__random_state':[42],\n",
    "#                'clf__sampling_strategy':sampling_strategy, \n",
    "#                'clf__ccp_alpha':ccp_alphas\n",
    "#              # 'clf__class_weight':['balanced']\n",
    "#               } # newly added\n",
    "# #pprint(random_grid)\n",
    "\n",
    "# rf_random = RandomizedSearchCV(pipeline,\n",
    "#                              param_distributions=random_grid, \n",
    "#                              n_iter=100,\n",
    "#                              cv=10,\n",
    "#                              verbose=2,\n",
    "#                             random_state=42,\n",
    "#                             n_jobs=-1,\n",
    "#                               refit='PR_AUC', # use this metric to evaluate performance of parameters \n",
    "#                       scoring={'PR_AUC':precision_recall_auc,\n",
    "#                           'roc_auc_ovr_weighted':'roc_auc_ovr_weighted',\n",
    "#                             'roc_auc_ovo':'roc_auc_ovo',\n",
    "#                               'balanced_accuracy':'balanced_accuracy',\n",
    "#                                'f1_weighted':'f1_weighted',\n",
    "#                                'Astro_accuracy': astro_acc,\n",
    "#                                'Neuron_accuracy':neuron_acc,\n",
    "#                                'Oligo_accuracy':oligo_acc,\n",
    "#                                'Others_accuracy':others_acc,\n",
    "#                                'A_as_N':A_as_N,\n",
    "#                                'A_as_O':A_as_O,\n",
    "#                                'A_as_Others':A_as_Others,\n",
    "#                                'N_as_A':N_as_A,\n",
    "#                                'N_as_O':N_as_O,\n",
    "#                                'N_as_Others':N_as_Others,\n",
    "#                                'O_as_A':O_as_A,\n",
    "#                                'O_as_N':O_as_N,\n",
    "#                                'O_as_Others':O_as_Others,\n",
    "#                                'Others_as_A':Others_as_A,\n",
    "#                                'Others_as_N':Others_as_N,\n",
    "#                                'Others_as_O':Others_as_O\n",
    "#                               })\n",
    "\n",
    "# rf_random.fit(X_train,y_train)\n",
    "\n",
    "# print(rf_random.best_score_)\n",
    "# print(rf_random.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
    "0.852294027848721\n",
    "{'selector__n_features_to_select': 30, 'clf__sampling_strategy': 'not majority', 'clf__random_state': 42, 'clf__n_estimators': 600, 'clf__min_samples_split': 10, 'clf__min_samples_leaf': 1, 'clf__max_features': 'sqrt', 'clf__max_depth': 60, 'clf__ccp_alpha': 0.0, 'clf__bootstrap': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Digging into more details \n",
    "# print(\"PR-AUC:\",\n",
    "#      rf_random.cv_results_['mean_test_PR_AUC'][rf_random.best_index_]*100)\n",
    "# print(\"ROC-AUC:\",\n",
    "#      rf_random.cv_results_['mean_test_roc_auc_ovr_weighted'][rf_random.best_index_]*100)\n",
    "# print(\"ROC-AUC:\",\n",
    "#      rf_random.cv_results_['mean_test_roc_auc_ovo'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Balanced accuracy:\",\n",
    "#       rf_random.cv_results_['mean_test_balanced_accuracy'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"F1_weighted:\",\n",
    "#       rf_random.cv_results_['mean_test_f1_weighted'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Astrocyte accuracy:\",\n",
    "#       rf_random.cv_results_['mean_test_Astro_accuracy'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Neuron accuracy:\",\n",
    "#       rf_random.cv_results_['mean_test_Neuron_accuracy'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Oligo accuracy:\",\n",
    "#       rf_random.cv_results_['mean_test_Oligo_accuracy'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Others accuracy:\",\n",
    "#       rf_random.cv_results_['mean_test_Others_accuracy'][rf_random.best_index_]*100)\n",
    "\n",
    "\n",
    "# print(\"Classified A as N:\",\n",
    "#       rf_random.cv_results_['mean_test_A_as_N'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified A as O:\",\n",
    "#       rf_random.cv_results_['mean_test_A_as_O'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified A as Others:\",\n",
    "#       rf_random.cv_results_['mean_test_A_as_Others'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified N as A:\",\n",
    "#       rf_random.cv_results_['mean_test_N_as_A'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified N as O:\",\n",
    "#       rf_random.cv_results_['mean_test_N_as_O'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified N as Others:\",\n",
    "#       rf_random.cv_results_['mean_test_N_as_Others'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified O as A:\",\n",
    "#       rf_random.cv_results_['mean_test_O_as_A'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified O as N:\",\n",
    "#       rf_random.cv_results_['mean_test_O_as_N'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified O as Others:\",\n",
    "#       rf_random.cv_results_['mean_test_O_as_Others'][rf_random.best_index_]*100)\n",
    "\n",
    "\n",
    "# print(\"Classified Others as A:\",\n",
    "#       rf_random.cv_results_['mean_test_Others_as_A'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified Others as N:\",\n",
    "#       rf_random.cv_results_['mean_test_Others_as_N'][rf_random.best_index_]*100)\n",
    "\n",
    "# print(\"Classified Others as O:\",\n",
    "#       rf_random.cv_results_['mean_test_Others_as_O'][rf_random.best_index_]*100)\n",
    "                                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PR-AUC: 85.2294027848721\n",
    "ROC-AUC: 95.75814823565217\n",
    "ROC-AUC: 94.30629270300071\n",
    "Balanced accuracy: 76.4833961098148\n",
    "F1_weighted: 81.00526513749949\n",
    "Astrocyte accuracy: 61.929824561403514\n",
    "Neuron accuracy: 82.0\n",
    "Oligo accuracy: 92.70529049010061\n",
    "Others accuracy: 69.2984693877551\n",
    "Classified A as N: 16.608187134502923\n",
    "Classified A as O: 12.923976608187132\n",
    "Classified A as Others: 8.538011695906432\n",
    "Classified N as A: 13.0\n",
    "Classified N as O: 0.5\n",
    "Classified N as Others: 4.5\n",
    "Classified O as A: 3.586497890295358\n",
    "Classified O as N: 0.25478740668614086\n",
    "Classified O as Others: 3.4534242129178843\n",
    "Classified Others as A: 8.205782312925171\n",
    "Classified Others as N: 6.164965986394557\n",
    "Classified Others as O: 16.33078231292517"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual cross validation, using PR curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=None, shuffle=False)\n",
      "mean ROC AUC: 0.9575814823565217\n",
      "--------------------------------\n",
      "mean log loss: 0.4988873125242989\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "### manual cross-validation method \n",
    "x= X_train\n",
    "y=y_train\n",
    "## Setting up cross-validation \n",
    "skf = StratifiedKFold(n_splits=10) # shuffling = False, no need to set random_state\n",
    "skf.get_n_splits(x,y) # using only training data\n",
    "print(skf)\n",
    "\n",
    "#for train_index, test_index in skf.split(x,y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    #print(\"Train_size:\", train_index.size, \"Test_size:\", test_index.size)\n",
    "    \n",
    "## Training \n",
    "accuracies = []\n",
    "accuracies_c = []\n",
    "\n",
    "t_accuracies= []\n",
    "t_accuracies_c= []\n",
    "\n",
    "reports = []\n",
    "reports_c = []\n",
    "\n",
    "t_reports= []\n",
    "t_reports_c= []\n",
    "\n",
    "confusion_matrices = []\n",
    "confusion_matrices_c = [] \n",
    "\n",
    "t_confusion_matrices=[]\n",
    "t_confusion_matrices_c=[]\n",
    "\n",
    "#train_features =[] \n",
    "#train_n_features=[]\n",
    "y_preds = []\n",
    "y_preds_c = []\n",
    "\n",
    "y_preds_t =[]\n",
    "y_preds_t_c =[]\n",
    "\n",
    "y_prob_preds = []\n",
    "y_prob_preds_c = []\n",
    "\n",
    "y_cv_test=[]\n",
    "x_cv_test=[]\n",
    "\n",
    "roc_auc_scores=[]\n",
    "roc_auc_scores_c=[]\n",
    "\n",
    "log_losses=[]\n",
    "log_losses_c=[]\n",
    "\n",
    "#brier_scores=[]\n",
    "#brier_scores_c=[]\n",
    "\n",
    "best_parameters=[]\n",
    "best_parameters_c=[]\n",
    "\n",
    "for train_index, test_index in skf.split(x,y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    #print(\"Train_size:\", train_index.size, \"Test_size:\", test_index.size)\n",
    "    x_train_, x_test_ = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train_, y_test_ = y[train_index], y[test_index]\n",
    "    x_test_l = X_train_l.iloc[test_index]\n",
    "    #print(\"n of each cell types at test:\\n\", y_test_.value_counts())\n",
    "    \n",
    "    ## 1) Create classifier \n",
    "    \n",
    "    pipeline_final=Pipeline([\n",
    "    ('normalizer',MinMaxScaler()),\n",
    "    ('selector',RFE(SVC(kernel='linear'),n_features_to_select=30)), \n",
    "    ('clf', BalancedRandomForestClassifier(sampling_strategy= 'not majority', random_state= 42,\n",
    "                                           n_estimators= 600, min_samples_split=10, min_samples_leaf= 1,\n",
    "                                           max_features= 'sqrt', max_depth= 60, ccp_alpha= 0.0, bootstrap= True))\n",
    "                                           ### MAKE SURE THESE ARE CORRECT \n",
    "                \n",
    "])\n",
    "# {'selector__n_features_to_select': 32, 'clf__sampling_strategy': 'not majority', 'clf__random_state': 42,\n",
    "#  'clf__n_estimators': 1800, 'clf__min_samples_split': 2, 'clf__min_samples_leaf': 2,\n",
    "#  'clf__max_features': 'auto', 'clf__max_depth': 40, 'clf__ccp_alpha': 0.005, 'clf__bootstrap': True}\n",
    "\n",
    "# {'selector__n_features_to_select': 30, 'clf__sampling_strategy': 'not majority',\n",
    "#  'clf__random_state': 42, 'clf__n_estimators': 600, 'clf__min_samples_split': 10, 'clf__min_samples_leaf': 1,\n",
    "#  'clf__max_features': 'sqrt', 'clf__max_depth': 60, 'clf__ccp_alpha': 0.0, 'clf__bootstrap': True}\n",
    "\n",
    "    # 2) Train the calibrated classifier with 'training' data (x,y) \n",
    "    pipeline_final.fit(x_train_,y_train_)\n",
    "    \n",
    "    # 3) Get class probability predictions for 'test' data \n",
    "    y_prob_predict = pipeline_final.predict_proba(x_test_)\n",
    "    \n",
    "    # 4.1) For thresholding: convert y_test_ from name classes to numeric classes\n",
    "    y_test_numeric = name_to_numeric_classes(y_test_)\n",
    "    \n",
    "    # 4.2) For thresholding: use predicted class probabilities to calculate ROC curve for each class vs rest\n",
    "    \n",
    "    precision,recall,thresh = multiclass_PR_curves(4,y_test_numeric,y_prob_predict)\n",
    "    \n",
    "    # 4.3) For thresholding: from ROC curves, find the best location (fpr,tpr,thresh) for each class \n",
    "    # Evaluated based on g-mean \n",
    "    best_params_ = best_param_f_score(4,precision,recall,thresh)\n",
    "    best_parameters.append(best_params_)\n",
    "    \n",
    "    # 4.4) For thresholding: apply thresholding to each class to create crisp class label \n",
    "    t_class = threshold_list_of_classes_5(y_prob_predict,best_params_)\n",
    "    \n",
    "    # 5) Get class labels using default thresholding value (0.5)\n",
    "    y_predict = pipeline_final.predict(x_test_)\n",
    "    \n",
    "    # 6) Put predictions (labels &probabilities & t_labels) in the corresponding list\n",
    "    y_preds.append(y_predict)\n",
    "    \n",
    "    y_prob_preds.append(y_prob_predict)\n",
    "    \n",
    "    y_preds_t.append(t_class)\n",
    "    \n",
    "    y_cv_test.append(y_test_) # for visualisation purposes later on\n",
    "    x_cv_test.append(x_test_l)\n",
    "    \n",
    "    # 7) Remove 'ambiguous class' from t_class & y_test_ - for accuracy calculation\n",
    "    (y_predict_no_amb,y_test_no_amb) = remove_amb_class(t_class,y_test_)\n",
    "    \n",
    "    # 8) Calculate and put Performance metric (balanced accuracy) per fold into a list\n",
    "    accuracies.append(balanced_accuracy_score(y_test_,y_predict)) ## using BALANCED ACC.\n",
    "    \n",
    "    t_accuracies.append(balanced_accuracy_score(y_test_no_amb,y_predict_no_amb))\n",
    "    \n",
    "    #8.1) Compute classification reports\n",
    "    reports.append(classification_report(y_test_,y_predict,output_dict=True)) \n",
    "  #  reports_c.append(classification_report(y_test_,y_predict_c,output_dict=True)) \n",
    "    \n",
    "    t_reports.append(classification_report(y_test_no_amb,y_predict_no_amb,output_dict=True))\n",
    "    \n",
    "    # 9) Calculate and put ROC AUC scores per fold into a list \n",
    "    roc_auc_scores.append(roc_auc_score(y_test_,y_prob_predict,multi_class='ovr',average='weighted'))\n",
    "    \n",
    "    #9.1) Calculate and put log loss per fold into a list\n",
    "    log_losses.append(log_loss(y_test_,y_prob_predict))\n",
    "\n",
    "    \n",
    "    # 10) Create confusion matrices for default & thresholded results per fold then put in a list \n",
    "    cm = confusion_matrix(y_test_,y_predict, labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"]) #,normalize='true'\n",
    "    \n",
    "    cm_t = confusion_matrix(y_test_no_amb,y_predict_no_amb, labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])#,normalize='true'\n",
    "    \n",
    "    confusion_matrices.append(cm)\n",
    "    \n",
    "    t_confusion_matrices.append(cm_t)\n",
    "\n",
    "print('mean ROC AUC:',mean(roc_auc_scores))\n",
    "print('--------------------------------')\n",
    "print('mean log loss:',mean(log_losses))\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting information from best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thresholds \n",
    "astro_t = [] \n",
    "neuron_t=[]\n",
    "oligo_t=[]\n",
    "others_t=[]\n",
    "#G-means\n",
    "astro_gm=[]\n",
    "neuron_gm=[]\n",
    "oligo_gm=[]\n",
    "others_gm=[]\n",
    "\n",
    "#Info extraction \n",
    "for fold in best_parameters:\n",
    "    a_t = fold[0][0]\n",
    "    n_t = fold[1][0]\n",
    "    o_t = fold[2][0]\n",
    "    ot_t = fold[3][0]\n",
    "    \n",
    "    a_gm = fold[0][1]\n",
    "    n_gm = fold[1][1]\n",
    "    o_gm = fold[2][1]\n",
    "    ot_gm = fold[3][1]\n",
    "    \n",
    "    astro_t.append(a_t)\n",
    "    neuron_t.append(n_t)\n",
    "    oligo_t.append(o_t)\n",
    "    others_t.append(ot_t)\n",
    "    \n",
    "    astro_gm.append(a_gm)\n",
    "    neuron_gm.append(n_gm)\n",
    "    oligo_gm.append(o_gm)\n",
    "    others_gm.append(ot_gm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON CALIBRATED\n",
      "mean astro threshold: 0.3973044856910375 , mean f1_macro: 0.6694727377445115\n",
      "mean neuron threshold: 0.45273629257841896 , mean f1_macro: 0.8547011614208093\n",
      "mean oligo threshold: 0.5795161596615945 , mean f1_macro: 0.9204556173272136\n",
      "mean others threshold: 0.24605117846048574 , mean f1_macro: 0.8408519357073003\n",
      "1.6756081163915366\n"
     ]
    }
   ],
   "source": [
    "print(\"NON CALIBRATED\")\n",
    "print('mean astro threshold:', mean(astro_t), ', mean f1_macro:',mean(astro_gm))\n",
    "print('mean neuron threshold:', mean(neuron_t), ', mean f1_macro:',mean(neuron_gm))\n",
    "print('mean oligo threshold:', mean(oligo_t), ', mean f1_macro:',mean(oligo_gm))\n",
    "print('mean others threshold:', mean(others_t), ', mean f1_macro:',mean(others_gm))\n",
    "print(mean(astro_t)+mean(neuron_t)+mean(oligo_t)+mean(others_t)) #is it okay that it is above 1? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NO Thresholding:** Non-calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with no thresholding: 76.4833961098148\n",
      "Macro avg F1  75.59362112648908\n",
      "Weighted avg F1  81.00526513749949\n",
      "--------------------------\n",
      "[[116  31  24  16]\n",
      " [ 26 164   1   9]\n",
      " [ 28   2 726  27]\n",
      " [ 40  30  79 337]]\n",
      "[[62.03208556 16.57754011 12.8342246   8.55614973]\n",
      " [13.         82.          0.5         4.5       ]\n",
      " [ 3.57598978  0.25542784 92.72030651  3.44827586]\n",
      " [ 8.23045267  6.17283951 16.25514403 69.34156379]]\n",
      "--------------------------\n",
      "Astro accuracy 62.03208556149733\n",
      "Neuron accuracy 82.0\n",
      "Oligo accuracy 92.72030651340997\n",
      "Others accuracy 69.34156378600824\n",
      "--------------------------\n",
      "Astro f1-score  58.945445973757394\n",
      "Neuron f1-score  76.7495487617384\n",
      "Oligo f1-score  90.03034845776652\n",
      "Others f1-score  76.64914131269401\n",
      "--------------------------\n",
      "Macro avg precision 76.35357580147054\n",
      "Macro avg recall  76.4833961098148\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix across 10 folds, WITHOUT thresholding \n",
    "print('with no thresholding:',mean(accuracies)*100)\n",
    "print('Macro avg F1 ',mean([i['macro avg']['f1-score'] for i in reports])*100)\n",
    "print('Weighted avg F1 ',mean([i['weighted avg']['f1-score'] for i in reports])*100)\n",
    "\n",
    "print(\"--------------------------\")\n",
    "C=sum(confusion_matrices)\n",
    "final_cm =  C.astype('float') / C.sum(axis=1)[:, np.newaxis]*100 #normalize(sum(confusion_matrices))*100\n",
    "print(C)\n",
    "print(final_cm)\n",
    "print(\"--------------------------\")\n",
    "print(\"Astro accuracy\",final_cm[0][0])\n",
    "print(\"Neuron accuracy\",final_cm[1][1])\n",
    "print(\"Oligo accuracy\",final_cm[2][2])\n",
    "print(\"Others accuracy\",final_cm[3][3])\n",
    "print(\"--------------------------\")\n",
    "# F1-score per class: \n",
    "print('Astro f1-score ',mean([i['Astro']['f1-score'] for i in reports])*100)\n",
    "print('Neuron f1-score ',mean([i['Neuron']['f1-score'] for i in reports])*100)\n",
    "print('Oligo f1-score ',mean([i['Oligo']['f1-score'] for i in reports])*100)\n",
    "print('Others f1-score ',mean([i['Others']['f1-score'] for i in reports])*100)\n",
    "print(\"--------------------------\")\n",
    "print('Macro avg precision',mean([i['macro avg']['precision'] for i in reports])*100)\n",
    "print('Macro avg recall ',mean([i['macro avg']['recall'] for i in reports])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thresholding:** Non-calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with thresholding (non-calibrated) ACC : 87.16553912430388\n",
      "Macro avg F1  86.49567115435103\n",
      "Weighted avg F1  89.8817067045254\n",
      "--------------------------\n",
      "[[116  13   5  15]\n",
      " [ 15 163   1   3]\n",
      " [ 17   2 683  26]\n",
      " [ 11  10  32 367]]\n",
      "[[77.85234899  8.72483221  3.3557047  10.06711409]\n",
      " [ 8.24175824 89.56043956  0.54945055  1.64835165]\n",
      " [ 2.33516484  0.27472527 93.81868132  3.57142857]\n",
      " [ 2.61904762  2.38095238  7.61904762 87.38095238]]\n",
      "--------------------------\n",
      "Astro accuracy 77.85234899328859\n",
      "Neuron accuracy 89.56043956043956\n",
      "Oligo accuracy 93.81868131868131\n",
      "Others accuracy 87.38095238095238\n",
      "------------------------------\n",
      "Astro f1-score  75.35297468269604\n",
      "Astro precision  75.50998537066648\n",
      "Astro recall  77.89017273576097\n",
      "--------------------------\n",
      "Neuron f1-score  88.2370073689147\n",
      "Neuron precision  87.19364689915908\n",
      "Neuron recall  90.03801169590643\n",
      "--------------------------\n",
      "Oligo f1-score  94.20731751311571\n",
      "Oligo precision  94.85318412080602\n",
      "Oligo recall  93.7205978214672\n",
      "--------------------------\n",
      "Others f1-score  88.18538505267766\n",
      "Others precision  89.83795009899661\n",
      "Others recall  87.01337424408094\n",
      "--------------------------\n",
      "Macro avg precision 86.84869162240705\n",
      "Macro avg recall  87.16553912430388\n",
      "Agreement:  1398 / 1656 =>  (84.42028985507247, '%')\n",
      "Disagreement:  258 / 1656 =>  (15.579710144927535, '%')\n",
      "------------------------------\n",
      "Of the disagreements, what are they?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Oligo     109\n",
       "Astro      66\n",
       "Neuron     47\n",
       "Others     36\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.5 \n",
    "#Confusion matrix across 10 folds, WITH thresholding \n",
    "print('with thresholding (non-calibrated) ACC :',mean(t_accuracies)*100)\n",
    "print('Macro avg F1 ',mean([i['macro avg']['f1-score'] for i in t_reports])*100)\n",
    "print('Weighted avg F1 ',mean([i['weighted avg']['f1-score'] for i in t_reports])*100)\n",
    "print(\"--------------------------\")\n",
    "C_t=sum(t_confusion_matrices)\n",
    "final_cm_t =  C_t.astype('float') / C_t.sum(axis=1)[:, np.newaxis]*100\n",
    "print(C_t)\n",
    "print(final_cm_t)\n",
    "print(\"--------------------------\")\n",
    "print(\"Astro accuracy\",final_cm_t[0][0])\n",
    "print(\"Neuron accuracy\",final_cm_t[1][1])\n",
    "print(\"Oligo accuracy\",final_cm_t[2][2])\n",
    "print(\"Others accuracy\",final_cm_t[3][3])\n",
    "print('------------------------------')\n",
    "# F1-score per class: \n",
    "print('Astro f1-score ',mean([i['Astro']['f1-score'] for i in t_reports])*100)\n",
    "print('Astro precision ',mean([i['Astro']['precision'] for i in t_reports])*100)\n",
    "print('Astro recall ',mean([i['Astro']['recall'] for i in t_reports])*100)\n",
    "print(\"--------------------------\")\n",
    "print('Neuron f1-score ',mean([i['Neuron']['f1-score'] for i in t_reports])*100)\n",
    "print('Neuron precision ',mean([i['Neuron']['precision'] for i in t_reports])*100)\n",
    "print('Neuron recall ',mean([i['Neuron']['recall'] for i in t_reports])*100)\n",
    "print(\"--------------------------\")\n",
    "print('Oligo f1-score ',mean([i['Oligo']['f1-score'] for i in t_reports])*100)\n",
    "print('Oligo precision ',mean([i['Oligo']['precision'] for i in t_reports])*100)\n",
    "print('Oligo recall ',mean([i['Oligo']['recall'] for i in t_reports])*100)\n",
    "print(\"--------------------------\")\n",
    "print('Others f1-score ',mean([i['Others']['f1-score'] for i in t_reports])*100)\n",
    "print('Others precision ',mean([i['Others']['precision'] for i in t_reports])*100)\n",
    "print('Others recall ',mean([i['Others']['recall'] for i in t_reports])*100)\n",
    "print(\"--------------------------\")\n",
    "print('Macro avg precision',mean([i['macro avg']['precision'] for i in t_reports])*100)\n",
    "print('Macro avg recall ',mean([i['macro avg']['recall'] for i in t_reports])*100)\n",
    "\n",
    "# Checking on disagreements \n",
    "\n",
    "\n",
    "thresholded_preds = pd.concat([pd.DataFrame(i) for i in y_preds_t])\n",
    "thresholded_preds = thresholded_preds.rename(columns={0:'t_Class'})\n",
    "thresholded_preds = thresholded_preds.reset_index(drop=True)\n",
    "\n",
    "\n",
    "preds = pd.concat([pd.DataFrame(i) for i in y_preds])\n",
    "preds = preds.rename(columns={0:'Class'})\n",
    "preds = preds.reset_index(drop=True)\n",
    "\n",
    "truth = pd.concat([pd.DataFrame(i) for i in y_cv_test])\n",
    "truth = truth.rename(columns={'Class':'Truth'})\n",
    "truth = truth.reset_index(drop=True)\n",
    "\n",
    "# x_truth = pd.concat([pd.DataFrame(i[['Image','Centroid_X','Centroid_Y']]) for i in x_cv_test])\n",
    "\n",
    "#Combine absolute prediction to thresholded prediction\n",
    "\n",
    "#get predicted probabilities\n",
    "p_probs=pd.concat([pd.DataFrame(i) for i in y_prob_preds])\n",
    "p_probs= p_probs.rename(columns={0:'Astro',1:'Neuron',2:'Oligo',3:'Others'})\n",
    "p_probs = p_probs.reset_index(drop=True)\n",
    "\n",
    "results = thresholded_preds.copy()\n",
    "results.loc[:,'Class']=preds\n",
    "results.loc[:,'Truth'] = truth\n",
    "results.loc[:,'Astro'] = p_probs['Astro']\n",
    "results.loc[:,'Neuron'] = p_probs['Neuron']\n",
    "results.loc[:,'Oligo'] = p_probs['Oligo']\n",
    "results.loc[:,'Others'] = p_probs['Others']\n",
    "# results.loc[:,'Image'] = x_truth['Image']\n",
    "# results.loc[:,'Centroid_X'] = x_truth['Centroid_X']\n",
    "# results.loc[:,'Centroid_Y'] = x_truth['Centroid_Y']\n",
    "\n",
    "\n",
    "#Calculate agreement between the two \n",
    "results.loc[:,'agreement'] = (results['t_Class']==results['Class'])*1\n",
    "agreements = results['agreement'].value_counts()\n",
    "print('Agreement: ',agreements[1],'/',agreements[1]+agreements[0],'=> ',(agreements[1]/(agreements[1]+agreements[0])*100,'%') )\n",
    "print('Disagreement: ',agreements[0],'/',agreements[1]+agreements[0],'=> ',(agreements[0]/(agreements[1]+agreements[0])*100,'%') )\n",
    "print('------------------------------')\n",
    "# Of those disagreed, what are they? (those with prob < 0.5)\n",
    "print('Of the disagreements, what are they?')\n",
    "disagreed = results[results['agreement']==0]\n",
    "disagreed['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oligo        721\n",
       "Others       411\n",
       "Neuron       188\n",
       "Ambiguous    177\n",
       "Astro        159\n",
       "Name: t_Class, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholded_preds['t_Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_Class</th>\n",
       "      <th>Class</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Astro</th>\n",
       "      <th>Neuron</th>\n",
       "      <th>Oligo</th>\n",
       "      <th>Others</th>\n",
       "      <th>agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.867352</td>\n",
       "      <td>0.129275</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>0.011431</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991724</td>\n",
       "      <td>0.008276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999484</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.054565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917978</td>\n",
       "      <td>0.027457</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t_Class  Class  Truth     Astro  Neuron     Oligo    Others  agreement\n",
       "0   Oligo  Oligo  Oligo  0.003373     0.0  0.867352  0.129275          1\n",
       "1   Oligo  Oligo  Oligo  0.000764     0.0  0.987805  0.011431          1\n",
       "2   Oligo  Oligo  Oligo  0.000000     0.0  0.991724  0.008276          1\n",
       "3   Oligo  Oligo  Oligo  0.000278     0.0  0.999484  0.000238          1\n",
       "4   Oligo  Oligo  Oligo  0.054565     0.0  0.917978  0.027457          1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_Class</th>\n",
       "      <th>Class</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Astro</th>\n",
       "      <th>Neuron</th>\n",
       "      <th>Oligo</th>\n",
       "      <th>Others</th>\n",
       "      <th>agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Others</td>\n",
       "      <td>Others</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.008141</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.358683</td>\n",
       "      <td>0.630367</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Others</td>\n",
       "      <td>Others</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.259244</td>\n",
       "      <td>0.045184</td>\n",
       "      <td>0.221733</td>\n",
       "      <td>0.473839</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Astro</td>\n",
       "      <td>0.535422</td>\n",
       "      <td>0.182759</td>\n",
       "      <td>0.084736</td>\n",
       "      <td>0.197083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.354454</td>\n",
       "      <td>0.491473</td>\n",
       "      <td>0.075477</td>\n",
       "      <td>0.078596</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Others</td>\n",
       "      <td>Others</td>\n",
       "      <td>Astro</td>\n",
       "      <td>0.052310</td>\n",
       "      <td>0.009289</td>\n",
       "      <td>0.293663</td>\n",
       "      <td>0.644738</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Astro</td>\n",
       "      <td>0.023917</td>\n",
       "      <td>0.974504</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Astro</td>\n",
       "      <td>0.037368</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>Astro</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.905754</td>\n",
       "      <td>0.025336</td>\n",
       "      <td>0.063158</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>Others</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Astro</td>\n",
       "      <td>0.458539</td>\n",
       "      <td>0.268606</td>\n",
       "      <td>0.038744</td>\n",
       "      <td>0.234111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.217336</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.650453</td>\n",
       "      <td>0.126014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        t_Class   Class   Truth     Astro    Neuron     Oligo    Others  \\\n",
       "8        Others  Others   Oligo  0.008141  0.002809  0.358683  0.630367   \n",
       "12       Others  Others   Oligo  0.259244  0.045184  0.221733  0.473839   \n",
       "23    Ambiguous   Astro   Astro  0.535422  0.182759  0.084736  0.197083   \n",
       "34       Neuron  Neuron   Oligo  0.354454  0.491473  0.075477  0.078596   \n",
       "49       Others  Others   Astro  0.052310  0.009289  0.293663  0.644738   \n",
       "...         ...     ...     ...       ...       ...       ...       ...   \n",
       "1642     Neuron  Neuron   Astro  0.023917  0.974504  0.000167  0.001412   \n",
       "1644     Neuron  Neuron   Astro  0.037368  0.958042  0.000919  0.003671   \n",
       "1650      Astro   Astro   Oligo  0.905754  0.025336  0.063158  0.005752   \n",
       "1652     Others   Astro   Astro  0.458539  0.268606  0.038744  0.234111   \n",
       "1653  Ambiguous   Oligo  Others  0.217336  0.006196  0.650453  0.126014   \n",
       "\n",
       "      agreement  \n",
       "8             1  \n",
       "12            1  \n",
       "23            0  \n",
       "34            1  \n",
       "49            1  \n",
       "...         ...  \n",
       "1642          1  \n",
       "1644          1  \n",
       "1650          1  \n",
       "1652          0  \n",
       "1653          0  \n",
       "\n",
       "[327 rows x 8 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['t_Class']!=results['Truth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test =pd.concat(x_cv_test)\n",
    "x_test=x_test.reset_index(drop=True)\n",
    "x_test_subset=x_test[['Image','Name','Centroid_X','Centroid_Y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_=results.copy()\n",
    "results_=results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ = results_.join(x_test_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_Class</th>\n",
       "      <th>Class</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Astro</th>\n",
       "      <th>Neuron</th>\n",
       "      <th>Oligo</th>\n",
       "      <th>Others</th>\n",
       "      <th>agreement</th>\n",
       "      <th>Image</th>\n",
       "      <th>Name</th>\n",
       "      <th>Centroid_X</th>\n",
       "      <th>Centroid_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.867352</td>\n",
       "      <td>0.129275</td>\n",
       "      <td>1</td>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>12022.2</td>\n",
       "      <td>8715.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>0.011431</td>\n",
       "      <td>1</td>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>12029.8</td>\n",
       "      <td>8722.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991724</td>\n",
       "      <td>0.008276</td>\n",
       "      <td>1</td>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>10048.5</td>\n",
       "      <td>9974.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999484</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>1</td>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>10029.8</td>\n",
       "      <td>9984.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.054565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917978</td>\n",
       "      <td>0.027457</td>\n",
       "      <td>1</td>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>10031.0</td>\n",
       "      <td>9993.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t_Class  Class  Truth     Astro  Neuron     Oligo    Others  agreement  \\\n",
       "0   Oligo  Oligo  Oligo  0.003373     0.0  0.867352  0.129275          1   \n",
       "1   Oligo  Oligo  Oligo  0.000764     0.0  0.987805  0.011431          1   \n",
       "2   Oligo  Oligo  Oligo  0.000000     0.0  0.991724  0.008276          1   \n",
       "3   Oligo  Oligo  Oligo  0.000278     0.0  0.999484  0.000238          1   \n",
       "4   Oligo  Oligo  Oligo  0.054565     0.0  0.917978  0.027457          1   \n",
       "\n",
       "        Image             Name  Centroid_X  Centroid_Y  \n",
       "0  721708.svs  Globus Pallidus     12022.2      8715.8  \n",
       "1  721708.svs  Globus Pallidus     12029.8      8722.0  \n",
       "2  721708.svs  Globus Pallidus     10048.5      9974.4  \n",
       "3  721708.svs  Globus Pallidus     10029.8      9984.5  \n",
       "4  721708.svs  Globus Pallidus     10031.0      9993.5  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747814.svs    275\n",
       "721708.svs    257\n",
       "747370.svs    244\n",
       "747820.svs    223\n",
       "771885.svs    203\n",
       "747308.svs    182\n",
       "747828.svs    149\n",
       "755497.svs    123\n",
       "Name: Image, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_['Image'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_Class</th>\n",
       "      <th>Class</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Astro</th>\n",
       "      <th>Neuron</th>\n",
       "      <th>Oligo</th>\n",
       "      <th>Others</th>\n",
       "      <th>agreement</th>\n",
       "      <th>Image</th>\n",
       "      <th>Name</th>\n",
       "      <th>Centroid_X</th>\n",
       "      <th>Centroid_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Others</td>\n",
       "      <td>Others</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.008141</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.358683</td>\n",
       "      <td>0.630367</td>\n",
       "      <td>1</td>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>10008.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Others</td>\n",
       "      <td>Others</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.259244</td>\n",
       "      <td>0.045184</td>\n",
       "      <td>0.221733</td>\n",
       "      <td>0.473839</td>\n",
       "      <td>1</td>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>11999.4</td>\n",
       "      <td>10042.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Astro</td>\n",
       "      <td>Astro</td>\n",
       "      <td>0.535422</td>\n",
       "      <td>0.182759</td>\n",
       "      <td>0.084736</td>\n",
       "      <td>0.197083</td>\n",
       "      <td>0</td>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>10857.7</td>\n",
       "      <td>10904.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Neuron</td>\n",
       "      <td>Neuron</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.354454</td>\n",
       "      <td>0.491473</td>\n",
       "      <td>0.075477</td>\n",
       "      <td>0.078596</td>\n",
       "      <td>1</td>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>12103.7</td>\n",
       "      <td>11999.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Others</td>\n",
       "      <td>Others</td>\n",
       "      <td>Astro</td>\n",
       "      <td>0.052310</td>\n",
       "      <td>0.009289</td>\n",
       "      <td>0.293663</td>\n",
       "      <td>0.644738</td>\n",
       "      <td>1</td>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>11764.1</td>\n",
       "      <td>12906.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      t_Class   Class  Truth     Astro    Neuron     Oligo    Others  \\\n",
       "8      Others  Others  Oligo  0.008141  0.002809  0.358683  0.630367   \n",
       "12     Others  Others  Oligo  0.259244  0.045184  0.221733  0.473839   \n",
       "23  Ambiguous   Astro  Astro  0.535422  0.182759  0.084736  0.197083   \n",
       "34     Neuron  Neuron  Oligo  0.354454  0.491473  0.075477  0.078596   \n",
       "49     Others  Others  Astro  0.052310  0.009289  0.293663  0.644738   \n",
       "\n",
       "    agreement       Image             Name  Centroid_X  Centroid_Y  \n",
       "8           1  721708.svs  Globus Pallidus     12000.0     10008.3  \n",
       "12          1  721708.svs  Globus Pallidus     11999.4     10042.9  \n",
       "23          0  721708.svs  Globus Pallidus     10857.7     10904.9  \n",
       "34          1  721708.svs  Globus Pallidus     12103.7     11999.8  \n",
       "49          1  721708.svs  Globus Pallidus     11764.1     12906.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect = results_[results_['t_Class']!=results_['Truth']]\n",
    "incorrect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Others    119\n",
       "Oligo     100\n",
       "Astro      71\n",
       "Neuron     37\n",
       "Name: Truth, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect['Truth'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Striatum               142\n",
       "Globus Pallidus        107\n",
       "Subthalamic Nucleus     78\n",
       "Name: Name, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect['Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Striatum               776\n",
       "Globus Pallidus        580\n",
       "Subthalamic Nucleus    300\n",
       "Name: Name, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_['Name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77.08333333, 10.41666667,  0.        , 12.5       ],\n",
       "       [ 4.16666667, 87.5       ,  0.        ,  8.33333333],\n",
       "       [ 1.38408304,  0.34602076, 95.5017301 ,  2.76816609],\n",
       "       [ 3.79746835,  0.63291139,  7.59493671, 87.97468354]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GP_results = results_[results_['Name']=='Globus Pallidus']\n",
    "GP_cm = confusion_matrix(GP_results['Truth'],GP_results['t_Class']\n",
    "                         ,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')*100\n",
    "GP_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[88.0952381 , 11.9047619 ,  0.        ],\n",
       "       [ 4.54545455, 95.45454545,  0.        ],\n",
       "       [ 1.42348754,  0.35587189, 98.22064057]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GP_results = results_[results_['Name']=='Globus Pallidus']\n",
    "GP_cm = confusion_matrix(GP_results['Truth'],GP_results['t_Class']\n",
    "                         ,labels=[\"Astro\",\"Neuron\",\"Oligo\"],normalize='true')*100\n",
    "GP_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[82.05128205,  7.69230769,  2.56410256,  7.69230769],\n",
       "       [ 7.35294118, 91.91176471,  0.        ,  0.73529412],\n",
       "       [ 2.56410256,  0.        , 92.94871795,  4.48717949],\n",
       "       [ 1.66666667,  4.44444444,  7.77777778, 86.11111111]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STR_results = results_[results_['Name']=='Striatum']\n",
    "STR_cm = confusion_matrix(STR_results['Truth'],STR_results['t_Class']\n",
    "                         ,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')*100\n",
    "STR_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[88.88888889,  8.33333333,  2.77777778],\n",
       "       [ 7.40740741, 92.59259259,  0.        ],\n",
       "       [ 2.68456376,  0.        , 97.31543624]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STR_results = results_[results_['Name']=='Striatum']\n",
    "STR_cm = confusion_matrix(STR_results['Truth'],STR_results['t_Class']\n",
    "                         ,labels=[\"Astro\",\"Neuron\",\"Oligo\"],normalize='true')*100\n",
    "STR_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[65.2173913 ,  8.69565217, 13.04347826, 13.04347826],\n",
       "       [18.18181818, 77.27272727,  4.54545455,  0.        ],\n",
       "       [ 3.93700787,  0.78740157, 92.12598425,  3.1496063 ],\n",
       "       [ 2.43902439,  1.2195122 ,  7.31707317, 89.02439024]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STN_results = results_[results_['Name']=='Subthalamic Nucleus']\n",
    "STN_cm = confusion_matrix(STN_results['Truth'],STN_results['t_Class']\n",
    "                         ,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"],normalize='true')*100\n",
    "STN_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 15,   2,   3,   3],\n",
       "       [  4,  17,   1,   0],\n",
       "       [  5,   1, 117,   4],\n",
       "       [  2,   1,   6,  73]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STN_results = results_[results_['Name']=='Subthalamic Nucleus']\n",
    "STN_cm = confusion_matrix(STN_results['Truth'],STN_results['t_Class']\n",
    "                         ,labels=[\"Astro\",\"Neuron\",\"Oligo\",\"Others\"])\n",
    "STN_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oligo        127\n",
       "Others        80\n",
       "Ambiguous     46\n",
       "Astro         26\n",
       "Neuron        21\n",
       "Name: t_Class, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STN_results['t_Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oligo     137\n",
       "Others    101\n",
       "Astro      36\n",
       "Neuron     26\n",
       "Name: Truth, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STN_results['Truth'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75.        , 10.        , 15.        ],\n",
       "       [18.18181818, 77.27272727,  4.54545455],\n",
       "       [ 4.06504065,  0.81300813, 95.12195122]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STN_results = results_[results_['Name']=='Subthalamic Nucleus']\n",
    "STN_cm = confusion_matrix(STN_results['Truth'],STN_results['t_Class']\n",
    "                         ,labels=[\"Astro\",\"Neuron\",\"Oligo\"],normalize='true')*100\n",
    "STN_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorrect_as_file = incorrect[['Image','Truth','Centroid_X','Centroid_Y','t_Class']]\n",
    "# path_ = 'D:/Tanrada_classification/imbalance_cortical_training/cortical_full_slide_predictions/Probabilistic_classification/Model8_occipital_classifier/cell_inspection/incorrect.txt'\n",
    "# incorrect_as_file.to_csv(path_, sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_Class</th>\n",
       "      <th>Class</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Astro</th>\n",
       "      <th>Neuron</th>\n",
       "      <th>Oligo</th>\n",
       "      <th>Others</th>\n",
       "      <th>agreement</th>\n",
       "      <th>Image</th>\n",
       "      <th>Name</th>\n",
       "      <th>Centroid_X</th>\n",
       "      <th>Centroid_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.867352</td>\n",
       "      <td>0.129275</td>\n",
       "      <td>1</td>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>12022.2</td>\n",
       "      <td>8715.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>0.011431</td>\n",
       "      <td>1</td>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>12029.8</td>\n",
       "      <td>8722.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991724</td>\n",
       "      <td>0.008276</td>\n",
       "      <td>1</td>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>10048.5</td>\n",
       "      <td>9974.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999484</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>1</td>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>10029.8</td>\n",
       "      <td>9984.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>Oligo</td>\n",
       "      <td>0.054565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917978</td>\n",
       "      <td>0.027457</td>\n",
       "      <td>1</td>\n",
       "      <td>721708.svs</td>\n",
       "      <td>Globus Pallidus</td>\n",
       "      <td>10031.0</td>\n",
       "      <td>9993.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  t_Class  Class  Truth     Astro  Neuron     Oligo    Others  agreement  \\\n",
       "0   Oligo  Oligo  Oligo  0.003373     0.0  0.867352  0.129275          1   \n",
       "1   Oligo  Oligo  Oligo  0.000764     0.0  0.987805  0.011431          1   \n",
       "2   Oligo  Oligo  Oligo  0.000000     0.0  0.991724  0.008276          1   \n",
       "3   Oligo  Oligo  Oligo  0.000278     0.0  0.999484  0.000238          1   \n",
       "4   Oligo  Oligo  Oligo  0.054565     0.0  0.917978  0.027457          1   \n",
       "\n",
       "        Image             Name  Centroid_X  Centroid_Y  \n",
       "0  721708.svs  Globus Pallidus     12022.2      8715.8  \n",
       "1  721708.svs  Globus Pallidus     12029.8      8722.0  \n",
       "2  721708.svs  Globus Pallidus     10048.5      9974.4  \n",
       "3  721708.svs  Globus Pallidus     10029.8      9984.5  \n",
       "4  721708.svs  Globus Pallidus     10031.0      9993.5  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = results_[results_['t_Class']==results_['Truth']]\n",
    "correct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_as_file = correct[['Image','Truth','Centroid_X','Centroid_Y','t_Class']]\n",
    "# path_ = 'D:/Tanrada_classification/imbalance_cortical_training/cortical_full_slide_predictions/Probabilistic_classification/Model8_occipital_classifier/cell_inspection/correct.txt'\n",
    "# correct_as_file.to_csv(path_, sep='\\t',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
